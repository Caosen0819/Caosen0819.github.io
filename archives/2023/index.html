
<!DOCTYPE html>
<html lang="zh-CH">
    
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1">
    <meta name="generator" content="森">
    <title>Archiv: 2023 - 森</title>
    <meta name="author" content="CSEN">
    
    
    
    <script type="application/ld+json">{}</script>
    <meta name="description" content="潮起潮落，云卷云舒">
<meta property="og:type" content="blog">
<meta property="og:title" content="森">
<meta property="og:url" content="http://example.com/archives/2023/index.html">
<meta property="og:site_name" content="森">
<meta property="og:description" content="潮起潮落，云卷云舒">
<meta property="og:locale" content="zh_CH">
<meta property="article:author" content="CSEN">
<meta name="twitter:card" content="summary">
    
    
        
    
    
        <meta property="og:image" content="http://example.com/assets/images/head.jpg"/>
    
    
    
    
    <!--STYLES-->
    
<link rel="stylesheet" href="/assets/css/style-w816scvuzwavitjylabixcb3ofuoklqul47j3rgwu1r0mxrxvbdehvp2jk5s.min.css">

    <!--STYLES END-->
    

    

    
</head>

    <body>
        <div id="blog">
            <!-- Define author's picture -->


    
        
            
        
    

<header id="header" data-behavior="1">
    <i id="btn-open-sidebar" class="fa fa-lg fa-bars"></i>
    <div class="header-title">
        <a
            class="header-title-link"
            href="/"
            aria-label=""
        >
            森
        </a>
    </div>
    
        
            <a
                class="header-right-picture "
                href="#about"
                aria-label="Öffne den Link: /#about"
            >
        
        
            <img class="header-picture" src="/assets/images/head.jpg" alt="Bild des Autors"/>
        
        </a>
    
</header>

            <!-- Define author's picture -->



        
    

<nav id="sidebar" data-behavior="1">
    <div class="sidebar-container">
        
            <div class="sidebar-profile">
                <a
                    href="/#about"
                    aria-label="Lesen Sie mehr über den Autor"
                >
                    <img class="sidebar-profile-picture" src="/assets/images/head.jpg" alt="Bild des Autors"/>
                </a>
                <h4 class="sidebar-profile-name">CSEN</h4>
                
                    <h5 class="sidebar-profile-bio"><p>author.bio</p>
</h5>
                
            </div>
        
        
            <ul class="sidebar-buttons">
            
                <li class="sidebar-button">
                    
                        <a
                            class="sidebar-button-link "
                            href="/"
                            
                            rel="noopener"
                            title="首页"
                        >
                        <i class="sidebar-button-icon fa fa-home" aria-hidden="true"></i>
                        <span class="sidebar-button-desc">首页</span>
                    </a>
            </li>
            
                <li class="sidebar-button">
                    
                        <a
                            class="sidebar-button-link "
                            href="/all-categories"
                            
                            rel="noopener"
                            title="分类"
                        >
                        <i class="sidebar-button-icon fa fa-bookmark" aria-hidden="true"></i>
                        <span class="sidebar-button-desc">分类</span>
                    </a>
            </li>
            
                <li class="sidebar-button">
                    
                        <a
                            class="sidebar-button-link "
                            href="/all-tags"
                            
                            rel="noopener"
                            title="标签"
                        >
                        <i class="sidebar-button-icon fa fa-tags" aria-hidden="true"></i>
                        <span class="sidebar-button-desc">标签</span>
                    </a>
            </li>
            
                <li class="sidebar-button">
                    
                        <a
                            class="sidebar-button-link "
                            href="/all-archives"
                            
                            rel="noopener"
                            title="档案"
                        >
                        <i class="sidebar-button-icon fa fa-archive" aria-hidden="true"></i>
                        <span class="sidebar-button-desc">档案</span>
                    </a>
            </li>
            
                <li class="sidebar-button">
                    
                        <a
                            class="sidebar-button-link open-algolia-search"
                            href="#search"
                            
                            rel="noopener"
                            title="搜索"
                        >
                        <i class="sidebar-button-icon fa fa-search" aria-hidden="true"></i>
                        <span class="sidebar-button-desc">搜索</span>
                    </a>
            </li>
            
                <li class="sidebar-button">
                    
                        <a
                            class="sidebar-button-link "
                            href="#about"
                            
                            rel="noopener"
                            title="关于"
                        >
                        <i class="sidebar-button-icon fa fa-question" aria-hidden="true"></i>
                        <span class="sidebar-button-desc">关于</span>
                    </a>
            </li>
            
        </ul>
        
            <ul class="sidebar-buttons">
            
                <li class="sidebar-button">
                    
                        <a
                            class="sidebar-button-link "
                            href="https://github.com/Caosen0819"
                            
                                target="_blank"
                            
                            rel="noopener"
                            title=".github"
                        >
                        <i class="sidebar-button-icon fab fa-github" aria-hidden="true"></i>
                        <span class="sidebar-button-desc">.github</span>
                    </a>
            </li>
            
        </ul>
        
    </div>
</nav>

            
            <div id="main" data-behavior="1"
                 class="
                        hasCoverMetaIn
                        ">
                
    <section class="postShorten-group main-content-wrap">
    
    
    <article class="postShorten postShorten--thumbnailimg-bottom">
        <div class="postShorten-wrap">
            
            <div class="postShorten-header">
                <h1 class="postShorten-title">
                    
                        <a
                            class="link-unstyled"
                            href="/2023/10/09/Redis/"
                            aria-label=": Redis复习"
                        >
                            Redis复习
                        </a>
                    
                </h1>
                <div class="postShorten-meta">
    <time datetime="2023-10-09T00:00:00+08:00">
	
		    09 Oct 2023
    	
    </time>
    
        <span>in </span>
        
    <a class="category-link" href="/categories/Java/">Java</a>


    
</div>

            </div>
            
                <div class="postShorten-content">
                    <h1 id="1、Redis数据结构"><a href="#1、Redis数据结构" class="headerlink" title="1、Redis数据结构"></a>1、Redis数据结构</h1><h1 id="2、Redis线程模型"><a href="#2、Redis线程模型" class="headerlink" title="2、Redis线程模型"></a>2、Redis线程模型</h1><h2 id="1、Redis是不是单线程的？"><a href="#1、Redis是不是单线程的？" class="headerlink" title="1、Redis是不是单线程的？"></a>1、Redis是不是单线程的？</h2><p>1、他有后台线程</p>
<p>2、Redis6之后，用 多IO线程 来处理网络请求的</p>
<p>所以他不是单线程的。</p>
<p>而我们之前说的单线程其实指的是：Redis在处理客户端的请求时包括获取 (socket 读)、解析、执行、内容返回 (socket 写) 等都由一个顺序串行的主线程处理</p>
<p><img src="/../images/Redis/70ca1c2378d64deb942e3dea580ceb7e~tplv-k3u1fbpfcp-zoom-in-crop-mark:1512:0:0:0.awebp" alt="image.png"></p>
<h2 id="2、单线程是怎么样子的"><a href="#2、单线程是怎么样子的" class="headerlink" title="2、单线程是怎么样子的"></a>2、单线程是怎么样子的</h2><p>网络请求过来，会先创建一个服务端socket，然后把这个socket加入到epoll里面，让epoll去监听这个socket哪个有事件产生，一旦发现事件产生，就交给事件分发器，事件分发器会根据事件的类型调用不同的事件处理器。</p>
<h2 id="3、为什么这么快？"><a href="#3、为什么这么快？" class="headerlink" title="3、为什么这么快？"></a>3、为什么这么快？</h2><p>基于内存</p>
<p>单线程避免了上下文竞争</p>
<p>io多路复用</p>
<p>高效的数据结构</p>
<h2 id="4、采用单线程原因"><a href="#4、采用单线程原因" class="headerlink" title="4、采用单线程原因"></a>4、采用单线程原因</h2><ul>
<li>使用单线程模型是 Redis 的开发和维护更简单</li>
<li>即使使用单线程模型也并发的处理多客户端的请求，主要使用的是多路复用IO</li>
<li>对于 Redis 系统来说， 主要的<code>性能瓶颈是内存或者网络带宽而并非 CPU</code>。</li>
</ul>
<h2 id="5、引入多线程原因"><a href="#5、引入多线程原因" class="headerlink" title="5、引入多线程原因"></a>5、引入多线程原因</h2><p>内存问题比较好解决，因此Redis的瓶颈原因为网络IO</p>
<h2 id="多线程工作原理"><a href="#多线程工作原理" class="headerlink" title="多线程工作原理"></a>多线程工作原理</h2><p>I&#x2F;O 的读和写本身是堵塞的，比如当 socket 中有数据时，Redis 会通过调用先将数据从内核态空间拷贝到用户态空间，再交给 Redis 调用，而这个拷贝的过程就是阻塞的，当数据量越大时拷贝所需要的时间就越多，而这些操作都是基于单线程完成的。</p>
<p><img src="/../images/Redis/1f56d21bf7c44aec872e391ea1f052bc~tplv-k3u1fbpfcp-zoom-in-crop-mark:1512:0:0:0.awebp" alt="image.png"></p>
<p>在 Redis 6.0 中新增了<strong>多线程的功能来提高 I&#x2F;O 的读写性能</strong>，将最耗时的Socket的读取、请求解析、写入单独外包给一组线程，剩下的命令执行仍然由主线程串行执行并和内存的数据交互。</p>
<p><img src="/../images/Redis/41070392631d4818a730d02b957517ae~tplv-k3u1fbpfcp-zoom-in-crop-mark:1512:0:0:0.awebp" alt="image.png"></p>
<p>流程简述如下：</p>
<ul>
<li>主线程获取 socket 放入等待列表</li>
<li>将 socket 分配给各个 IO 线程（并不会等列表满）</li>
<li>主线程<code>阻塞等待 IO 线程(多线程)</code>读取 socket 完毕</li>
<li>主线程执行命令 - <code>单线程</code>（如果命令没有接收完毕，会等 IO 下次继续）</li>
<li>主线程<code>阻塞等待 IO 线程(多线程)</code>将数据回写 socket 完毕（一次没写完，会等下次再写）</li>
</ul>
<p><img src="/../images/Redis/75394f2582e145fa842e31cdf3be550b~tplv-k3u1fbpfcp-zoom-in-crop-mark:1512:0:0:0.awebp" alt="img.png"></p>
<p>Redis自身出道就是优秀，基于内存操作、数据结构简单、多路复用和非阻塞 I&#x2F;O、避免了不必要的线程上下文切换等特性，在单线程的环境下依然很快；</p>
<p>但对于大数据的 key 删除还是卡顿厉害，因此在 Redis 4.0 引入了多线程unlink key&#x2F;flushall async 等命令，主要用于 Redis 数据的异步删除；</p>
<p>而在 Redis 6.0 中引入了 I&#x2F;O 多线程的读写，这样就可以更加高效的处理更多的任务了， Redis 只是<code>将 I/O 读写变成了多线程</code> ，而 <code>命令的执行依旧是由主线程串行执行的</code> ，因此在多线程下操作 Redis <code>不会出现线程安全的问题</code>。 </p>
<h1 id="3、Redis持久化"><a href="#3、Redis持久化" class="headerlink" title="3、Redis持久化"></a>3、Redis持久化</h1><p>Redis 共有三种数据持久化的方式：</p>
<ul>
<li><strong>AOF 日志</strong>：每执行一条写操作命令，就把该命令以追加的方式写入到一个文件里；</li>
<li><strong>RDB 快照</strong>：将某一时刻的内存数据，以二进制的方式写入磁盘；</li>
<li><strong>混合持久化方式</strong>：Redis 4.0 新增的方式，集成了 AOF 和 RBD 的优点；</li>
</ul>
<h2 id="1、AOF"><a href="#1、AOF" class="headerlink" title="1、AOF"></a>1、AOF</h2><p>执行一条写命令，就把这个命令往aof文件里面写</p>
<h3 id="1、为什么先执行命令，再把数据写入日志呢？"><a href="#1、为什么先执行命令，再把数据写入日志呢？" class="headerlink" title="1、为什么先执行命令，再把数据写入日志呢？"></a>1、为什么先执行命令，再把数据写入日志呢？</h3><blockquote>
<p>1、避免额外的开销</p>
<p>2、不会阻塞当前的写命令</p>
<p>缺点：</p>
<p>1、可能数据丢失，因为如果在执行完还没写入aof文件之间宕机，那就丢失</p>
<p>2、可能阻塞下一个命令</p>
</blockquote>
<h3 id="2、写回策略几种？"><a href="#2、写回策略几种？" class="headerlink" title="2、写回策略几种？"></a>2、写回策略几种？</h3><p>三种：Always everySec no，其实和mysql的binlog非常相似</p>
<p>第一种就是每次都同步</p>
<p>第二种就是每一秒都讲缓冲区里面的写会磁盘</p>
<p>第三种就是写到缓冲区里面，但是什么时候写到磁盘依赖于操作系统</p>
<h3 id="3、AOF-日志过大，会触发什么机制？"><a href="#3、AOF-日志过大，会触发什么机制？" class="headerlink" title="3、AOF 日志过大，会触发什么机制？"></a>3、AOF 日志过大，会触发什么机制？</h3><p>aof重写机制：读取当前数据库中的所有键值对，对每一键值对用一条命令记录到「新的 AOF 文件」，等到全部记录完后，就将新的 AOF 文件替换掉现有的 AOF 文件。</p>
<p>aof是由后台子进程完成的。</p>
<p>这里有一个问题，就是如果aof重写过程中，主进程对内存进行了修改，怎么办？会触发写时复制</p>
<p>当aof重写过程中父进程修改内存，那我们执行一个写命令后，会写到aof缓冲区和aof重写缓冲区里面。当子进程完成重写，再去吧重写缓冲区里面的内容追加到aof文件</p>
<h2 id="2、RDB快照"><a href="#2、RDB快照" class="headerlink" title="2、RDB快照"></a>2、RDB快照</h2><p>快照就是记录一瞬间的意思。记录的是当前的实际数据。</p>
<p>有两种启动的方式，一个save阻塞住线程，一种bgsave，不阻塞主线程。</p>
<p>所以rdb快照不会想aof那样开辟一个缓冲区用于记录新操作。这里rdb用的是全量快照数据。</p>
<p>如果在rdb快照的时候，主线程修改了内容，那么这时候会出发写保护中断，写时复制，原本的物理内存A，复制一份A‘，然后主线程修改A’就好了</p>
<h2 id="3、混合持久化"><a href="#3、混合持久化" class="headerlink" title="3、混合持久化"></a>3、混合持久化</h2><p>混合持久化就是合并了aof和rdb的两个优点，rdb恢复数据块，aof丢失数据少</p>
<p>混合持久化，fork出来的子进程先去把共享内存以rdb的格式写入到aof文件里面，然后写入过程中主进程执行的命令会被记录到重写缓冲区里面，然后这些增量命令最后会以aof的格式增加到aof文件里面，所以aof文件里面前一部分时rdb，后一部分是aof。</p>
<h1 id="4、Redis集群"><a href="#4、Redis集群" class="headerlink" title="4、Redis集群"></a>4、Redis集群</h1><h1 id="5、Redis-过期删除与内存淘汰"><a href="#5、Redis-过期删除与内存淘汰" class="headerlink" title="5、Redis 过期删除与内存淘汰"></a>5、Redis 过期删除与内存淘汰</h1><h2 id="1、Redis过期策略"><a href="#1、Redis过期策略" class="headerlink" title="1、Redis过期策略"></a>1、Redis过期策略</h2><p>Redis 使用的过期删除策略是「<strong>惰性删除+定期删除</strong>」这两种策略配和使用。</p>
<blockquote>
<p>什么是惰性删除？</p>
<p>我不主动的删除，每当访问key的时候，我去判断一下是否过期，如果过期那么就删除该key</p>
<p>优点：占用比较少的资源，对cpu时间最友好</p>
<p>缺点：会导致缓存污染，浪费内存空间，对内存友好</p>
</blockquote>
<blockquote>
<p>什么是定期删除策略？</p>
<p>就是定期的数据库里面随机抽取一定数量的key，并删除其中的过期的key</p>
<p>抽取策略？</p>
<p>1、从过期字典里面随机找20个</p>
<p>2、然后判断是否过期，并删除已经过期的key</p>
<p>3、如果过期的key超过了25%，那么就重复这个过程，如果没有，那就等待下一轮的抽查</p>
<p>优点：通过限制删除操作的时长的频率可以减少一些无用的占用</p>
<p>缺点：很难确定删除的时长和频率，太频繁对cpu不好，太少又和惰性删除一样。</p>
</blockquote>
<h3 id="1、Redis-持久化时，对过期键会如何处理的？"><a href="#1、Redis-持久化时，对过期键会如何处理的？" class="headerlink" title="1、Redis 持久化时，对过期键会如何处理的？"></a>1、Redis 持久化时，对过期键会如何处理的？</h3><p>持久化有两种 aof和rdb</p>
<p>对于rdb，考虑生成和加载阶段</p>
<p>生成阶段：对于过期的key不写入rdb文件里面</p>
<p>加载阶段：这里分两种情况，一种是主服务器，另一种是从服务器。</p>
<p>​	主服务器：加载阶段回去判断key是不是过期了，如果过期了那我就不加载这个</p>
<p>​	从服务器：不管key是不是过期，全部加载。</p>
<p>aof：考虑aof写入阶段和重写阶段</p>
<p>写入阶段：如果这个key过期了，但是没有被删除，那么aof文件就会保留这个key，如果这个key被过期策略删除了，那么就会往aof文件里面追加一条del语句</p>
<p>重写阶段：重写阶段如果过期了，那么就直接删除，不会保留在新的aof文件里面</p>
<h3 id="2、Redis-主从模式中，对过期键会如何处理？"><a href="#2、Redis-主从模式中，对过期键会如何处理？" class="headerlink" title="2、Redis 主从模式中，对过期键会如何处理？"></a>2、Redis 主从模式中，对过期键会如何处理？</h3><p>主从模式中，从数据库完全依赖于主数据库，所以即使从库的key过期了，但是你查询，依旧能查到。只有主数据库在key到期的时候往aof文件里面增加del语句，同步到所有的从库，从库才会删除这个key。</p>
<h2 id="2、Redis-内存淘汰"><a href="#2、Redis-内存淘汰" class="headerlink" title="2、Redis 内存淘汰"></a>2、Redis 内存淘汰</h2><p>在 Redis 的运行内存达到了某个阀值，就会触发<strong>内存淘汰机制</strong>，这个阀值就是我们设置的最大运行内存，此值在 Redis 的配置文件中可以找到，配置项为 maxmemory。</p>
<p>内存淘汰机制分为两类：一类是对有过期时间的内存淘汰机制；一类是对所有数据的淘汰机制。</p>
<p>对过期时间的内存淘汰机制可以分成四种：</p>
<p>1、volatile random</p>
<p>2、volatile lru 最近最少使用</p>
<p>3、volatile lfu <strong>最近最不常用的</strong></p>
<p>4、volatile ttl  最早时间</p>
<p>对所有数据的淘汰机制：</p>
<p>1、volatile random</p>
<p>2、volatile lru 最近最少使用</p>
<p>3、volatile lfu <strong>最近最不常用的</strong></p>
<h3 id="LRU-算法和-LFU-算法有什么区别？"><a href="#LRU-算法和-LFU-算法有什么区别？" class="headerlink" title="LRU 算法和 LFU 算法有什么区别？"></a>LRU 算法和 LFU 算法有什么区别？</h3><p>传统的lru算法依赖于一个链表，，数据被访问时候，链表中的节点会出现很多的移动操作，降低性能</p>
<p>Redis实现lru是在RedisObject里面新增一个字段，记录最后一次访问时间</p>
<p>进行淘汰的时候，随机选取五个，然后淘汰访问时间最早的</p>
<p>优点：节省空间，提高性能</p>
<p>缺点：无法解决缓存污染</p>
<p>LFU</p>
<p>lfu在RedisObject的基础上新增了一个字段，用于记录数据的访问频次。24位</p>
<p>高16位记录时间戳，后8位记录访问频次，默认5，会随着时间衰减</p>
<p>数据每次被访问的时候：</p>
<p>先做一个衰减操作，根据时间和上一次访问时间的差</p>
<p>然后做一次增加的操作，这个是基于一定的概率</p>
<p><img src="/../images/Redis/%E8%BF%87%E6%9C%9F%E5%88%A0%E9%99%A4%E7%AD%96%E7%95%A5.jpg" alt="img"></p>
<p><img src="/../images/Redis/%E5%86%85%E5%AD%98%E6%B7%98%E6%B1%B0%E7%AD%96%E7%95%A5.jpg" alt="img"></p>
<h1 id="6、Redis缓存设计"><a href="#6、Redis缓存设计" class="headerlink" title="6、Redis缓存设计"></a>6、Redis缓存设计</h1><h2 id="1、如何避免缓存雪崩？"><a href="#1、如何避免缓存雪崩？" class="headerlink" title="1、如何避免缓存雪崩？"></a>1、如何避免缓存雪崩？</h2><p>缓存雪崩是指在同一时间大量的key同时过期了</p>
<p>解决方法：</p>
<p>这里关键就是同时和过期，所以解决方法如下：</p>
<p>1、打乱过期的时间</p>
<p>2、设置缓存不过期</p>
<h2 id="2、缓存击穿"><a href="#2、缓存击穿" class="headerlink" title="2、缓存击穿"></a>2、缓存击穿</h2><p>对于一个热点数据过期了，导致请求全部打到数据库</p>
<p>1、设置缓存不过期，后台异步的去更新</p>
<p>2、互斥锁，分布式锁的方法。让同一时间只有一个线程去访问</p>
<h2 id="3、缓存穿透"><a href="#3、缓存穿透" class="headerlink" title="3、缓存穿透"></a>3、缓存穿透</h2><p>访问的值既不在redis 也不在mysql，所以很可能是那种黑客攻击之类的，解决方法的话</p>
<p>1、非法请求的限制</p>
<p>2、空值或者默认值</p>
<p>3、布隆过滤器</p>
<h3 id="4、说说常见的缓存更新策略？"><a href="#4、说说常见的缓存更新策略？" class="headerlink" title="4、说说常见的缓存更新策略？"></a>4、说说常见的缓存更新策略？</h3><blockquote>
<p>常见的缓存更新策略共有2种：</p>
</blockquote>
<ul>
<li><p>Cache Aside（旁路缓存）策略；</p>
</li>
<li><p>Read&#x2F;Write Through（读穿 &#x2F; 写穿）策略；</p>
</li>
</ul>
<p>Read&#x2F;Write Through（读穿 &#x2F; 写穿）策略</p>
<p><strong>写策略的步骤：</strong></p>
<ul>
<li>先更新数据库中的数据，再删除缓存中的数据。</li>
</ul>
<p><strong>读策略的步骤：</strong></p>
<ul>
<li>如果读取的数据命中了缓存，则直接返回数据；</li>
<li>如果读取的数据没有命中缓存，则从数据库中读取数据，然后将数据写入到缓存，并且返回给用户。</li>
</ul>
<blockquote>
<p>Read&#x2F;Write Through（读穿 &#x2F; 写穿）策略</p>
</blockquote>
<p>Read&#x2F;Write Through（读穿 &#x2F; 写穿）策略原则是应用程序只和缓存交互，不再和数据库交互，而是由缓存和数据库交互，相当于更新数据库的操作由缓存自己代理了。</p>
<p><em><strong>1、Read Through 策略</strong></em></p>
<p>先查询缓存中数据是否存在，如果存在则直接返回，如果不存在，则由缓存组件负责从数据库查询数据，并将结果写入到缓存组件，最后缓存组件将数据返回给应用。</p>
<p><em><strong>2、Write Through 策略</strong></em></p>
<p>当有数据更新的时候，先查询要写入的数据在缓存中是否已经存在：</p>
<ul>
<li>如果缓存中数据已经存在，则更新缓存中的数据，并且由缓存组件同步更新到数据库中，然后缓存组件告知应用程序更新完成。</li>
<li>如果缓存中数据不存在，直接更新数据库，然后返回；</li>
</ul>

                    
                        


                    
                    
                        <p>
                            <a
                                href="/2023/10/09/Redis/#post-footer"
                                class="postShorten-excerpt_link link"
                                aria-label=""
                            >
                                Kommentieren und teilen
                            </a>
                        </p>
                    
                </div>
            
        </div>
        
    </article>
    
    
    <article class="postShorten postShorten--thumbnailimg-bottom">
        <div class="postShorten-wrap">
            
            <div class="postShorten-header">
                <h1 class="postShorten-title">
                    
                        <a
                            class="link-unstyled"
                            href="/2023/09/30/shua/"
                            aria-label=": Java刷题"
                        >
                            Java刷题
                        </a>
                    
                </h1>
                <div class="postShorten-meta">
    <time datetime="2023-09-30T00:00:00+08:00">
	
		    30 Sep 2023
    	
    </time>
    
        <span>in </span>
        
    <a class="category-link" href="/categories/Java/">Java</a>


    
</div>

            </div>
            
                <div class="postShorten-content">
                    <h2 id="TIPS"><a href="#TIPS" class="headerlink" title="TIPS"></a>TIPS</h2><p>注意Integer和Int，基础和引用的&#x3D;&#x3D;是不一样的，在此基础上形成的stack vector，List也是这样</p>
<h2 id="递归"><a href="#递归" class="headerlink" title="递归"></a><strong>递归</strong></h2><p>递归判断两个值是否相等或者对称这种题目，或者先判断两个空，然后判断一个空</p>
<p>if (root1 &#x3D;&#x3D; null &amp;&amp; root2 &#x3D;&#x3D; null) 两个都为空的情况</p>
<p>if(root1 &#x3D;&#x3D; null || root2 &#x3D;&#x3D; null || root1.val !&#x3D; root2.val) 一个为空的情况</p>
<p>结束条件判断中，建议判断已知的。</p>
<p>结束标志一般一个是null，一个是结束值。</p>
<p>递归中的凭据，如果是多个数组、Treenode、链表，用坐标也许会很麻烦，可以先尝试原本的类型，比如数组，就用子数组。因为数组如果用坐标判断长度是不是0会比较麻烦</p>
<p><img src="/../images/shua/image-20231001132922742.png" alt="image-20231001132922742"></p>
<p>如果能做一次这种就好了</p>
<p>递归函数体一般分三部分</p>
<p>1、结束</p>
<p>2、主要函数操作，比如visit【】&#x3D;true</p>
<p>3、列举 dfs</p>
<p>如果是两个匹配，可以用被匹配的长度作为结束判断条件之一,比如两个字符都匹配完，某个字符匹配完某个字符没有匹配完</p>
<h2 id="动态规划"><a href="#动态规划" class="headerlink" title="动态规划"></a>动态规划</h2><p>状态定义：</p>
<p>状态转移函数：</p>
<p>状态初始化 如果是两个数组，那辅助表就是二维数组，最好比原来的宽长都多1位 </p>
<p>前面（第零列或者第零行 或者两个都）可能需要初始化</p>
<p>然后真正匹配的是从1到n；</p>

                    
                        


                    
                    
                        <p>
                            <a
                                href="/2023/09/30/shua/#post-footer"
                                class="postShorten-excerpt_link link"
                                aria-label=""
                            >
                                Kommentieren und teilen
                            </a>
                        </p>
                    
                </div>
            
        </div>
        
    </article>
    
    
    <article class="postShorten postShorten--thumbnailimg-bottom">
        <div class="postShorten-wrap">
            
            <div class="postShorten-header">
                <h1 class="postShorten-title">
                    
                        <a
                            class="link-unstyled"
                            href="/2023/09/08/Java%E5%B9%B6%E5%8F%91/"
                            aria-label=": Java并发知识"
                        >
                            Java并发知识
                        </a>
                    
                </h1>
                <div class="postShorten-meta">
    <time datetime="2023-09-08T00:00:00+08:00">
	
		    08 Sep 2023
    	
    </time>
    
        <span>in </span>
        
    <a class="category-link" href="/categories/Java/">Java</a>


    
</div>

            </div>
            
                <div class="postShorten-content">
                    <p><strong>偏向锁</strong></p>
<p>java对象头后三位是101，然后把对象头的偏向线程id改为自己就好就代表自己获得了锁。当偏向锁的获取出现竞争，则偏向锁可能会升级为轻量级锁。</p>
<p>线程查看若锁标志位是为01，如果是01，并且偏向锁标志1的话。不是1直接升级轻量级，是1的话我们去看threadid，如果是本线程id，那就获得锁。如果不是，这时候CAS操作尝试将mark word的threadid改成线程A的id，如果当前threadid是0，那就替换成功获得锁，如果是线程B的id。这时候要去撤销偏向锁。先查看线程b的存活状态，如果存活并且还在执行，那就升级为轻量级，如果未存活或者没有在执行，那么我们就尝试重偏向。可以的话就让threadid偏向我们线程A，否则升级为轻量级锁。</p>
<p>偏向锁适合无竞争、竞争小的场景，理想的情况为总是由同一个线程去访问同步块、获取某个对象的锁。</p>
<p><strong>轻量级锁</strong></p>
<p>轻量级锁由偏向锁升级而来，特点是获取轻量级锁的是通过CAS原子操作进行的，失败的线程不会进入阻塞，而是自旋尝试再次CAS去获取锁。若失败的次数过多，则轻量级锁会膨胀为重量级锁。因为自旋也是要消耗cpu的，不能让线程一直自旋下去。</p>
<p>根据这些，可以看出 轻量级锁最适合场景是追求响应时间的情景，理想的情况是少量线程交替访问同步块、获取锁。若多个线程访问同步块的时间重合的比骄密集就会发生很多自旋造成cpu资源浪费。</p>
<p>1、无锁可以直接加锁，关于markword的初始状态0|01<br> 1、1 在当前线程的栈帧中创建锁记录<br> 1、2 将锁对象中的markword复制到锁记录中<br> 1、3 通过CAS方式将markword设置成指向锁记录的指针。<br>2、有锁状态下<br>  2、1如果是当前线程持有的轻量级锁，说明是可重入锁，由于每次获取轻量级锁都会创建一个锁记录，所以，除第一次锁记录存储markword外，后面均设置为null。<br>  2、2如果不是当前线程持有的锁，说明出现锁竞争，可能需要锁升级</p>
<p><strong>重量级锁</strong></p>
<p>重量级锁是轻量级锁受到激烈竞争时，为防止cpu被自旋的线程浪费膨胀而来，因此重量级锁肯定是应付大量线程同时访问同步块的情景。让申请锁失败的线程阻塞后，cpu的负担会减小不少，因此数据的吞吐量也就上来了。</p>
<h2 id="JAVA内存模型"><a href="#JAVA内存模型" class="headerlink" title="JAVA内存模型"></a>JAVA内存模型</h2><p>JMM定义了线程和主线程之间的抽奖关系。涉及到内存屏障 重排序等问题。它的基本方针就是：正确同步的情况下，尽可能为处理器打开方面之门。没有正确同步的情况下不保证执行结果和顺序一致性是一样的。</p>
<p>对于程序员来说，直接能感触到的是happers-before规则，包括程序规则、锁规则、volatile规则。而JMM实现这些规则依靠的就是处理器的重排序规则（禁止重排序）。重排序是一种优化性能的手段。它要求前一个操作的结果对后一个操作可见并且在前一个操作按顺序排在后一个操作前。</p>
<h2 id="Volatile"><a href="#Volatile" class="headerlink" title="Volatile"></a>Volatile</h2><p>我们可以从三个角度出发了解它。分别是本身的特性，内存语义，和内存语义的实现</p>
<p><strong>特性：</strong>得益于happensbefore规则，对一个volatile的读，总能看到对这个volatile最后的写入。</p>
<p><strong>内存语义：</strong></p>
<p>volatile写：当写一个volatile变量，jmm会把该线程对应的本地内存中共享变量刷新到主内存</p>
<p>volatile读：当读一个volatile变量，jmm会把该线程对应的本地内存置为无效，然后存主内存里面读</p>
<p><strong>内存语义的实现</strong></p>
<p>重排序分为编译器重排序和处理器重排序。</p>
<p>编译器方面有这么一个规定</p>
<p><img src="/../images/%E5%B9%B6%E5%8F%91/image-20230919132522971.png" alt="image-20230919132522971"></p>
<p>当第二个操作是volatile写时，不管第一个操作是什么，都不能重排序。这个规则确保volatile写之前的操作不会被编译器重排序到volatile写之后。</p>
<p>当第一个操作是volatile读时，不管第二个操作是什么，都不能重排序。这个规则确保volatile读之后的操作不会被编译器重排序到volatile读之前。</p>
<p>当第一个操作是volatile写，第二个操作是volatile读时，不能重排序。</p>
<p>为了实现这些语义，比那一起在生成字节码的时候会插入内存屏障。</p>
<ul>
<li>在每个volatile写操作的前面插入一个StoreStore屏障。</li>
<li>在每个volatile写操作的后面插入一个StoreLoad屏障。</li>
<li>在每个volatile读操作的后面插入一个LoadLoad屏障。</li>
<li>在每个volatile读操作的后面插入一个LoadStore屏障。</li>
</ul>
<h2 id="锁"><a href="#锁" class="headerlink" title="锁"></a><strong>锁</strong></h2><p>happendbefore<strong>规则</strong>：</p>
<p>对一个锁的解锁，happensbefore于随后对它的加锁</p>
<p><strong>锁的内存语义</strong></p>
<p>释放锁的时候，jmm把该线程对应的本地内存中的共享变量刷新到主内存，加锁的时候把该线程对应的本地内存置为无效。</p>
<p>ps：锁和volatile是一样的内存语义</p>
<p><strong>锁内存语义的实现</strong></p>
<p>分为公平锁和非公平锁</p>
<p>ReentrantLock的实现依赖于AbstractQueuedSynchronizer（AQS），AQS使用一个整形的volatile变量（state）来维护同步状态。这个volatile变量是ReentrantLock实现的关键。</p>
<p>　　编译器<strong>不会对volatile读与其后的任意内存操作重排序</strong>，<strong>不会对volatile写与其前的任意操作重排序</strong>。AQS提供了compareAndSetState()方法来对state进行原子操作。CAS同时具有volatile读和写的内存语义，编译器<strong>不会对CAS前和后的任意内存操作重排序</strong>，其是通过底层处理器缓存锁定实现原子性的。</p>
<p>CAS同时具有volatile读和写的内存语义，故Java线程之间的通信存在4种方式：</p>
<p>　　① A线程写volatile变量，随后B线程读该变量；</p>
<p>　　② A线程写volatile变量，随后B线程使用CAS更新该变量；</p>
<p>　　③ A线程使用CAS更新volatile变量，随后B线程使用CAS更新该变量；</p>
<p>　　④ A线程使用CAS更新volatile变量，随后B线程读该变量。</p>
<p>公平锁在释放锁的最后写volatile变量state，在获取锁的时候先读volatile变量，根据先行发生原则释放锁的线程对volatile变量的写，必须对volatile变量的读可见，也就是上节讲的volatile的可见性，所以公平锁本质是通过volatile变量和AQS（这里暂时不对AbstractQueuedSynchronizer讲解）来实现同步的；</p>
<h2 id="AQS"><a href="#AQS" class="headerlink" title="AQS"></a>AQS</h2><p>本质是一个抽象类，用来构造锁或其他同步组件的基础框架</p>
<p>用state表示同步状态（volatile）	</p>
<p>用一个同步队列来管理同步状态fifo双向队列，当线程获取同步状态失败，那就把这个线程和等待状态等信息狗造成一个节点加入同步队列，并且阻塞。</p>
<p>独占式，线程调用tryacquire获取同步状态，如果获取同步状态失败的话构造同步节点将该节点通过CAS加入到同步队列尾部，并处于死循环。</p>
<p>共享式和独占式最大的区别就局势同一时刻能够多个线程获取到同步状态</p>
<h2 id="ReentrantLock原理"><a href="#ReentrantLock原理" class="headerlink" title="ReentrantLock原理"></a>ReentrantLock原理</h2><p>用这个之前需要先创建 ReentrantLock 对象，然后使用 lock 方法进行加锁，使用完之后再调用 unlock 方法释放锁</p>
<p><strong>synchronized 是 JVM 层面通过监视器（Monitor）实现的，而 ReentrantLock 是通过 AQS（AbstractQueuedSynchronizer）程序级别的 API 实现</strong></p>
<p>这里涉及到aqs的两种实现一个公平锁一个非公平锁，她们两个的区别是，我的线程入栈的时候，公平锁直接往队列的末尾去加，非公平锁先看下我能不能通过cas的方式获得到锁，如果获取不到，这个时候我要进行入栈。入栈的时候也会判断一下，当前这个栈头是不是和我这个线程的id是一致的，如果是一致的，那我就获得到锁。</p>
<p>用state表示同步状态，state&#x3D;0表示初始状态可以占有锁，state&#x3D;1表示已有线程占有，大于1是重入锁。</p>
<p>用一个同步队列来管理同步状态fifo双向队列，</p>
<p>解锁的时候将state减一，看其是否为0，如果是的话将空闲标志置为true，将持有锁的线程设置为null。然后设置state。当这个线程已经没有持有state的时候就要唤醒下一个节点。</p>
<h2 id="公平锁和非公平锁"><a href="#公平锁和非公平锁" class="headerlink" title="公平锁和非公平锁"></a>公平锁和非公平锁</h2><p><strong>锁 synchronized 和 ReentrantLock 默认都是非公平锁，当然我们在创建 ReentrantLock 时，可以手动指定其为公平锁</strong></p>
<p><strong>每个线程获取锁的顺序是按照线程访问锁的先后顺序获取的，最前面的线程总是最先获取到锁。</strong> </p>
<p>公平锁和非公平锁有两个判断的区别，非公平锁在acquire的之前会先用CAS的方式获取锁，拿不到我就走正常的逻辑。还有一个判断是tryacquire的时候，里面有一个步骤是获取同步状态时候，如果这个同步状态是0的话，说明现在没人拿，我可以去直接去拿，公平锁这里会多一个判断，会先看看自己是不是排队的第一个，如果不是的话，我就不抢占state了。如果state等于当前线程，说明当前线程已经持有锁的，触发可重入功能。如果没拿到就那就把这个线程和等待状态等信息狗造成一个节点加入同步队列，并且阻塞。</p>
<h2 id="synchronized"><a href="#synchronized" class="headerlink" title="synchronized"></a>synchronized</h2><p><strong>特性</strong></p>
<p>原子性</p>
<p><strong>可见性</strong>	</p>
<ol>
<li>线程解锁前，必须把共享变量的最新值刷新到主内存中。</li>
<li>线程加锁前，将清空工作内存中共享变量的值，从而使用共享变量时需要从主内存<br>中重新读取最新的值。</li>
<li>volatile 的可见性都是通过内存屏障（Memnory Barrier）来实现的。</li>
<li>synchronized 靠操作系统内核的Mutex Lock（互斥锁）实现，相当于 JMM 中的 lock、unlock。退出代码块时刷新变量到主内存。</li>
</ol>
<p><strong>实现原理</strong></p>
<blockquote>
<p>jvm基于进入和退出Monitor对象来实现方法同步和代码块同步</p>
</blockquote>
<p>方法级的同步是隐式，即无需通过字节码指令来控制的，它实现在方法调用和返回操作之中。JVM可以从方法常量池中的方法表结构中的 ACC_SYNCHRONIZED 访问标志区分一个方法是否同步方法。当方法调用时，调用指令将会常量池里面检查方法的 ACC_SYNCHRONIZED 访问标志是否被设置，如果设置了，执行线程将先持有monitor（虚拟机规范中用的是管程一词）， 然后再执行方法，方法完成释放monitor。</p>
<p>代码块的同步是利用monitorenter和monitorexit这两个字节码指令。它们分别位于同步代码块的开始和结束位置。当jvm执行到monitorenter指令时，当前线程试图获取monitor对象的所有权，如果未加锁或者已经被当前线程所持有，就把锁的计数器+1；当执行monitorexit指令时，锁计数器-1；当锁计数器为0时，该锁就被释放了。如果获取monitor对象失败，该线程则会进入阻塞状态，直到其他线程释放锁。</p>
<p><strong>synchronized的底层实现</strong></p>
<p>是完全依赖JVM虚拟机的,所以谈synchronized的底层实现，就不得不谈数据在JVM内存的存储：Java对象头，以及Monitor对象监视器。</p>
<p>HotSpot 虚拟机中，对象在内存中存储的布局可以分为三块区域：对象头（Header）、<br>实例数据（Instance Data）和对齐填充（Padding）。</p>
<p>对象头一般有两部分：Mark Word和对象类型数据的指针</p>
<p>Mark Word如哈希码（HashCode）、GC分代年龄、锁状态标志、线程持有的锁、偏向线程 ID、偏向时间戳等等,它是实现轻量级锁和偏向锁的关键.</p>
<p>我们发现当对象头中<code>锁状态</code>为<strong>重量级锁</strong>时，<strong>对象头的MarkWord存储了指向堆中的Monitor对象的指针</strong></p>
<p>monitor由ObjectMonitor实现，他有两个队列，一个是waitset一个是entrylist，用来保存 等待锁的线程	</p>
<p>_owner指向持有ObjectMonitor对象的线程，当多个线程同时访问一段同步代码时，首先会进入 _EntryList 集合，当线程获取到对象的monitor 后把monitor中的owner变量设置为当前线程同时monitor中的计数器count加1，若线程调用 wait() 方法，将释放当前持有的monitor，owner变量恢复为null，count自减1，同时该线程进入 WaitSe t集合中等待被唤醒。若当前线程执行完毕也将释放monitor(锁)并复位变量的值，以便其他线程进入获取monitor(锁)。</p>
<p>前面已经分析了Monitor的机制，那么在Java中是如何实现的呢？<br><strong>即通过synchronized关键字实现线程同步来获取对象的Monitor。</strong><br>实现方式为：<strong>ACC_SYNCHRONIZED和monitorenter&#x2F;monitorexit</strong> *ACC_SYNCHRONIZED标识符会去隐式调用这两个指令：monitorenter和monitorexit</p>

                    
                        


                    
                    
                        <p>
                            <a
                                href="/2023/09/08/Java%E5%B9%B6%E5%8F%91/#post-footer"
                                class="postShorten-excerpt_link link"
                                aria-label=""
                            >
                                Kommentieren und teilen
                            </a>
                        </p>
                    
                </div>
            
        </div>
        
    </article>
    
    
    <article class="postShorten postShorten--thumbnailimg-bottom">
        <div class="postShorten-wrap">
            
            <div class="postShorten-header">
                <h1 class="postShorten-title">
                    
                        <a
                            class="link-unstyled"
                            href="/2023/08/07/Java%E5%9F%BA%E7%A1%80%E7%9F%A5%E8%AF%86/"
                            aria-label=": Java基础知识"
                        >
                            Java基础知识
                        </a>
                    
                </h1>
                <div class="postShorten-meta">
    <time datetime="2023-08-07T00:00:00+08:00">
	
		    07 Aug 2023
    	
    </time>
    
        <span>in </span>
        
    <a class="category-link" href="/categories/Java/">Java</a>


    
</div>

            </div>
            
                <div class="postShorten-content">
                    <h2 id="讲讲Java的代理"><a href="#讲讲Java的代理" class="headerlink" title="讲讲Java的代理"></a>讲讲Java的代理</h2><p>代理分成静态代理和动态代理，静态代理需要自己实现对每一个方法对代理，那么如果新增一个方法，那就要手动修改目标对象代理对象的代码，非常繁琐。动态代理更加灵活，不需要你一个一个的对方法进行代理。</p>
<p>动态代理就是运行的时候生成class。这个DynamicProxy其实就是一个Proxy，</p>
<p>动态代理有两种方式一种是jdk方法，一种是cglib方法</p>
<p><strong>我们先来讲jdk代理：</strong></p>
<p>首先，代理是一个代理类代理真正的对象去帮助你做一些操作，可以在原本的方法前后加一些操作。那代理类就需要一个执行器去帮你做这些事情，那这个执行器就是InvocationHandler接口，他只有一个invoke方法，三个参数是代理类，被代理方法，方法参数组</p>
<p>这三个参数里面代理方法和参数组其实我们可以依赖于最基础反射得到。而jdk代理又必须要实现InvocationHandler接口，而这个接口他又有这么三个参数，而这三个参数其实是可以变化的，被代理类被代理方法参数组是可以变化的，那这样就成功的实现了动态的代理。</p>
<p>那我们怎么去调用这个方法呢？依赖于Proxy类和他的方法newproxyInstance，得到的代理类，调用方法其实会直接调用我们实现InvocationHandler接口的invoke方法</p>
<p><strong>下面来讲CGLIB代理</strong></p>
<p><strong>在 CGLIB 动态代理机制中 <code>MethodInterceptor</code> 接口和 <code>Enhancer</code> 类是核心。你可以通过 <code>Enhancer</code>类来动态获取被代理类，</strong></p>
<p>  CGLIB 通过动态生成一个需要被代理类的子类（即被代理类作为父类），该子类重写被代理类的所有不是 final 修饰的方法，每次调用代理类的方法都会被方法<a target="_blank" rel="noopener" href="https://so.csdn.net/so/search?q=%E6%8B%A6%E6%88%AA%E5%99%A8&spm=1001.2101.3001.7020">拦截器</a>拦截，在拦截器中才是调用目标类的该方法的逻辑。所以我们说，当代理类调用方法的时候，实际调用的是 <code>MethodInterceptor</code> 中的 <code>intercept</code> 方法。</p>
<p>为什么JDK动态代理只能代理接口实现类，原因是JDK动态代理是基于接口实现的。</p>
<p>有两个原因，一个是继承Proxy。第二个是当你使用Proxy类创建代理对象时，你需要指定一个接口列表来表示理对象的类型。代理对象的类型是由接口列表决定的，因此只有实现了接口的类才能被代理。如果你想代理一个类而不是一个接口，你需要使用其他的代理技术，比如CGLIB。</p>
<p><strong>二者区别</strong><br>总结一下两者的区别吧：</p>
<p>JDK 动态代理基于接口，CGLIB 动态代理基于类。因为 JDK 动态代理生成的代理类需要继承 java.lang.reflect.Proxy，所以，只能基于接口；CGLIB 动态代理是根据类创建此类的子类，所以，此类不能被 final 修饰<br>JDK 和 CGLIB 动态代理都是在运行期生成字节码。而 JDK 是直接写 Class 字节码；而 CGLIB 使用 ASM 框架写 Class 字节码（不鼓励直接使用ASM，因为它要求你必须对 JVM 内部结构包括 class 文件的格式和指令集都很熟悉）<br>JDK 通过反射调用方法，CGLIB 通过 FastClass 机制（下一篇再将）直接调用方法。所以，CGLIB 执行的效率较高<br>JDK 核心是实现 InvocationHandler接口，使用 invoke()方法进行面向切面的处理，调用相应的通知；CGLIB 动态代理是利用 asm 开源包，对代理对象类的 class 文件加载进来，通过修改其字节码生成子类来处理。核心是实现 MethodInterceptor 接口，使用 intercept() 方法进行面向切面的处理，调用相应的通知。</p>
<h1 id="集合"><a href="#集合" class="headerlink" title="集合"></a>集合</h1><p>重点是list和map，其中list比较简单，map需要重点掌握</p>
<h2 id="ArrayList-插入和删除元素的时间复杂度？"><a href="#ArrayList-插入和删除元素的时间复杂度？" class="headerlink" title="ArrayList 插入和删除元素的时间复杂度？"></a>ArrayList 插入和删除元素的时间复杂度？</h2><p>对于插入：</p>
<ul>
<li>头部插入：由于需要将所有元素都依次向后移动一个位置，因此时间复杂度是 O(n)。</li>
<li>尾部插入：当 <code>ArrayList</code> 的容量未达到极限时，往列表末尾插入元素的时间复杂度是 O(1)，因为它只需要在数组末尾添加一个元素即可；当容量已达到极限并且需要扩容时，则需要执行一次 O(n) 的操作将原数组复制到新的更大的数组中，然后再执行 O(1) 的操作添加元素。</li>
<li>指定位置插入：需要将目标位置之后的所有元素都向后移动一个位置，然后再把新元素放入指定位置。这个过程需要移动平均 n&#x2F;2 个元素，因此时间复杂度为 O(n)。</li>
</ul>
<p>对于删除：</p>
<ul>
<li>头部删除：由于需要将所有元素依次向前移动一个位置，因此时间复杂度是 O(n)。</li>
<li>尾部删除：当删除的元素位于列表末尾时，时间复杂度为 O(1)。</li>
<li>指定位置删除：需要将目标元素之后的所有元素向前移动一个位置以填补被删除的空白位置，因此需要移动平均 n&#x2F;2 个元素，时间复杂度为 O(n)。</li>
</ul>
<h2 id="LinkedList-插入和删除元素的时间复杂度？"><a href="#LinkedList-插入和删除元素的时间复杂度？" class="headerlink" title="LinkedList 插入和删除元素的时间复杂度？"></a>LinkedList 插入和删除元素的时间复杂度？</h2><ul>
<li>头部插入&#x2F;删除：只需要修改头结点的指针即可完成插入&#x2F;删除操作，因此时间复杂度为 O(1)。</li>
<li>尾部插入&#x2F;删除：只需要修改尾结点的指针即可完成插入&#x2F;删除操作，因此时间复杂度为 O(1)。</li>
<li>指定位置插入&#x2F;删除：需要先移动到指定位置，再修改指定节点的指针完成插入&#x2F;删除，因此需要移动平均 n&#x2F;2 个元素，时间复杂度为 O(n)。</li>
</ul>
<h2 id="ArrayList-与-LinkedList-区别"><a href="#ArrayList-与-LinkedList-区别" class="headerlink" title="ArrayList 与 LinkedList 区别?"></a>ArrayList 与 LinkedList 区别?</h2><p> <strong>是否保证线程安全：</strong> <code>ArrayList</code> 和 <code>LinkedList</code> 都是不同步的，也就是不保证线程安全；</p>
<p><strong>底层数据结构：</strong> <code>ArrayList</code> 底层使用的是 <strong><code>Object</code> 数组</strong>；<code>LinkedList</code> 底层使用的是 <strong>双向链表</strong> 数据结构（JDK1.6 之前为循环链表，JDK1.7 取消了循环。注意双向链表和双向循环链表的区别，下面有介绍到！）</p>
<p>**插入和删除是否受元素位置的影响：</p>
<p><strong>插入和删除是否受元素位置的影响：</strong></p>
<p><strong>是否支持快速随机访问：</strong> <code>LinkedList</code> 不支持高效的随机元素访问，而 <code>ArrayList</code>（实现了 <code>RandomAccess</code> 接口） 支持。快速随机访问就是通过元素的序号快速获取元素对象(对应于<code>get(int index)</code>方法)。</p>
<p><strong>内存空间占用：</strong> <code>ArrayList</code> 的空间浪费主要体现在在 list 列表的结尾会预留一定的容量空间，而 LinkedList 的空间花费则体现在它的每一个元素都需要消耗比 ArrayList 更多的空间（因为要存放直接后继和直接前驱以及数据）</p>
<h2 id="ArrayList扩容机制"><a href="#ArrayList扩容机制" class="headerlink" title="ArrayList扩容机制"></a>ArrayList扩容机制</h2><p>首先有三种初始化方式，无参数（空数组，没有分配空间），有数量参数，collections的列表（Arrays.copyOf）</p>
<p>再者讲一下扩容机制，add函数先会经历一次ensurecapacityInternal，确保容量能达到指定的最小容量，当容量不足的时候将新容量更新为旧容量的1.5倍，新容量是否大于最小需要容量，若还是小于最小需要容量，那么就把最小需要容量当作数组的新容量。如果minCapacity大于最大容量，则新容量则为<code>Integer.MAX_VALUE</code>，否则，新容量大小则为 MAX_ARRAY_SIZE 即为 <code>Integer.MAX_VALUE - 8</code></p>
<p>ps</p>
<ul>
<li>Java 中的 <code>length</code>属性是针对数组说的,比如说你声明了一个数组,想知道这个数组的长度则用到了 length 这个属性.</li>
<li>Java 中的 <code>length()</code> 方法是针对字符串说的,如果想看这个字符串的长度则用到 <code>length()</code> 这个方法.</li>
<li>Java 中的 <code>size()</code> 方法是针对泛型集合说的,如果想看这个泛型有多少个元素,就调用此方法来查看!</li>
</ul>
<h2 id="元素排序-Comparable-和-Comparator-有什么区别？"><a href="#元素排序-Comparable-和-Comparator-有什么区别？" class="headerlink" title="元素排序 Comparable 和 Comparator 有什么区别？"></a>元素排序 Comparable 和 Comparator 有什么区别？</h2><p>Comparable 接口只有一个方法 compareTo，实现 Comparable 接口并重写 compareTo 方法就可以实现某个类的排序了，它支持 Collections.sort 和 Arrays.sort 的排序。compareTo 方法接收的参数 p 是要对比的对象，排序规则是用当前对象和要对比的对象进行比较，然后返回一个 int 类型的值。正序从小到大的排序规则是：使用当前的对象值减去要对比对象的值；而倒序从大到小的排序规则刚好相反：是用对比对象的值减去当前对象的值。</p>
<p>Comparator 除了可以通过创建自定义比较器外，还可以通过<a target="_blank" rel="noopener" href="https://so.csdn.net/so/search?q=%E5%8C%BF%E5%90%8D%E7%B1%BB&spm=1001.2101.3001.7020">匿名类</a>的方式，更快速、便捷的完成自定义比较器的功能，具体的代码实现如下：</p>
<p>Comparable 必须由自定义类内部实现排序方法，而 Comparator 是外部定义并实现排序的</p>
<h2 id="比较-HashSet、LinkedHashSet-和-TreeSet-三者的异同"><a href="#比较-HashSet、LinkedHashSet-和-TreeSet-三者的异同" class="headerlink" title="比较 HashSet、LinkedHashSet 和 TreeSet 三者的异同"></a>比较 HashSet、LinkedHashSet 和 TreeSet 三者的异同</h2><ul>
<li><code>HashSet</code>、<code>LinkedHashSet</code> 和 <code>TreeSet</code> 都是 <code>Set</code> 接口的实现类，都能保证元素唯一，并且都不是线程安全的。</li>
<li><code>HashSet</code>、<code>LinkedHashSet</code> 和 <code>TreeSet</code> 的主要区别在于底层数据结构不同。<code>HashSet</code> 的底层数据结构是哈希表（基于 <code>HashMap</code> 实现）。<code>LinkedHashSet</code> 的底层数据结构是链表和哈希表，元素的插入和取出顺序满足 FIFO。<code>TreeSet</code> 底层数据结构是红黑树，元素是有序的，排序的方式有自然排序和定制排序。</li>
<li>底层数据结构不同又导致这三者的应用场景不同。<code>HashSet</code> 用于不需要保证元素插入和取出顺序的场景，<code>LinkedHashSet</code> 用于保证元素的插入和取出顺序满足 FIFO 的场景，<code>TreeSet</code> 用于支持对元素自定义排序规则的场景。</li>
</ul>
<h2 id="Queue-与-Deque-的区别"><a href="#Queue-与-Deque-的区别" class="headerlink" title="Queue 与 Deque 的区别"></a>Queue 与 Deque 的区别</h2><p><code>Queue</code> 是单端队列，只能从一端插入元素，另一端删除元素，实现上一般遵循 <strong>先进先出（FIFO）</strong> 规则。</p>
<p><code>Deque</code> 是双端队列，在队列的两端均可以插入或删除元素。</p>
<p><code>Deque</code> 扩展了 <code>Queue</code> 的接口, 增加了在队首和队尾进行插入和删除的方法</p>
<h2 id="ArrayDeque-与-LinkedList-的区别"><a href="#ArrayDeque-与-LinkedList-的区别" class="headerlink" title="ArrayDeque 与 LinkedList 的区别"></a>ArrayDeque 与 LinkedList 的区别</h2><p><code>ArrayDeque</code> 和 <code>LinkedList</code> 都实现了 <code>Deque</code> 接口，两者都具有队列的功能，但两者有什么区别呢？</p>
<ul>
<li><code>ArrayDeque</code> 是基于可变长的数组和双指针来实现，而 <code>LinkedList</code> 则通过链表来实现。</li>
<li><code>ArrayDeque</code> 不支持存储 <code>NULL</code> 数据，但 <code>LinkedList</code> 支持。</li>
<li><code>ArrayDeque</code> 插入时可能存在扩容过程, 不过均摊后的插入操作依然为 O(1)。虽然 <code>LinkedList</code> 不需要扩容，但是每次插入数据时均需要申请新的堆空间，均摊性能相比更慢。</li>
</ul>
<p>从性能的角度上，选用 <code>ArrayDeque</code> 来实现队列要比 <code>LinkedList</code> 更好。此外，<code>ArrayDeque</code> 也可以用于实现栈。</p>
<h3 id="什么是-BlockingQueue？"><a href="#什么是-BlockingQueue？" class="headerlink" title="什么是 BlockingQueue？"></a>什么是 BlockingQueue？</h3><p><code>BlockingQueue</code> （阻塞队列）是一个接口，继承自 <code>Queue</code>。<code>BlockingQueue</code>阻塞的原因是其支持当队列没有元素时一直阻塞，直到有元素；还支持如果队列已满，一直等到队列可以放入新元素时再放入。<code>BlockingQueue</code> 常用于生产者-消费者模型中，生产者线程会向队列中添加数据，而消费者线程会从队列中取出数据进行处理。</p>
<h1 id="Hashmap："><a href="#Hashmap：" class="headerlink" title="Hashmap："></a>Hashmap：</h1><h2 id="HashMap-和-Hashtable-的区别"><a href="#HashMap-和-Hashtable-的区别" class="headerlink" title="HashMap 和 Hashtable 的区别"></a>HashMap 和 Hashtable 的区别</h2><ul>
<li><strong>线程是否安全：</strong><code>HashMap</code> 是非线程安全的，<code>Hashtable</code> 是线程安全的,因为 <code>Hashtable</code> 内部的方法基本都经过<code>synchronized</code> 修饰。（如果你要保证线程安全的话就使用 <code>ConcurrentHashMap</code> 吧！）</li>
<li><strong>效率：</strong> 因为线程安全的问题，<code>HashMap</code> 要比 <code>Hashtable</code> 效率高一点。另外，<code>Hashtable</code> 基本被淘汰，不要在代码中使用它；</li>
<li><strong>初始容量大小和每次扩充容量大小的不同：</strong> ① 创建时如果不指定容量初始值，<code>Hashtable</code> 默认的初始大小为 11，之后每次扩充，容量变为原来的 2n+1。<code>HashMap</code> 默认的初始化大小为 16。之后每次扩充，容量变为原来的 2 倍。② 创建时如果给定了容量初始值，那么 <code>Hashtable</code> 会直接使用你给定的大小，而 <code>HashMap</code> 会将其扩充为 2 的幂次方大小（<code>HashMap</code> 中的<code>tableSizeFor()</code>方法保证，下面给出了源代码）。也就是说 <code>HashMap</code> 总是使用 2 的幂作为哈希表的大小,后面会介绍到为什么是 2 的幂次方。</li>
<li><strong>底层数据结构：</strong> JDK1.8 以后的 <code>HashMap</code> 在解决哈希冲突时有了较大的变化，当链表长度大于阈值（默认为 8）时，将链表转化为红黑树（将链表转换成红黑树前会判断，如果当前数组的长度小于 64，那么会选择先进行数组扩容，而不是转换为红黑树），以减少搜索时间（后文中我会结合源码对这一过程进行分析）。<code>Hashtable</code> 没有这样的机制。</li>
<li><strong>相比于<code>HashMap</code>来说 <code>TreeMap</code> 主要多了对集合中的元素根据键排序的能力以及对集合内元素的搜索的能力</strong></li>
</ul>
<h2 id="HashMap-的底层实现"><a href="#HashMap-的底层实现" class="headerlink" title="HashMap 的底层实现"></a>HashMap 的底层实现</h2><p>JDK1.8 之前 <code>HashMap</code> 底层是 <strong>数组和链表</strong> 结合在一起使用也就是 <strong>链表散列</strong>。相比于之前的版本， JDK1.8 之后在解决哈希冲突时有了较大的变化，当链表长度大于阈值（默认为 8）（将链表转换成红黑树前会判断，如果当前数组的长度小于 64，那么会选择先进行数组扩容，而不是转换为红黑树）时，将链表转化为红黑树，以减少搜索时间</p>
<p>HashMap 通过 key 的 <code>hashcode</code> 经过扰动函数处理过后得到 hash 值，然后通过 <code>(n - 1) &amp; hash</code> 判断当前元素存放的位置（这里的 n 指的是数组的长度），如果当前位置存在元素的话，就判断该元素与要存入的元素的 hash 值以及 key 是否相同，如果相同的话，直接覆盖，不相同就通过拉链法解决冲突。</p>
<p><code>HashMap</code> 链表到红黑树的转换。</p>
<p><strong>1、 <code>putVal</code> 方法中执行链表转红黑树的判断逻辑。</strong></p>
<p>链表的长度大于 8 的时候，就执行 <code>treeifyBin</code> （转换红黑树）的逻辑。</p>
<p><strong><code>treeifyBin</code> 方法中判断是否真的转换为红黑树。</strong></p>
<h2 id="HashMap-的长度为什么是-2-的幂次方"><a href="#HashMap-的长度为什么是-2-的幂次方" class="headerlink" title="HashMap 的长度为什么是 2 的幂次方"></a>HashMap 的长度为什么是 2 的幂次方</h2><p>我们首先可能会想到采用%取余的操作来实现。但是，重点来了：<strong>“取余(%)操作中如果除数是 2 的幂次则等价于与其除数减一的与(&amp;)操作（也就是说 hash%length&#x3D;&#x3D;hash&amp;(length-1)的前提是 length 是 2 的 n 次方；）。”</strong> 并且 <strong>采用二进制位操作 &amp;，相对于%能够提高运算效率，这就解释了 HashMap 的长度为什么是 2 的幂次方。</strong>1111最后一位是1，散列平均</p>
<h2 id="HashMap-多线程操作导致死循环问题"><a href="#HashMap-多线程操作导致死循环问题" class="headerlink" title="HashMap 多线程操作导致死循环问题"></a>HashMap 多线程操作导致死循环问题</h2><p>扩容问题和头插法问题</p>
<p>假设两个线程同时对hashmap进行扩容，这时候两个都指向首节点A，后面的节点分别是bcd。</p>
<p>那么这时候线程1正常执行，线程2卡住了。但是A执行完后因为是头插法所以abc变成了cba，但是问题就在与线程2还是从a指向b，这样子就出现了问题。一个是c指向b指向a，一个是a指向 b。</p>
<p>解决的方法：concurrenthashmap，推荐；hashtable安全，不建议；或者直接加锁，也不建议。或者头插法改成尾插法。</p>
<h2 id="HashMap-为什么线程不安全？"><a href="#HashMap-为什么线程不安全？" class="headerlink" title="HashMap 为什么线程不安全？"></a>HashMap 为什么线程不安全？</h2><p>一方面就是多线程操作导致的死循环问题。</p>
<p>另一方面就是两个线程 1,2 进行 put 操作，线程1 、执行的时候通过判断发现没有出发hash碰撞，但是时间片用完了挂起，这时候线程2也判断有没有hash碰撞发现没有，因为线程1还没来得及插入。这时候线程2插入一个b值结束了，线程1重新获得时间片，因为之前已经成功判断过了，所以直接插入一个a值，那么这样b值就被a值覆盖了。</p>
<h2 id="Hashmap代码"><a href="#Hashmap代码" class="headerlink" title="Hashmap代码"></a>Hashmap代码</h2><p><strong>loadFactor 负载因子</strong></p>
<p>loadFactor 负载因子是控制数组存放数据的疏密程度，loadFactor 越趋近于 1，那么 数组中存放的数据(entry)也就越多，也就越密，也就是会让链表的长度增加，loadFactor 越小，也就是趋近于 0，数组中存放的数据(entry)也就越少，也就越稀疏。</p>
<p><strong>loadFactor 太大导致查找元素效率低，太小导致数组的利用率低，存放的数据会很分散。loadFactor 的默认值为 0.75f 是官方给出的一个比较好的临界值</strong>。</p>
<p>给定的默认容量为 16，负载因子为 0.75。Map 在使用过程中不断的往里面存放数据，当数量超过了 16 * 0.75 &#x3D; 12 就需要将当前 16 的容量进行扩容，而扩容这个过程涉及到 rehash、复制数据等操作，所以非常消耗性能。</p>
<h2 id="hashmap插入"><a href="#hashmap插入" class="headerlink" title="hashmap插入"></a>hashmap插入</h2><p>扰动函数的得到散列值，将 hash 值右移16位（hash值的高16位）与 原 hash 值做异或运算（^），从而得到一个新的散列值</p>
<p>如果定位到的数组位置没有元素 就直接插入。</p>
<p>如果定位到的数组位置有元素就和要插入的 key 比较，如果 key 相同就直接覆盖，如果 key 不相同，就判断 p 是否是一个树节点，如果是就调用<code>e = ((TreeNode&lt;K,V&gt;)p).putTreeVal(this, tab, hash, key, value)</code>将元素添加进入。</p>
<p>如果不是就遍历链表插入(插入的是链表尾部)，并查看连标长度是不是大于等于8且数组长度是不是大于64，如果是的话转化成红黑树，如果链表长度大于等于8，数组长度小于64，那么先不转成红黑树，先扩容。</p>
<h2 id="hashmap扩容过程"><a href="#hashmap扩容过程" class="headerlink" title="hashmap扩容过程"></a>hashmap扩容过程</h2><p>首先判断扩容，插入数据后，如果容量大于threshold（容量*负载因子），则进行扩容；<br>获取当前容量，若当前容量大于0，并且大于MAXIMUM_CAPACITY &#x3D; 1 &lt;&lt; 30，则不进行扩容，将 threshold &#x3D; Integer.MAX_VALUE进行赋值。<br>否则创建新的数组，将容量进行两倍扩大，threshold也进行两倍扩容,下面截取部分源码；</p>
<p>扩容后将旧数组的元素进行迁移到新数组上，通过尾插法进行插入到新数组中新的位置。</p>
<p>扩容简单来说就是做了两件事。1：创建一个新数组，原来的两倍大。2：把旧数组的元素放入到新数组中</p>
<p>遍历老数组的每个槽位；<br>如果槽位中是一个普通节点，则将节点放在新数组中，所在新数组中的下标计算方式为：e.hash &amp; (newCap - 1);<br>如果槽位中是一个树节点，则进行红黑树的迁移操作，新数组中下标计算方式同普通节点；<br>如果槽位中是一个链表节点，则将链表拆为高位链表和低位链表，分别放入新数组的旧数组的下标位置和 （旧数组下标 + 旧数组容量）下标位置；<br>最后返回新数组。</p>
<h2 id="ConcurrentHashMap-和-Hashtable-的区别"><a href="#ConcurrentHashMap-和-Hashtable-的区别" class="headerlink" title="ConcurrentHashMap 和 Hashtable 的区别"></a>ConcurrentHashMap 和 Hashtable 的区别</h2><p><strong>实现线程安全的方式（重要）：</strong></p>
<p>在 JDK1.7 的时候，<code>ConcurrentHashMap</code> 对整个桶数组进行了分割分段(<code>Segment</code>，分段锁)，每一把锁只锁容器其中一部分数据（下面有示意图），多线程访问容器里不同数据段的数据，就不会存在锁竞争，提高并发访问率。</p>
<p>到了 JDK1.8 的时候，<code>ConcurrentHashMap</code> 已经摒弃了 <code>Segment</code> 的概念，而是直接用 <code>Node</code> 数组+链表+红黑树的数据结构来实现，并发控制使用 <code>synchronized</code> 和 CAS 来操作。（JDK1.6 以后 <code>synchronized</code> 锁做了很多优化） 整个看起来就像是优化过且线程安全的 <code>HashMap</code>，虽然在 JDK1.8 中还能看到 <code>Segment</code> 的数据结构，但是已经简化了属性，只是为了兼容旧版本；</p>
<p><strong><code>Hashtable</code>(同一把锁)</strong> :使用 <code>synchronized</code> 来保证线程安全，效率非常低下。当一个线程访问同步方法时，其他线程也访问同步方法，可能会进入阻塞或轮询状态，如使用 put 添加元素，另一个线程不能使用 put 添加元素，也不能使用 get，竞争会越来越激烈效率越低。</p>
<h2 id="ConcurrentHashMap"><a href="#ConcurrentHashMap" class="headerlink" title="ConcurrentHashMap"></a><strong>ConcurrentHashMap</strong></h2><p><code>ConcurrentHashMap</code>是线程安全的，<code>ConcurrentHashMap</code>并非锁住整个方法，而是通过原子操作和局部加锁的方法保证了多线程的线程安全，且尽可能减少了性能损耗</p>
<p>想要解析concurrenthashmap，我从他的底层具体原理和实际的代码层面讲一讲。</p>
<p>底层具体原理方面：</p>
<p><code>ConcurrentHashMap</code> 取消了 <code>Segment</code> 分段锁，采用 <code>Node + CAS + synchronized</code> 来保证并发安全。数据结构跟 <code>HashMap</code> 1.8 的结构类似，数组+链表&#x2F;红黑二叉树。Java 8 在链表长度超过一定阈值（8）时将链表（寻址时间复杂度为 O(N)）转换为红黑树（寻址时间复杂度为 O(log(N))）。</p>
<p>Java 8 中，锁粒度更细，<code>synchronized</code> 只锁定当前链表或红黑二叉树的首节点，这样只要 hash 不冲突，就不会产生并发，就不会影响其他 Node 的读写，效率大幅提升。</p>
<p>具体的代码层面：</p>
<p>代码层面做插入操作的时候</p>
<p>做插入操作时，<br>首先初始化则初始化容器，<br>如果已经初始化，则判断该hash位置的节点是否为空，如果为空，则通过CAS操作进行插入。<br>如果该节点不为空，再判断容器是否在扩容中，如果在扩容，则帮助其扩容。<br>如果没有扩容，则进行最后一步，先加锁，然后找到hash值相同的那个节点(hash冲突)，<br>循环判断这个节点上的链表，决定做覆盖操作还是插入操作。<br>循环结束，插入完毕。</p>

                    
                        


                    
                    
                        <p>
                            <a
                                href="/2023/08/07/Java%E5%9F%BA%E7%A1%80%E7%9F%A5%E8%AF%86/#post-footer"
                                class="postShorten-excerpt_link link"
                                aria-label=""
                            >
                                Kommentieren und teilen
                            </a>
                        </p>
                    
                </div>
            
        </div>
        
    </article>
    
    
    <article class="postShorten postShorten--thumbnailimg-bottom">
        <div class="postShorten-wrap">
            
            <div class="postShorten-header">
                <h1 class="postShorten-title">
                    
                        <a
                            class="link-unstyled"
                            href="/2023/07/08/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C%E5%A4%8D%E4%B9%A01/"
                            aria-label=": 计算机网络复习1"
                        >
                            计算机网络复习1
                        </a>
                    
                </h1>
                <div class="postShorten-meta">
    <time datetime="2023-07-08T00:00:00+08:00">
	
		    08 Jul 2023
    	
    </time>
    
        <span>in </span>
        
    <a class="category-link" href="/categories/Java/">Java</a>


    
</div>

            </div>
            
                <div class="postShorten-content">
                    <p>计算机网络整体的学习可以按照tcpip网络模型进行学习。我们的总结也是这样的</p>
<p>Tcp&#x2F;ip网络模型分别是应用层、传输层、网络层、数据链路层</p>
<p>这里面前三层比较重要，数据链路层复杂的方面涉及实际的物理知识所以我们只对逻辑思想上做一个学习，</p>
<p>那每一层分别学的是什么呢？</p>
<p>应用层：http  https tls</p>
<p>传输层：tcp udp </p>
<p>网络层：ipv4 v6</p>
<p>基本上就是这样子</p>
<p>TCP 连接传输协议，这是传输层的，很多应用层的协议在传输层都是使用这个的，比如http</p>
<p>那tcp和udp的差距是，tcp相比udp多了很多为了可靠的连接所增加的特性，比如流量控制，超时重传，拥塞控制，就是为了数据能可靠的传到对方，但是过程中究竟是请求-应答模式还是什么模式，那就是后面的不同版本做出的更新。</p>
<p>udp他不在乎这个数据究竟有没有到对面，只负责发送，所以实时性号，效率高。但是他并不是不能做到可靠传输，因为udp只是传输层，我们还可以在应用层做出一定的限制来保证传输是可靠的，比如quic协议，当然这是困难的。</p>
<p>除此之外，还有一个很大的不同就是tcp是会分片的，但是udp是不会分片。在这里我们还要知道的一点是在网络层，也就是ip协议中还是会分片的，MTU。但是对于tcp来说因为你要是在ip层才分片，我为了保证可靠，我假设12345 丢了一个2，那我就要12345全部重新发，这样不好，所以我们就在tcp层也分片，大小是mss。而udp不用可靠，所以他不用分片。</p>
<p>网络层，主要的作用其实就是路由和寻址，加上ip头，规定好源ip，目的ip等信息，</p>
<p>网络接口层，是提供链路级别的传输服务，因为源ip和目的ip知道了，但是在以太网中实际上是不行的，IP会变，我们需要一个确切的信息，这个就是mac地址，</p>
<p>那我们这里用输入网址到显示，来串联一下整体的流程：</p>
<h4 id="1、解析url"><a href="#1、解析url" class="headerlink" title="1、解析url"></a>1、解析url</h4><p>解析之后得到三个信息，一个协议，一个是web服务器地址，一个是请求文件的路径（可选）</p>
<p>那对于我们前两个是最重要的，</p>
<p>这时候我们客户端生产自己的http请求报文，格式如下，方法get，url没有默认index什么的，版本http1.1，字段名就很多，然后是数据，这个数据也是后面一种包装的根数据。</p>
<p><img src="/../images/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C%E5%A4%8D%E4%B9%A01/image-20230728193306158.png" alt="image-20230728193306158">	</p>
<p>如图所示，一个是请求一个是响应报文</p>
<p>到这里消息成功生产，那我们生产出一个消息之后就要开始发送？那应该怎么发？往哪里发？</p>
<p>这就需要下面的知识。</p>
<h2 id="地址查询-——-DNS"><a href="#地址查询-——-DNS" class="headerlink" title="地址查询 —— DNS"></a>地址查询 —— DNS</h2><p>基于我们已经拿到的web服务器域名，我们可以先去浏览器缓存里面找有没有，如果有，就直接返回，如果没有那就问操作系统的缓存再去看hosts文件，如果都没有，那就看走下面</p>
<p>客户端首先会发出一个 DNS 请求，问 <a target="_blank" rel="noopener" href="http://www.xx.com/">www.xx.com</a> 的 IP 是啥，发给本地 DNS 服务器（也就是客户端的 TCP&#x2F;IP 设置中填写的 DNS 服务器地址）。</p>
<p>本地域名服务器收到客户端的请求后，如果缓存里的表格能找到 <a target="_blank" rel="noopener" href="http://www.xx.com,则它直接返回/">www.xx.com，则它直接返回</a> IP 地址。如果没有，本地 DNS 会去问它的根域名服务器：“老大， 能告诉我 <a target="_blank" rel="noopener" href="http://www.xx.com/">www.xx.com</a> 的 IP 地址吗？” 根域名服务器是最高层次的，它不直接用于域名解析，但能指明一条道路。</p>
<p>根 DNS 收到来自本地 DNS 的请求后，发现后置是 .com，说：“<a target="_blank" rel="noopener" href="http://www.xx.com/">www.xx.com</a> 这个域名归 .com 区域管理”，我给你 .com 顶级域名服务器地址给你，你去问问它吧。”</p>
<p>本地 DNS 收到顶级域名服务器的地址后，发起请求问“老二， 你能告诉我 <a target="_blank" rel="noopener" href="http://www.xx.com/">www.xx.com</a> 的 IP 地址吗？”</p>
<p>顶级域名服务器说：“我给你负责 <a target="_blank" rel="noopener" href="http://www.xx.com/">www.xx.com</a> 区域的权威 DNS 服务器的地址，你去问它应该能问到”。</p>
<p>本地 DNS 于是转向问权威 DNS 服务器：“老三，<a href="http://www.xx.com对应的IP是啥呀？”">www.xx.com对应的IP是啥呀？”</a> server.com 的权威 DNS 服务器，它是域名解析结果的原出处。为啥叫权威呢？就是我的域名我做主。</p>
<p>权威 DNS 服务器查询后将对应的 IP 地址 X.X.X.X 告诉本地 DNS。</p>
<p>本地 DNS 再将 IP 地址返回客户端，客户端和目标建立连接</p>
<p><img src="/../images/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C%E5%A4%8D%E4%B9%A01/image-20230728193808617.png" alt="image-20230728193808617"></p>
<p>通过dns或者缓存获取到ip地址之后，我们就要为发送做一些准备，首先浏览器通过调用 Socket 库，来委托协议栈工作。</p>
<p><img src="/../images/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C%E5%A4%8D%E4%B9%A01/image-20230728193955912.png" alt="image-20230728193955912"></p>
<p>说是协议栈，其实就是中间tcp udp ip这些协议。那下面我们就来仔细的看看</p>
<h2 id="TCP"><a href="#TCP" class="headerlink" title="TCP"></a>TCP</h2><p>tcp段的头如下所示：</p>
<p><img src="/../images/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C%E5%A4%8D%E4%B9%A01/image-20230728194108402.png" alt="image-20230728194108402"></p>
<p>TCP 传输数据之前，要先三次握手建立连接</p>
<p>前提：客户端 为closed状态，服务端变成listen状态</p>
<p>连接：</p>
<p>1、客户端向服务端发送连接syn，之后客户端处于syn-sent状态；</p>
<p>2、服务端接收到这个消息之后，会返回一个syn+ack，之后服务端处于syn-rcvd状态</p>
<p>3、客户端收到这个之后，再给服务端发送一个对syn的ack，之后客户端处于establish状态</p>
<p>服务端收到ack也变成了establish状态</p>
<p>所以三次握手目的是<strong>保证双方都有发送和接收的能力</strong>。</p>
<p>假设我们已经建立了连接，我们要发送消息，但是消息要遵循tcp协议，他的消息大小是有限制的，不是每一次都可以发送全部消息。具体要求如下：</p>
<p><img src="/../images/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C%E5%A4%8D%E4%B9%A01/image-20230728195857751.png" alt="image-20230728195857751"></p>
<ul>
<li><code>MTU</code>：一个网络包的最大长度，以太网中一般为 <code>1500</code> 字节。</li>
<li><code>MSS</code>：除去 IP 和 TCP 头部之后，一个网络包所能容纳的 TCP 数据的最大长度</li>
</ul>
<p>所以如果http请求消息超过mss，那么就要分段发送。</p>
<p>到这里我们得到了一个tcp的报文段或者说包，下面我们就要把这个包发送给网络层，因为在传输层我们就是服务应用层，然后对好端口，确定好协议，之后的事情就不归传输层管控了。</p>
<p>到这里，我们的数据包的格式如下所示：</p>
<p><img src="/../images/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C%E5%A4%8D%E4%B9%A01/image-20230728200405680.png" alt="image-20230728200405680"></p>
<h2 id="定位IP"><a href="#定位IP" class="headerlink" title="定位IP"></a>定位IP</h2><p>ip协议的最重要的功能就是寻址和路由，他要做到这两点就需要你遵循ip协议，那么遵循的要求就是你加一个ip头<img src="/../images/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C%E5%A4%8D%E4%B9%A01/image-20230728200452235.png" alt="image-20230728200452235"></p>
<p>加上ip头之后我们就知道了我们的源ip和目的ip地址，那么起点站和终点站就已经知道了</p>
<p>可以现在又有一个小问题，那就是路径怎么规划呢？这时候就需要用到Mac地址</p>
<h2 id="mac地址"><a href="#mac地址" class="headerlink" title="mac地址"></a>mac地址</h2><p><img src="/../images/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C%E5%A4%8D%E4%B9%A01/image-20230728202408619.png" alt="image-20230728202408619"></p>
<ul>
<li>先查询 ARP 缓存，如果其中已经保存了对方的 MAC 地址，就不需要发送 ARP 查询，直接使用 ARP 缓存中的地址。</li>
<li>而当 ARP 缓存中不存在对方 MAC 地址时，则发送 ARP 广播查询</li>
</ul>
<p>也就是说到了网络接口层，要发了，结果不知道往哪里发，这时候就按照上面两步得到mac地址</p>
<p>因为上面已经得到了ip地址，所以直接喊话：这个 IP 地址是谁的？请把你的 MAC 地址告诉我，就得到mac地址了。</p>
<p>到这里数据包还差最后一层包装</p>
<h2 id="出口–网卡"><a href="#出口–网卡" class="headerlink" title="出口–网卡"></a>出口–网卡</h2><p><img src="/../images/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C%E5%A4%8D%E4%B9%A01/image-20230728204942674.png" alt="image-20230728204942674"></p>
<p>最后一层包装就是上面图片提到的报头和起始帧分界符和fcs帧校验序列</p>
<p>网卡驱动获取网络包之后，会将其<strong>复制</strong>到网卡内的缓存区中，接着会在其<strong>开头加上报头和起始帧分界符，在末尾加上用于检测错误的帧校验序列</strong>。</p>
<p>到这里数据包就真正的包装结束了，最后网卡会将包转为电信号，通过网线发送出去。！！</p>
<h2 id="送别者—交换机"><a href="#送别者—交换机" class="headerlink" title="送别者—交换机"></a>送别者—交换机</h2><p>交换机的设计是将网络包<strong>原样</strong>转发到目的地。交换机工作在 MAC 层，也称为<strong>二层网络设备</strong>。</p>
<p>一般在网线接口啊这些地方，其实路由器也可以作为交换机。</p>
<h3 id="交换机的包接收操作"><a href="#交换机的包接收操作" class="headerlink" title="交换机的包接收操作"></a>交换机的包接收操作</h3><p>交换机里的模块将电信号转换为数字信号。</p>
<p>然后通过包末尾的fcs校验错误，没问题就放到缓存区，这部分操作基本和计算机的网卡相同，但交换机的工作方式和网卡不同。</p>
<p>计算机的网卡本身具有 MAC 地址，并通过核对收到的包的接收方 MAC 地址判断是不是发给自己的，如果不是发给自己的则丢弃；相对地，交换机的端口不核对接收方 MAC 地址，而是直接接收所有的包并存放到缓冲区中。因此，和网卡不同，<strong>交换机的端口不具有 MAC 地址</strong>。</p>
<h3 id="查询MAC-地址表"><a href="#查询MAC-地址表" class="headerlink" title="查询MAC 地址表"></a>查询<strong>MAC 地址表</strong></h3><p>如果找到，就发送到相应的端口，如果找不到，那说明该mac地址的设备还没有向我们交换机发送过包，那这时候我们主动的向除了源端口的所有端口都发送一遍，因为后面的设备他自己都有检测功能，所以不需要担心</p>
<p>这时候要么就发送到位，要么就可能离开子网了，离开子网需要用到路由器</p>
<h2 id="出境大门–路由器"><a href="#出境大门–路由器" class="headerlink" title="出境大门–路由器"></a>出境大门–路由器</h2><h3 id="路由器的包接收操作"><a href="#路由器的包接收操作" class="headerlink" title="路由器的包接收操作"></a>路由器的包接收操作</h3><p>首先，电信号到达网线接口部分，路由器中的模块会将电信号转成数字信号，然后通过包末尾的 <code>FCS</code> 进行错误校验。</p>
<p>如果没问题则检查 MAC 头部中的<strong>接收方 MAC 地址</strong>，看看是不是发给自己的包，如果是就放到接收缓冲区中，否则就丢弃这个包。</p>
<p>完成包接收操作之后，路由器就会<strong>去掉</strong>包开头的 MAC 头部。</p>
<p><strong>MAC 头部的作用就是将包送达路由器</strong>，其中的接收方 MAC 地址就是路由器端口的 MAC 地址。因此，当包到达路由器之后，MAC 头部的任务就完成了，于是 MAC 头部就会<strong>被丢弃</strong>。</p>
<p>接下来，路由器会根据 MAC 头部后方的 <code>IP</code> 头部中的内容进行包的转发操作。</p>
<h3 id="路由器的发送操作"><a href="#路由器的发送操作" class="headerlink" title="路由器的发送操作"></a>路由器的发送操作</h3><p>首先，我们需要根据<strong>路由表的网关列</strong>判断对方的地址。</p>
<ul>
<li>如果网关是一个 IP 地址，则这个IP 地址就是我们要转发到的目标地址，<strong>还未抵达终点</strong>，还需继续需要路由器转发。</li>
<li>如果网关为空，则 IP 头部中的接收方 IP 地址就是要转发到的目标地址，也是就终于找到 IP 包头里的目标地址了，说明<strong>已抵达终点</strong>。</li>
</ul>
<p>反正我们从路由表知道了ip地址，那么我们同样用这个地址去查mac地址</p>
<p>接下来是发送方 MAC 地址字段，这里填写输出端口的 MAC 地址。还有一个以太类型字段，填写 <code>0800</code> （十六进制）表示 IP 协议。</p>
<p>网络包完成后，接下来会将其转换成电信号并通过端口发送出去。这一步的工作过程和计算机也是相同的。</p>
<p>发送出去的网络包会通过<strong>交换机</strong>到达下一个路由器。由于接收方 MAC 地址就是下一个路由器的地址，所以交换机会根据这一地址将包传输到下一个路由器。</p>
<h1 id="例子"><a href="#例子" class="headerlink" title="例子"></a>例子</h1><p>这边举个例子<img src="/../images/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C%E5%A4%8D%E4%B9%A01/image-20230729000740012.png" alt="image-20230729000740012"></p>
<p>子网1某个设备想要发送数据给子网2的某个设备</p>
<p>首先源ip和目的ip是知道的，如果只是简单的arp群发这个ip问是谁的ip地址，其实是找不到的，所以判断是否为同一子网，如果不是，就把目的mac改成网关的mac，然后数据发送到网关，这时候官网一查mac地址，发现属于子网2的设备，这时候修改源mac为自己的mac，修改目的mac为设备的地址，从子网2的网卡发出。</p>
<p>大多数情况下一个子网的默认网关就是一个，就基本代表着出口。复杂情况就需要某种选择算法了</p>
<h2 id="Http"><a href="#Http" class="headerlink" title="Http"></a>Http</h2><p>下面我们来讲一下http 也叫超文本传输协议，就是两点之间超越普通文本范畴的文本（包括文本视频图片等等）的一种协议</p>
<h4 id="http常见状态码"><a href="#http常见状态码" class="headerlink" title="http常见状态码"></a>http常见状态码</h4><p>1XX 代表提示信息，表示这是处理的中间状体，后续还有操作</p>
<p>2XX 这个就是成功的状态吗</p>
<p>​	200 普通的正常的成功</p>
<p>​	204 没有body的成功，就是响应头里面没有body数据的意思</p>
<p>​	206 用于分快下载，断点续传，</p>
<p>3XX 代表重定向</p>
<p>​	 301 永久重定向</p>
<p>​	302 临时重定向</p>
<p>​	304缓存重定向，也就是配合协商缓存那一块</p>
<p>4XX 带表客户端的报文错误</p>
<p>​	400 比较笼统的</p>
<p>​	403 禁止范围</p>
<p>​	404 没找到</p>
<p>5XX 代表服务器端端报文错误</p>
<p>​	500 同样比较笼统</p>
<p>​	501 目前不支持</p>
<p>​	502 自身服务器没问题，后续转发的服务器有问题</p>
<p>​	503 请稍后再访问</p>
<h4 id="常见的字段"><a href="#常见的字段" class="headerlink" title="常见的字段"></a>常见的字段</h4><p>host</p>
<p>content-length</p>
<p>content-type</p>
<p>connection </p>
<p>content-encodeing</p>
<h4 id="Http缓存"><a href="#Http缓存" class="headerlink" title="Http缓存"></a>Http缓存</h4><p>包括强制缓存和协商缓存</p>
<p>强制缓存就是浏览器判断缓存没有过期，那我就直接使用浏览器的缓存</p>
<p>实现可以用两个响应头部的字段表示Cache-control和Expires，前者相对时间，后者绝对时间，前者优先级更高，更加精细</p>
<p>协商缓存也是有两种方法</p>
<p>1、请求头部里面的if modified since 和响应头部last- modified</p>
<p>先问浏览器缓存，如果没过期那就是强制缓存，如果过期了，响应信息的头部会有last modified，然后我们会带这个ifmodifiedsince：时间，去访问服务器，服务器看到之后，就拿自己的Last modified去对比 如果没改，返回304，如果改了，返回200</p>
<p>2、Etag 唯一标识</p>
<p>流程一样，但是etag优先级更高，因为 if modified since还是基于时间，而时间本身可能有一些限制。</p>
<p>1、有可能没有修改文件，但是文件的最后修改时间会变化</p>
<p>2、秒级以内的操作也许不能充分做出响应</p>
<h4 id="Http优缺点"><a href="#Http优缺点" class="headerlink" title="Http优缺点"></a>Http优缺点</h4><p>优点：简单，灵活易扩充，应用广泛跨平台</p>
<p>缺点：</p>
<p>1、http无状态的，所以导致一系列相联的操作可能每一次都要反问数据库，那就非常的繁琐</p>
<p>在此基础上出现了cookie技术，他就是通过在请求和响应报文里面增加cookie信息，来控制客户端的状态</p>
<p>2、明文传输。毫无隐私</p>
<p>3、不安全 也是最重要的原因</p>
<p>账号信息不安全</p>
<p>不验证对方的身份</p>
<p>无法证明报文的完整性</p>
<p>对于1.0改进：</p>
<p>1、http1.1在http1.0的基础上提出了长连接，之前是《请求-应答》模式就是你发完应答完，关闭连接，想要进行下一次通信，那就得重新建立连接，现在可以建立一次连接之后，就可以 发收发收发收 只要一方没有明确提出断开连接，那么就一直连着</p>
<p>2、管道通信，http1.1支持管道，就是所有请求都处于管道内部，我们可以发发发，而不需要等他先回复再发第二个，你可以发发发，减少了时间</p>
<p>但是这里有一个问题，http是基于tcp的所以服务端会按照顺序接收请求。</p>
<p>所以说，http1.1可以解决发送端的对头阻塞，但是无法解决接受端的对头阻塞</p>
<p>然而！然而！http1.1默认不开启管道，</p>
<h2 id="HTTPS"><a href="#HTTPS" class="headerlink" title="HTTPS"></a>HTTPS</h2><p>但是安全性的那三个缺点依旧无法得到改善，所以提出了https &#x3D; http + tls</p>
<p>https完美的解决了：窃听风险、篡改风险、冒充风险，其实就是（防止号不会没，内容数据不会被插入一些垃圾广告，访问的网站不是冒充）</p>
<p>所以给予上面这句话，我们可以知道tls他其实做了三件事情：信息加密，校验机制，身份证书</p>
<h3 id="TLS"><a href="#TLS" class="headerlink" title="TLS"></a>TLS</h3><h4 id="1、信息加密"><a href="#1、信息加密" class="headerlink" title="1、信息加密"></a>1、信息加密</h4><p>使用的是混合加密，采用对称加密和非对称加密的结合体，混合加密，就是两种都用到了，非对称加密是在tls握手的时候，对称加密是在传输数据的时候。</p>
<p>非对成加密安全，非对称加密速度更快。</p>
<h4 id="2、校验机制，身份证书，这两个可以一起讲"><a href="#2、校验机制，身份证书，这两个可以一起讲" class="headerlink" title="2、校验机制，身份证书，这两个可以一起讲"></a>2、校验机制，身份证书，这两个可以一起讲</h4><p>对内容先哈希算法，然后用私钥加密哈希结果得到的结果叫数字签名，把数字签名和原本的内容和在一起就相当于认证了</p>
<p>然后现在还是缺一个身份验证的问题，就是这个私钥到底对不对？</p>
<p>这时候需要一个权威机关，就叫CA</p>
<p>整体流程：服务器发送公钥和数字签名发到CA里面，CA用自己的私钥加密服务器的公钥和数字签名，这个就是证书！然后客户端发来请求的时候，服务器就把自己的证书发过去，客户端收到证书，用CA的公钥解密，得到了服务器的公钥和服务器的数字证签名，这个签名我们上面讲了一个是原始内容一个是私钥对于哈希值的加密，那我们怎么验证呢？就是用公钥去解密加密项得到一个哈希值，再对原始内容做同样的哈希操作，判断两个哈希值到底一不一样，一样代表认证成功，否则，认证失败。</p>
<h4 id="TLS的连接"><a href="#TLS的连接" class="headerlink" title="TLS的连接"></a>TLS的连接</h4><p>tls的密钥交换算法不同，那么连接步骤也不同，我们会介绍两种</p>
<h4 id="RSA"><a href="#RSA" class="headerlink" title="RSA"></a>RSA</h4><h5 id="1、客户端-gt-服务端。client-随机数-tls版本好-密码套件，密码套件可以说是一组配置的整合信息罢了"><a href="#1、客户端-gt-服务端。client-随机数-tls版本好-密码套件，密码套件可以说是一组配置的整合信息罢了" class="headerlink" title="1、客户端 &gt; 服务端。client 随机数 + tls版本好+密码套件，密码套件可以说是一组配置的整合信息罢了"></a>1、客户端 &gt; 服务端。client 随机数 + tls版本好+密码套件，密码套件可以说是一组配置的整合信息罢了</h5><h5 id="2、客户端-lt-服务端。server随机数-确认版本号-确认密码套件-自己的数字证书Done"><a href="#2、客户端-lt-服务端。server随机数-确认版本号-确认密码套件-自己的数字证书Done" class="headerlink" title="2、客户端 &lt; 服务端。server随机数+确认版本号+确认密码套件+自己的数字证书Done"></a>2、客户端 &lt; 服务端。server随机数+确认版本号+确认密码套件+自己的数字证书Done</h5><p>当然这里收到之后，先校验，校验流程如下：</p>
<p>首先我们知道了数字签名有原始内容和对于哈希值加密的数字签名，我们对原始内容加密（签名算法），对数字签名解密（CA公钥）</p>
<p>当然，其中有一个问题就是证书的信任问题？为什么？</p>
<p>因为我们得到的证书不一定是CA签发的，假如是中间机构签发的百度证书，那么我们就不能用内置的本地CA证书中的公钥去认证，所以我们先找签发机构，发现是一个中间机构，我们向中间机构请求证书，收到证书后发现这个机构的签发者是CA，那么我们可以用CA去认证中间的这个证书，这个证书被认证了 ，那么百度的也没认证了。</p>
<h4 id="3、客户端-gt-服务端-使用服务器的公钥加密pre-master随机数发给服务端"><a href="#3、客户端-gt-服务端-使用服务器的公钥加密pre-master随机数发给服务端" class="headerlink" title="3、客户端 &gt; 服务端 使用服务器的公钥加密pre-master随机数发给服务端"></a>3、客户端 &gt; 服务端 使用服务器的公钥加密pre-master随机数发给服务端</h4><h5 id="4、客户端-lt-服务端-服务端发送-加密算法改变通知，和握手结束通知"><a href="#4、客户端-lt-服务端-服务端发送-加密算法改变通知，和握手结束通知" class="headerlink" title="4、客户端 &lt; 服务端 服务端发送 加密算法改变通知，和握手结束通知"></a>4、客户端 &lt; 服务端 服务端发送 加密算法改变通知，和握手结束通知</h5><p>这样，两边就都有了三个随机数，算出会话密钥</p>
<p>之后的通信就用会话密钥了</p>
<p>上面这个就是RSA的基本流程，但是基于RSA的https依旧存在《前向安全》的问题，如果服务端私钥泄密，那么所有的tls通讯就将被破解</p>
<h4 id="ECDHE"><a href="#ECDHE" class="headerlink" title="ECDHE"></a>ECDHE</h4><p>1、客户端 &gt; 服务端。client Hello消息。随机数+tls版本好+密码套件。</p>
<p>2、客户端 &lt; 服务端。serverhello消息，随机数+确认版本号+确认密码套件。certificate消息（证书）。ServerKeyExchange消息（选择名为25519的椭圆曲线基点G，生成随机数作为私钥保留本地，用G点和私钥算出公钥，对公钥做签名）。Server Hello Done。</p>
<p>3、客户端 &gt; 服务端 校验证书，用服务端给的信息生成自己的公钥，发送client key exchange发给服务端</p>
<p>至此，双方都有各自的公钥，自己的私钥，曲线基点，所以能算出x</p>
<p>最终的会话密钥（客户端随机数，服务端随机数，x）</p>
<p>算好后，客户端会发一个change cipher spec，开始使用对成算法加密通信</p>
<p>接着，客户端再发一个excryted handshake message消息，把之前的摘要加密，让服务端做个验证。</p>
<p>4、最后，服务端也会有一个同样的操作，发「<strong>Change Cipher Spec</strong>」和「<strong>Encrypted Handshake Message</strong>」消息，如果双方都验证加密和解密没问题，那么握手正式完成。于是，就可以正常收发加密的 HTTP 请求和响应了。</p>
<p>RSA和ECDHE的区别</p>
<ul>
<li>RSA 密钥协商算法「不支持」前向保密，ECDHE 密钥协商算法「支持」前向保密；</li>
<li>使用了 RSA 密钥协商算法，TLS 完成四次握手后，才能进行应用数据传输，而对于 ECDHE 算法，客户端可以不用等服务端的最后一次 TLS 握手，就可以提前发出加密的 HTTP 数据，节省了一个消息的往返时间（这个是 RFC 文档规定的，具体原因文档没有说明，所以这点我也不太明白）；</li>
<li>使用 ECDHE， 在 TLS 第 2 次握手中，会出现服务器端发出的「Server Key Exchange」消息，而 RSA 握手过程没有该消息</li>
</ul>
<h4 id="https怎么实现数据的完整性？"><a href="#https怎么实现数据的完整性？" class="headerlink" title="https怎么实现数据的完整性？"></a>https怎么实现数据的完整性？</h4><p>刚才我们提到了TLS可以解决三个问题，包括完整性，</p>
<p>其实TLS在实现上包括了握手协议和记录协议</p>
<p>​	握手协议就是四次握手+后续加密来保护应用程序</p>
<p>​	记录协议负责保护数据的完整性和来源</p>
<p>所以我们来看记录协议：，他的实现就是负责对消息（http数据）的压缩，加密和数据认证<img src="/../images/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C%E5%A4%8D%E4%B9%A01/image-20230802185945107.png" alt="	"></p>
<p>这里还是应用层，消息被分割后进行压缩，加上消息验证码，加密，加密后加上一个报头，后面就是交给tcp层，传输层</p>
<h4 id="HTTPS一定安全吗"><a href="#HTTPS一定安全吗" class="headerlink" title="HTTPS一定安全吗"></a>HTTPS一定安全吗</h4><p>理论上这个协议是安全的，https其实就是加了个tls协议，那就是问这个tls是不是安全的</p>
<p>而tls就是按四次握手</p>
<p>1、第一种方法：返回的证书，他大概率是伪造的，但是我们如果叫接受了，那就不一样了，你接受了服务器的证书，相当于信任了，那后面的通信就会被监听</p>
<p>2、直接植入根证书也会导致这种情况</p>
<p>所以关键就是对于证书的认证</p>
<h3 id="http1-1-gt-http-2-gt-http3"><a href="#http1-1-gt-http-2-gt-http3" class="headerlink" title="http1.1  -&gt; http 2 -&gt; http3"></a>http1.1  -&gt; http 2 -&gt; http3</h3><h5 id="http1-1在http1-0的基础上增了长连接和管道，解决了发送方的对头阻塞"><a href="#http1-1在http1-0的基础上增了长连接和管道，解决了发送方的对头阻塞" class="headerlink" title="http1.1在http1.0的基础上增了长连接和管道，解决了发送方的对头阻塞"></a>http1.1在http1.0的基础上增了长连接和管道，解决了发送方的对头阻塞</h5><p>缺点：header是没有压缩的，只压缩了body部分，接收方会有对头阻塞，服务端智能被动响应</p>
<h5 id="http2在是基于https的，所以安全性肯定有保障"><a href="#http2在是基于https的，所以安全性肯定有保障" class="headerlink" title="http2在是基于https的，所以安全性肯定有保障"></a>http2在是基于https的，所以安全性肯定有保障</h5><p>1、头部压缩</p>
<p>http1.1报文是【header+body】对于body部分可以通过content- encoding指定比如gzip，但是http1.1对Header不做出处理</p>
<p>http2会压缩头部，如果同时发送多个请求，头是一样的化，协议就会帮你压缩消除重复的部分</p>
<p>这就是HPACK算法，HPACK包括三个部分（静态字典、动态字典、huffman编码）</p>
<p>2、二进制格式</p>
<p>http2不像是http1是纯文本的报文，而是全部改成了二进制，头部和数据题都是二进制，统称帧</p>
<p>3、并发传输，引入了流的机制</p>
<p>一条tcp连接有多个流，每个流可以包含一个或者多个message，这个message就是请求或者响应，message里面有一个或者多个frame帧，不同的http请求有独一无二的帧，所以可以乱序发送，后面会按照streamid组装，<strong>同一 Stream 内部的帧必须是严格有序的</strong></p>
<p>4、服务器主动推送</p>
<p>缺点：</p>
<p>他是基于tcp协议的，tcp是字节流，所以必须保证收到的数据是完整连续的，才会把数据交给应用，如果有一个数据卡住了，那么后面的流都要卡住，那就会触发超时重传，一个tcp连接的http请求都要等待的这个重传成功。</p>
<h5 id="http3，就把tcp换成了udp，但是为了可靠，推出了QUIC"><a href="#http3，就把tcp换成了udp，但是为了可靠，推出了QUIC" class="headerlink" title="http3，就把tcp换成了udp，但是为了可靠，推出了QUIC"></a>http3，就把tcp换成了udp，但是为了可靠，推出了QUIC</h5><p>1、没有对头阻塞</p>
<p>借鉴了http2的流，就是每一个流都有一个自己的滑动窗口，某个流内部的确还是会阻塞，但是各个流之间是相互独立的，一个流阻塞了，另外的流不会阻塞，这样就保证了没有对头阻塞</p>
<p>2、更快连接</p>
<p>因为http2里面tcp和tls是分层的先三次握手然后四次握手，这样需要3个rtt</p>
<p>然后在http3厘米quic内部适合tls一起的，而且只需要一个rtt就可以完成密钥的协商，用的是tls1.3，1.3版本有话了过程，就是说，第一次发送的时候就已经把签名算法、随机数都发给服务端了。</p>
<p>，甚至在第二次可以达到0rtt</p>
<p>3、连接迁移</p>
<p>tcp是四元组，而quic是基于dcp的，他是考连接id来标记通信，所以ip换了也没事</p>
<p>4、头部压缩变成了QPACK，静态表变成91项，动态编码方式换了，</p>
<h4 id="http1-1请求怎么优化"><a href="#http1-1请求怎么优化" class="headerlink" title="http1.1请求怎么优化"></a>http1.1请求怎么优化</h4><p>一方面是http发送的问题，一方面是他本身数据的问题</p>
<p>1、首先肯定是避免http请求：缓存技术</p>
<p>2、减少重定向，这个就是把重定向请求交给代理服务器</p>
<p>3、合并请求，就是把多个访问小文件的请求合并成一个大的</p>
<p>4、延迟发送，只访问看得到的资源</p>
<p>5、无损压缩，accept- encoding：gzip br </p>
<p>6、有损压缩，webP png</p>
<h4 id="https怎么优化"><a href="#https怎么优化" class="headerlink" title="https怎么优化"></a>https怎么优化</h4><p>https对于http多了一个tls，关键就是通过非对成加密握手得到对成加密的会话密钥</p>
<ul>
<li>提高cpu</li>
<li>升级linux </li>
<li>对密钥交换过程进行优化</li>
<li>RSA要四次握手，慢，安全性不高，我们可以缓存eche密钥交换算法，曲线选择x25519，对成加密算法，也可以换aes128</li>
<li>tls升级1.3，升级的地方在于hello和公钥交换两个消息合并成一个消息</li>
<li>证书优化，分为传输优化和验证优化。</li>
</ul>
<p>传输：服务器证书选择椭圆曲线</p>
<p>验证：验证的过程中不仅需要ca还需要是否被ca吊销；crl是吊销列表，ca定期更新，但是实时性不好，ocsp，向ca fan song请求，返回状态，这个增加了请求开销，万一网络不好或者ca繁忙就会出现延迟；oscp stapling，服务器向ca定期查证书状态，然后在握手阶段就直接发给客户端，这样客户端就不用再去请求了。</p>
<ul>
<li>会话复用：session id 和session ticket</li>
</ul>
<p>session id：首次连接后，在内存缓存会话密钥，用session id标识，再次连接的时候，会在hello消息中带上这个，服务器收到这个就从缓存里面找，直接回复会话状态，跳过中间流程</p>
<p>缺点是，内存压力大</p>
<p>session ticket：类似于cookie，把缓存的工作交给客户端，首次连接，会加密这个发给客户端缓存起来，第二次连接，客户端会发送ticket，服务器解密后验证日期是否有效，没问题就恢复会话。</p>

                    
                        


                    
                    
                        <p>
                            <a
                                href="/2023/07/08/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C%E5%A4%8D%E4%B9%A01/#post-footer"
                                class="postShorten-excerpt_link link"
                                aria-label=""
                            >
                                Kommentieren und teilen
                            </a>
                        </p>
                    
                </div>
            
        </div>
        
    </article>
    
    
    <article class="postShorten postShorten--thumbnailimg-bottom">
        <div class="postShorten-wrap">
            
            <div class="postShorten-header">
                <h1 class="postShorten-title">
                    
                        <a
                            class="link-unstyled"
                            href="/2023/07/08/MYSQL%E5%A4%8D%E4%B9%A01/"
                            aria-label=": Mysql复习1"
                        >
                            Mysql复习1
                        </a>
                    
                </h1>
                <div class="postShorten-meta">
    <time datetime="2023-07-08T00:00:00+08:00">
	
		    08 Jul 2023
    	
    </time>
    
        <span>in </span>
        
    <a class="category-link" href="/categories/Java/">Java</a>


    
</div>

            </div>
            
                <div class="postShorten-content">
                    <p>执行一个mysql语句会发生什么？</p>
<h3 id="连接器"><a href="#连接器" class="headerlink" title="连接器"></a>连接器</h3><p>你要有一个和数据库的连接，这时候，接待你的就是连接器</p>
<p>mysql -h ip -P port -u user -p</p>
<p>然后这个连接是tcp连接，所以会比较麻烦，那这样子的话，我就们尽量使用长连接</p>
<p>然而在mysql在执行过程中临时使用的内内存是管理在连接对象里面的，这些资源只有在连接断开的时候才会释放，如果长连接一直进行，可能导致内存占用过大，被系统强行杀掉OOM，可以考虑两种方式解决：</p>
<p>1、定期的断开长连接，比如在程序中加一个判断内存是否占用过大的查询</p>
<p>2、如果你用的是 MySQL 5.7 或更新版本，可以在每次执行一个比较大的操作后，通过执行 mysql_reset_connection 来重新初始化连接资源。这个过程不需要重连和重新做权限验证，但是会将连接恢复到刚刚创建完时的状态。</p>
<h3 id=""><a href="#" class="headerlink" title=""></a></h3><h3 id="查询缓存"><a href="#查询缓存" class="headerlink" title="查询缓存"></a>查询缓存</h3><p>8.0以后不用了，因为缓存命中率很低的，比如一条更新语句会使得缓存里面的所有相关的表全部失效，</p>
<h3 id="分析器"><a href="#分析器" class="headerlink" title="分析器"></a>分析器</h3><p>包括词法分析和语法分析</p>
<p>词法分析就是分析是什么，代表什么意思</p>
<p>语法分析就是分析符不符合语法要求</p>
<h3 id="优化器"><a href="#优化器" class="headerlink" title="优化器"></a>优化器</h3><p>优化器就是确定一个执行效率高的执行方案，比如选择索引、连接表的顺序等等</p>
<h3 id="执行器"><a href="#执行器" class="headerlink" title="执行器"></a>执行器</h3><p>真正的执行</p>
<p>但是更新操作还会涉及两个表的操作，一个是redo log 一个是binlog</p>
<p>这两种日志有以下三点不同。</p>
<ol>
<li>redo log 是 InnoDB 引擎特有的；binlog 是 MySQL 的 Server 层实现的，所有引擎都可以使用。</li>
<li>redo log 是物理日志，记录的是“在某个数据页上做了什么修改”；binlog 是逻辑日志，记录的是这个语句的原始逻辑，比如“给 ID&#x3D;2 这一行的 c 字段加 1 ”。</li>
<li>redo log 是循环写的，空间固定会用完；binlog 是可以追加写入的。“追加写”是指 binlog 文件写到一定大小后会切换到下一个，并不会覆盖以前的日志。</li>
</ol>
<p>这两个日志的配合是使用两阶段提交</p>
<p><img src="/Users/csen/Documents/Amusement/Sen-Blog/source/images/MYSQL1/image-20230805142953314.png" alt="image-20230805142953314"></p>
<p>可以发现将redo log的写入分成了两个阶段，一个是prepare 一个commit</p>
<p>在两阶段提交的情况下，是怎么实现崩溃恢复的呢？<br>首先比较重要的一点是，在写入redo log时，会顺便记录XID，即当前事务id。在写入binlog时，也会写入XID。</p>
<p>如果在写入redo log之前崩溃，那么此时redo log与binlog中都没有，是一致的情况，崩溃也无所谓。</p>
<p>如果在写入redo log prepare阶段后立马崩溃，之后会在崩恢复时，由于redo log没有被标记为commit。于是拿着redo log中的XID去binlog中查找，此时肯定是找不到的，那么执行回滚操作。</p>
<p>如果在写入binlog后立马崩溃，在恢复时，由redo log中的XID可以找到对应的binlog，这个时候直接提交即可。</p>
<p>总的来说，在崩溃恢复后，只要redo log不是处于commit阶段，那么就拿着redo log中的XID去binlog中寻找，找得到就提交，否则就回滚。</p>
<p>在这样的机制下，两阶段提交能在崩溃恢复时，能够对提交中断的事务进行补偿，来确保redo log与binlog的数据一致性。</p>
<h3 id="binlog-记录内容"><a href="#binlog-记录内容" class="headerlink" title="binlog 记录内容"></a>binlog <strong>记录内容</strong></h3><p>binlog应该说是Mysql里最核心的日志， 它记录了除了查询语句(select、show)之外的所有的 <code>DDL</code> 和 <code>DML</code> 语句,也就意味着我们基本上所有对数据库的操作变更都会记录到binlog里面。binlog以事件形式记录，不仅记录了操作的语句，同时还记录了语句所执行的消耗的时间。 binlog 有三种记录格式，分别是ROW、STATEMENT、MIXED。</p>
<p><strong>1、ROW：</strong> 基于变更的数据行进行记录，如果一个update语句修改一百行数据，那么这种模式下就会记录100行对应的记录日志。</p>
<p><strong>2、STATEMENT：</strong>基于SQL语句级别的记录日志，相对于ROW模式，STATEMENT模式下只会记录这个update 的语句。所以此模式下会非常节省日志空间，也避免着大量的IO操作。</p>
<p><strong>3、MIXED：</strong> 混合模式，此模式是ROW模式和STATEMENT模式的混合体，一般的语句修改使用statment格式保存binlog，如一些函数，statement无法完成主从复制的操作，则采用row格式保存binlog。</p>
<p>这三种模式需要注意的是：使用 row 格式的 binlog 时，在进行数据同步或恢复的时候不一致的问题更容易被发现，因为它是基于数据行记录的。而使用 mixed 或者 statement 格式的 binlog 时，很多事务操作都是基于SQL逻辑记录，我们都知道一个SQL在不同的时间点执行它们产生的数据变化和影响是不一样的，所以这种情况下，数据同步或恢复的时候就容易出现不一致的情况。</p>
<h2 id="锁"><a href="#锁" class="headerlink" title="锁"></a>锁</h2><h3 id="全局锁"><a href="#全局锁" class="headerlink" title="全局锁"></a>全局锁</h3><p>典型的使用场景就是做全库的逻辑备份，对所有的表进行 行锁定，从而获取一致性视图，保证数据的完整性。加了全局锁就是只能读</p>
<ul>
<li><p>一旦加了全局锁之后，其他的DDL、 DML全部都处于阻塞状态，但是可以执行DQL语句，也就是处于只读状态，而数据备份就是查询操作。 那么数据在进行逻辑备份的过程中，数据库中的数据就是不会发生变化的，这样就保证了数据的一致性 和完整性 .</p>
</li>
<li><p>语法</p>
<p>1、加全局锁</p>
<figure class="highlight sql"><table><tr><td class="code"><pre><span class="line">flush tables <span class="keyword">with</span> read lock;</span><br></pre></td></tr></table></figure>

<p>2、数据备份</p>
<figure class="highlight sql"><table><tr><td class="code"><pre><span class="line">mysqldump <span class="operator">-</span>uroot <span class="operator">-</span>pxxx db_name <span class="operator">-</span><span class="operator">&gt;</span> xxx.sql;</span><br></pre></td></tr></table></figure>

<p>3、释放锁</p>
<figure class="highlight sql"><table><tr><td class="code"><pre><span class="line">unlock tables;</span><br></pre></td></tr></table></figure></li>
</ul>
<h4 id="数据库中加全局锁，是一个比较重的操作，存在的问题有："><a href="#数据库中加全局锁，是一个比较重的操作，存在的问题有：" class="headerlink" title="数据库中加全局锁，是一个比较重的操作，存在的问题有："></a>数据库中加全局锁，是一个比较重的操作，存在的问题有：</h4><ul>
<li>如果在主库上备份，那么在备份期间都不能执行更新，业务基本上就得停摆。</li>
<li>如果在从库上备份，那么在备份期间从库不能执行主库同步过来的二进制日志（binlog），会导致主从延迟。</li>
</ul>
<p>在InnoDB引擎中，我们可以在备份时加上参数 –single-transaction 参数来完成不加锁的一致 性数据备份。</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">mysqldump --single-transaction -uroot -pxxx db_name -&gt; xxx.sql;</span><br><span class="line"></span><br></pre></td></tr></table></figure>

<h2 id="表级锁"><a href="#表级锁" class="headerlink" title="表级锁"></a>表级锁</h2><p>表级锁，主要分为3类：</p>
<ul>
<li>表锁</li>
<li>元数据锁（meta data lock，MDL）</li>
<li>意向锁</li>
</ul>
<p>表锁</p>
<p>对于表锁，又可以分为2类：</p>
<ul>
<li>表共享读锁（read lock）</li>
<li>表独占写锁（write lock）</li>
</ul>
<p>结论: 读锁不会阻塞其他客户端的读，但是会阻塞写。写锁既会阻塞其他客户端的读，又会阻塞 其他客户端的写。</p>
<h3 id="元数据锁"><a href="#元数据锁" class="headerlink" title="元数据锁"></a>元数据锁</h3><p>再来说说<strong>元数据锁</strong>（MDL）。</p>
<p>我们不需要显示的使用 MDL，因为当我们对数据库表进行操作时，会自动给这个表加上 MDL：</p>
<ul>
<li>对一张表进行 CRUD 操作时，加的是 <strong>MDL 读锁</strong>；</li>
<li>对一张表做结构变更操作的时候，加的是 <strong>MDL 写锁</strong>；</li>
</ul>
<p>MDL 是为了保证当用户对表执行 CRUD 操作时，防止其他线程对这个表结构做了变更。</p>
<p>当有线程在执行 select 语句（ 加 MDL 读锁）的期间，如果有其他线程要更改该表的结构（ 申请 MDL 写锁），那么将会被阻塞，直到执行完 select 语句（ 释放 MDL 读锁）。</p>
<p>反之，当有线程对表结构进行变更（ 加 MDL 写锁）的期间，如果有其他线程执行了 CRUD 操作（ 申请 MDL 读锁），那么就会被阻塞，直到表结构变更完成（ 释放 MDL 写锁）。</p>
<blockquote>
<p>MDL 不需要显示调用，那它是在什么时候释放的?</p>
</blockquote>
<p>MDL 是在事务提交后才会释放，这意味着<strong>事务执行期间，MDL 是一直持有的</strong>。</p>
<p>MDL 加锁过程是系统自动控制，无需显式使用，在访问一张表的时候会自动加上。MDL 锁主要作用是维 护表元数据的数据一致性，在表上有活动事务的时候，不可以对元数据进行写入操作。为了避免DML与 DDL冲突，保证读写的正确性。</p>
<h3 id="意向锁"><a href="#意向锁" class="headerlink" title="意向锁"></a>意向锁</h3><p>我觉得意向锁主要还是解决行锁和表锁之间的冲突问题。</p>
<ul>
<li>在使用 InnoDB 引擎的表里对某些记录加上「共享锁」之前，需要先在表级别加上一个「意向共享锁」；</li>
<li>在使用 InnoDB 引擎的表里对某些纪录加上「独占锁」之前，需要先在表级别加上一个「意向独占锁」；</li>
</ul>
<p>也就是，当执行插入、更新、删除操作，需要先对表加上「意向独占锁」，然后对该记录加行级独占锁。</p>
<p><img src="/../images/MYSQL%E5%A4%8D%E4%B9%A01/20e0f35589584352bd15e817668a0886.png" alt="img"></p>
<p><img src="/../images/MYSQL%E5%A4%8D%E4%B9%A01/6e6b275c2d6d4dfcbbb338be4f61bee9.png" alt="img"></p>
<p>所以，<strong>意向锁的目的是为了快速判断表里是否有记录被加锁</strong>。</p>
<h2 id="行锁"><a href="#行锁" class="headerlink" title="行锁"></a>行锁</h2><p>InnoDB实现了以下两种类型的行锁：</p>
<ul>
<li>共享锁（S）：允许一个事务去读一行，阻止其他事务获得相同数据集的排它锁。</li>
<li>排他锁（X）：允许获取排他锁的事务更新数据，阻止其他事务获得相同数据集的共享锁和排他 锁</li>
</ul>
<p><img src="/Users/csen/Documents/Amusement/Sen-Blog/source/images/MYSQL1/image-20230805221422216.png" alt="image-20230805221422216"></p>
<h1 id="隔离性与隔离级别"><a href="#隔离性与隔离级别" class="headerlink" title="隔离性与隔离级别"></a>隔离性与隔离级别</h1><p><a target="_blank" rel="noopener" href="https://blog.csdn.net/weixin_35794878/article/details/125741468">https://blog.csdn.net/weixin_35794878/article/details/125741468</a></p>
<p>事务就是要保证一组数据库操作，要么全部成功，要么全部失败。在 MySQL 中，事务支持是在引擎层实现的。你现在知道，MySQL 是一个支持多引擎的系统，但并不是所有的引擎都支持事务。比如 MySQL 原生的 MyISAM 引擎就不支持事务，这也是 MyISAM 被 InnoDB 取代的重要原因之一</p>
<p>在谈隔离级别之前，你首先要知道，你隔离得越严实，效率就会越低。因此很多时候，我们都要在二者之间寻找一个平衡点。SQL 标准的事务隔离级别包括：读未提交（read uncommitted）、读提交（read committed）、可重复读（repeatable read）和串行化（serializable ）。下面我逐一为你解释：</p>
<ul>
<li>读未提交是指，一个事务还没提交时，它做的变更就能被别的事务看到。</li>
<li>读提交是指，一个事务提交之后，它做的变更才会被其他事务看到。</li>
<li>可重复读是指，一个事务执行过程中看到的数据，总是跟这个事务在启动时看到的数据是一致的。当然在可重复读隔离级别下，未提交变更对其他事务也是不可见的。</li>
<li>串行化，顾名思义是对于同一行记录，“写”会加“写锁”，“读”会加“读锁”。当出现读写锁冲突的时候，后访问的事务必须等前一个事务执行完成，才能继续执行。</li>
</ul>
<h1 id="事务隔离的实现"><a href="#事务隔离的实现" class="headerlink" title="事务隔离的实现"></a>事务隔离的实现</h1><h2 id="实现隔离级别的方式："><a href="#实现隔离级别的方式：" class="headerlink" title="实现隔离级别的方式："></a>实现隔离级别的方式：</h2><p>事务有四个隔离级别</p>
<p><strong>一级封锁协议 (对应 read uncommited)</strong> 　<br>一级封锁协议是：事务在对需要修改的数据上面（就是在发生修改的瞬间）对其加共享锁（其他事务不能更改，但是可以读取-导致“脏读”），直到事务结束才释放。事务结束包括正常结束（COMMIT）和非正常结束（ROLLBACK）。</p>
<p><strong>二级封锁协议 （对应read commited)</strong>　<br>二级封锁协议是：1）事务在对需要更新的数据上（就是发生更新的瞬间）加排他锁（直到事务结束），防止其他事务读取未提交的数据，这样，也就避免了“脏读”的情况。2）事务对当前被读取的数据上面加共享锁（当读到时加上共享锁），一旦读完该行，立即释放该该行的共享锁-从数据库的底层实现更深入的来理解，既是，数据库会对游标当前的数据上加共享锁，但是当游标离开当前行的时候，立即释放该行的共享锁。</p>
<p><strong>三级封锁协议 （对应reapetable read ）</strong>（默认）<br>三级封锁协议是：二级封锁协议加上事务在读取数据的瞬间必须先对其加共享锁，但是直到事务结束才释放，这样保证了可重复读（既是其他的事务职能读取该数据，但是不能更新该数据）。</p>
<p><strong>最强封锁协议（对应Serialization)</strong><br>四级封锁协议是对三级封锁协议的增强，其实现机制也最为简单，直接对事务中所读取或者更改的数据所在的表加表锁，也就是说，其他事务不能读写该表中的任何数据。这样所有的脏读，不可重复读，幻读，都得以避免</p>
<h3 id="MVCC。"><a href="#MVCC。" class="headerlink" title="MVCC。"></a>MVCC。</h3><p><strong>MVCC</strong> 在 <strong>MySQL InnoDB</strong> 中的实现主要是为了提高数据库并发性能，用更好的方式去处理读-写冲突，做到即使有读写冲突时，也能做到不加锁，非阻塞并发读。可认为MVCC是行级锁的一个变种，但是它在很多情况下避免了加锁操作，因此额外开销更低。</p>
<p>什么是当前读和快照读？<br>在学习 MVCC 多版本并发控制之前，我们必须先了解一下，什么是 MySQL InnoDB 下的当前读和快照读?</p>
<p>当前读<br>像 select lock in share mode (共享锁), select for update; update; insert; delete (排他锁)这些操作都是一种当前读，为什么叫当前读？就是它读取的是记录的最新版本，读取时还要保证其他并发事务不能修改当前记录，会对读取的记录进行加锁</p>
<p>快照读<br>像不加锁的 select 操作就是快照读，即不加锁的非阻塞读；快照读的前提是隔离级别不是串行级别，串行级别下的快照读会退化成当前读；之所以出现快照读的情况，是基于提高并发性能的考虑，快照读的实现是基于多版本并发控制，即 MVCC ,可以认为 MVCC 是行锁的一个变种，但它在很多情况下，避免了加锁操作，降低了开销；既然是基于多版本，即快照读可能读到的并不一定是数据的最新版本，而有可能是之前的历史版本</p>
<p>说白了 MVCC 就是为了实现读-写冲突不加锁，而这个读指的就是快照读, 而非当前读，当前读实际上是一种加锁的操作，是悲观锁的实现<br>当前读，快照读和MVCC的关系</p>
<p>MVCC 多版本并发控制是 「维持一个数据的多个版本，使得读写操作没有冲突」 的概念，只是一个抽象概念，并非实现</p>
<p>因为 MVCC 只是一个抽象概念，要实现这么一个概念，MySQL 就需要提供具体的功能去实现它，「快照读就是 MySQL 实现 MVCC 理想模型的其中一个非阻塞读功能」。而相对而言，当前读就是悲观锁的具体功能实现</p>
<p>要说的再细致一些，快照读本身也是一个抽象概念，再深入研究。MVCC 模型在 MySQL 中的具体实现则是由 3 个隐式字段，undo 日志 ， Read View 等去完成的，具体可以看下面的 MVCC 实现原理</p>
<p>MVCC 能解决什么问题，好处是？<br>数据库并发场景有三种，分别为：</p>
<p>读-读：不存在任何问题，也不需要并发控制<br>读-写：有线程安全问题，可能会造成事务隔离性问题，可能遇到脏读，幻读，不可重复读<br>写-写：有线程安全问题，可能会存在更新丢失问题，比如第一类更新丢失，第二类更新丢失<br>MVCC 带来的好处是？<br>多版本并发控制（MVCC）是一种用来解决读-写冲突的无锁并发控制，也就是为事务分配单向增长的时间戳，为每个修改保存一个版本，版本与事务时间戳关联，读操作只读该事务开始前的数据库的快照。 所以 MVCC 可以为数据库解决以下问题</p>
<p>在并发读写数据库时，可以做到在读操作时不用阻塞写操作，写操作也不用阻塞读操作，提高了数据库并发读写的性能<br>同时还可以解决脏读，幻读，不可重复读等事务隔离问题，但不能解决更新丢失问题<br>小结一下咯<br>简而言之，MVCC 就是因为大佬们，不满意只让数据库采用悲观锁这样性能不佳的形式去解决读-写冲突问题，而提出的解决方案，所以在数据库中，因为有了 MVCC，所以我们可以形成两个组合：</p>
<ul>
<li><code>MVCC + 悲观锁</code><br>MVCC解决读写冲突，悲观锁解决写写冲突</li>
<li><code>MVCC + 乐观锁</code><br>MVCC 解决读写冲突，乐观锁解决写写冲突</li>
</ul>
<p>这种组合的方式就可以最大程度的提高数据库并发性能，并解决读写冲突，和写写冲突导致的问题</p>
<p>MVCC只在repeatable read和read committed两个隔离级别下工作。其他两个隔离级别都和MVCC不兼容，因为read uncommitted总是读取最新的数据行，而不是符合当前事务版本的数据行。而serializable则会对所有读取的行都加锁。</p>
<p><strong>READ COMMITTED —— 每次读取数据前都生成一个ReadView</strong></p>
<p><strong>REPEATABLE READ —— 在第一次读取数据时生成一个ReadView</strong></p>

                    
                        


                    
                    
                        <p>
                            <a
                                href="/2023/07/08/MYSQL%E5%A4%8D%E4%B9%A01/#post-footer"
                                class="postShorten-excerpt_link link"
                                aria-label=""
                            >
                                Kommentieren und teilen
                            </a>
                        </p>
                    
                </div>
            
        </div>
        
    </article>
    
    
    <article class="postShorten postShorten--thumbnailimg-bottom">
        <div class="postShorten-wrap">
            
            <div class="postShorten-header">
                <h1 class="postShorten-title">
                    
                        <a
                            class="link-unstyled"
                            href="/2023/07/08/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C%E5%A4%8D%E4%B9%A03/"
                            aria-label=": 计算机网络复习3"
                        >
                            计算机网络复习3
                        </a>
                    
                </h1>
                <div class="postShorten-meta">
    <time datetime="2023-07-08T00:00:00+08:00">
	
		    08 Jul 2023
    	
    </time>
    
        <span>in </span>
        
    <a class="category-link" href="/categories/Java/">Java</a>


    
</div>

            </div>
            
                <div class="postShorten-content">
                    <h3 id="这一章节就来学习IP协议"><a href="#这一章节就来学习IP协议" class="headerlink" title="这一章节就来学习IP协议"></a>这一章节就来学习IP协议</h3><p>我们知道两个不相连的网络之间的传输其实靠的是ip地址，两个直连的设备之间的用的协议MAC头，</p>
<p>ipv4是32位</p>
<p>我们把这些分成了5类，包括a类，b类，c类，d类，e类</p>
<p>a类是0开头，b类是10开头，c类是11开头，d类是1110开头，然后e类是1111开头</p>
<p>d类用于多播，多播是可以穿透网段的，e类用于留存</p>
<p>然后每个网络号对应的主机号的数量其实是2的主机号次幂-2，因为，主机号全为0指定某个网络，主机号全为1指代某个网络下的所有主机，用于广播</p>
<p>广播是用于对链路中相互连接的主机发送消息</p>
<p>在本网络中的广播叫做本地广播，不同网络之间的叫直接广播、</p>
<p>这种分类方式的好处就是简单，清晰</p>
<p>但是有缺点：</p>
<p>首先同一层次下，没有分类</p>
<p>第二，不能和现实网络很好的适配</p>
<p>所以提出了无分类地址cidr</p>
<p><img src="/../images/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C%E5%A4%8D%E4%B9%A03/image-20230804145043580.png" alt="image-20230804145043580"></p>
<p>我们知道可以通过子网掩码划分出网络号和主机号，那实际上子网掩码还有一个作用，那就是<strong>划分子网</strong>。</p>
<p><strong>子网划分实际上是将主机地址分为两个部分：子网网络地址和子网主机地址</strong></p>
<p>其实就是在a类b类上再分而已</p>
<p>dhcp</p>
<p>先说明一点，DHCP 客户端进程监听的是 68 端口号，DHCP 服务端进程监听的是 67 端口号。</p>
<p>这 4 个步骤：</p>
<ul>
<li>客户端首先发起 <strong>DHCP 发现报文（DHCP DISCOVER）</strong> 的 IP 数据报，由于客户端没有 IP 地址，也不知道 DHCP 服务器的地址，所以使用的是 UDP <strong>广播</strong>通信，其使用的广播目的地址是 255.255.255.255（端口 67） 并且使用 0.0.0.0（端口 68） 作为源 IP 地址。DHCP 客户端将该 IP 数据报传递给链路层，链路层然后将帧广播到所有的网络中设备。</li>
<li>DHCP 服务器收到 DHCP 发现报文时，用 <strong>DHCP 提供报文（DHCP OFFER）</strong> 向客户端做出响应。该报文仍然使用 IP 广播地址 255.255.255.255，该报文信息携带服务器提供可租约的 IP 地址、子网掩码、默认网关、DNS 服务器以及 <strong>IP 地址租用期</strong>。</li>
<li>客户端收到一个或多个服务器的 DHCP 提供报文后，从中选择一个服务器，并向选中的服务器发送 <strong>DHCP 请求报文（DHCP REQUEST</strong>进行响应，回显配置的参数。</li>
<li>最后，服务端用 <strong>DHCP ACK 报文</strong>对 DHCP 请求报文进行响应，应答所要求的参数。</li>
</ul>
<p>一旦客户端收到 DHCP ACK 后，交互便完成了，并且客户端能够在租用期内使用 DHCP 服务器分配的 IP 地址。</p>

                    
                        


                    
                    
                        <p>
                            <a
                                href="/2023/07/08/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C%E5%A4%8D%E4%B9%A03/#post-footer"
                                class="postShorten-excerpt_link link"
                                aria-label=""
                            >
                                Kommentieren und teilen
                            </a>
                        </p>
                    
                </div>
            
        </div>
        
    </article>
    
    
    <article class="postShorten postShorten--thumbnailimg-bottom">
        <div class="postShorten-wrap">
            
            <div class="postShorten-header">
                <h1 class="postShorten-title">
                    
                        <a
                            class="link-unstyled"
                            href="/2023/07/08/%E8%BE%93%E5%85%A5%E7%BD%91%E7%BB%9C%EF%BC%8C%E6%9C%9F%E9%97%B4%E5%8F%91%E7%94%9F%E4%BA%86%E4%BB%80%E4%B9%88/"
                            aria-label=": 输入网络，期间发生了什么？"
                        >
                            输入网络，期间发生了什么？
                        </a>
                    
                </h1>
                <div class="postShorten-meta">
    <time datetime="2023-07-08T00:00:00+08:00">
	
		    08 Jul 2023
    	
    </time>
    
        <span>in </span>
        
    <a class="category-link" href="/categories/Java/">Java</a>


    
</div>

            </div>
            
                <div class="postShorten-content">
                    <h1 id="输入网络，期间发生了什么，或者说两个设备之间是怎么传输的？"><a href="#输入网络，期间发生了什么，或者说两个设备之间是怎么传输的？" class="headerlink" title="输入网络，期间发生了什么，或者说两个设备之间是怎么传输的？"></a>输入网络，期间发生了什么，或者说两个设备之间是怎么传输的？</h1><h2 id="1、解析url"><a href="#1、解析url" class="headerlink" title="1、解析url"></a>1、解析url</h2><p>首先，就是对我们输入的url进行解析，一般可以得到三个信息：协议，web服务器，文件的路径</p>
<p>拿到这三个信息之后我们就可以包装成一个http请求信息</p>
<p>![image-20230728193306158](&#x2F;Users&#x2F;csen&#x2F;Library&#x2F;Application Support&#x2F;typora-user-images&#x2F;image-20230728193306158.png)</p>
<p>如图所示，一个是请求一个是响应报文</p>
<p>那我们生产出一个消息之后就要开始发送？那应该怎么发？往哪里发？</p>
<p>这就需要下面的知识。</p>
<h2 id="地址查询-——-DNS"><a href="#地址查询-——-DNS" class="headerlink" title="地址查询 —— DNS"></a>地址查询 —— DNS</h2><p>基于我们已经拿到的web服务器域名，我们可以先去浏览器缓存里面找有没有，如果有，就直接返回，如果没有那就问操作系统的缓存再去看hosts文件，如果都没有，那就看走下面</p>
<p>客户端首先会发出一个 DNS 请求，问 <a target="_blank" rel="noopener" href="http://www.xx.com/">www.xx.com</a> 的 IP 是啥，并发给本地 DNS 服务器（也就是客户端的 TCP&#x2F;IP 设置中填写的 DNS 服务器地址）。</p>
<p>本地域名服务器收到客户端的请求后，如果缓存里的表格能找到 <a target="_blank" rel="noopener" href="http://www.xx.com,则它直接返回/">www.xx.com，则它直接返回</a> IP 地址。如果没有，本地 DNS 会去问它的根域名服务器：“老大， 能告诉我 <a target="_blank" rel="noopener" href="http://www.xx.com/">www.xx.com</a> 的 IP 地址吗？” 根域名服务器是最高层次的，它不直接用于域名解析，但能指明一条道路。</p>
<p>根 DNS 收到来自本地 DNS 的请求后，发现后置是 .com，说：“<a target="_blank" rel="noopener" href="http://www.xx.com/">www.xx.com</a> 这个域名归 .com 区域管理”，我给你 .com 顶级域名服务器地址给你，你去问问它吧。”</p>
<p>本地 DNS 收到顶级域名服务器的地址后，发起请求问“老二， 你能告诉我 <a target="_blank" rel="noopener" href="http://www.xx.com/">www.xx.com</a> 的 IP 地址吗？”</p>
<p>顶级域名服务器说：“我给你负责 <a target="_blank" rel="noopener" href="http://www.xx.com/">www.xx.com</a> 区域的权威 DNS 服务器的地址，你去问它应该能问到”。</p>
<p>本地 DNS 于是转向问权威 DNS 服务器：“老三，<a href="http://www.xx.com对应的IP是啥呀？”">www.xx.com对应的IP是啥呀？”</a> server.com 的权威 DNS 服务器，它是域名解析结果的原出处。为啥叫权威呢？就是我的域名我做主。</p>
<p>权威 DNS 服务器查询后将对应的 IP 地址 X.X.X.X 告诉本地 DNS。</p>
<p>本地 DNS 再将 IP 地址返回客户端，客户端和目标建立连接</p>
<p>![image-20230728193808617](&#x2F;Users&#x2F;csen&#x2F;Library&#x2F;Application Support&#x2F;typora-user-images&#x2F;image-20230728193808617.png)</p>
<p>通过dns或者缓存获取到ip地址之后，我们就要为发送做一些准备，首先浏览器通过调用 Socket 库，来委托协议栈工作。</p>
<p>![image-20230728193955912](&#x2F;Users&#x2F;csen&#x2F;Library&#x2F;Application Support&#x2F;typora-user-images&#x2F;image-20230728193955912.png)</p>
<p>说是协议栈，其实就是中间tcp udp ip这些协议。那下面我们就来仔细的看看</p>
<h2 id="TCP"><a href="#TCP" class="headerlink" title="TCP"></a>TCP</h2><p>tcp段的头如下所示：</p>
<p>![image-20230728194108402](&#x2F;Users&#x2F;csen&#x2F;Library&#x2F;Application Support&#x2F;typora-user-images&#x2F;image-20230728194108402.png)</p>
<p>TCP 传输数据之前，要先三次握手建立连接</p>
<p>前提：客户端 为closed状态，服务端变成listen状态</p>
<p>连接：</p>
<p>1、客户端向服务端发送连接syn，之后客户端处于syn-sent状态；</p>
<p>2、服务端接收到这个消息之后，会返回一个syn+ack，之后服务端处于syn-rcvd状态</p>
<p>3、客户端收到这个之后，再给服务端发送一个对syn的ack，之后客户端处于establish状态</p>
<p>服务端收到ack也变成了establish状态</p>
<p>所以三次握手目的是<strong>保证双方都有发送和接收的能力</strong>。</p>
<p>假设我们已经建立了连接，我们要发送消息，但是消息要遵循tcp协议，他的消息大小是有限制的，不是每一次都可以发送全部消息。具体要求如下：</p>
<p>![image-20230728195857751](&#x2F;Users&#x2F;csen&#x2F;Library&#x2F;Application Support&#x2F;typora-user-images&#x2F;image-20230728195857751.png)</p>
<ul>
<li><code>MTU</code>：一个网络包的最大长度，以太网中一般为 <code>1500</code> 字节。</li>
<li><code>MSS</code>：除去 IP 和 TCP 头部之后，一个网络包所能容纳的 TCP 数据的最大长度</li>
</ul>
<p>所以如果http请求消息超过mss，那么就要分段发送。</p>
<p>到这里我们得到了一个tcp的报文段或者说包，下面我们就要把这个包发送给网络层，因为在传输层我们就是服务应用层，然后对好端口，确定好协议，之后的事情就不归传输层管控了。</p>
<p>到这里，我们的数据包的格式如下所示：</p>
<p>![image-20230728200405680](&#x2F;Users&#x2F;csen&#x2F;Library&#x2F;Application Support&#x2F;typora-user-images&#x2F;image-20230728200405680.png)</p>
<h2 id="定位IP"><a href="#定位IP" class="headerlink" title="定位IP"></a>定位IP</h2><p>ip协议的最重要的功能就是寻址和路由，他要做到这两点就需要你遵循ip协议，那么遵循的要求就是你加一个ip头![image-20230728200452235](&#x2F;Users&#x2F;csen&#x2F;Library&#x2F;Application Support&#x2F;typora-user-images&#x2F;image-20230728200452235.png)</p>
<p>加上ip头之后我们就知道了我们的源ip和目的ip地址，那么起点站和终点站就已经知道了</p>
<p>可以现在又有一个小问题，那就是路径怎么规划呢？这时候就需要用到Mac地址</p>
<h2 id="mac地址"><a href="#mac地址" class="headerlink" title="mac地址"></a>mac地址</h2><p>![image-20230728202408619](&#x2F;Users&#x2F;csen&#x2F;Library&#x2F;Application Support&#x2F;typora-user-images&#x2F;image-20230728202408619.png)</p>
<ul>
<li>先查询 ARP 缓存，如果其中已经保存了对方的 MAC 地址，就不需要发送 ARP 查询，直接使用 ARP 缓存中的地址。</li>
<li>而当 ARP 缓存中不存在对方 MAC 地址时，则发送 ARP 广播查询</li>
</ul>
<p>也就是说到了网络接口层，要发了，结果不知道往哪里发，这时候就按照上面两步得到mac地址</p>
<p>因为上面已经得到了ip地址，所以直接喊话：这个 IP 地址是谁的？请把你的 MAC 地址告诉我，就得到mac地址了。</p>
<p>到这里数据包还差最后一层包装</p>
<h2 id="出口–网卡"><a href="#出口–网卡" class="headerlink" title="出口–网卡"></a>出口–网卡</h2><p>![image-20230728204942674](&#x2F;Users&#x2F;csen&#x2F;Library&#x2F;Application Support&#x2F;typora-user-images&#x2F;image-20230728204942674.png)</p>
<p>最后一层包装就是上面图片提到的报头和起始帧分界符和fcs帧校验序列</p>
<p>网卡驱动获取网络包之后，会将其<strong>复制</strong>到网卡内的缓存区中，接着会在其<strong>开头加上报头和起始帧分界符，在末尾加上用于检测错误的帧校验序列</strong>。</p>
<p>到这里数据包就真正的包装结束了，最后网卡会将包转为电信号，通过网线发送出去。！！</p>
<h2 id="送别者—交换机"><a href="#送别者—交换机" class="headerlink" title="送别者—交换机"></a>送别者—交换机</h2><p>交换机的设计是将网络包<strong>原样</strong>转发到目的地。交换机工作在 MAC 层，也称为<strong>二层网络设备</strong>。</p>
<p>一般在网线接口啊这些地方，其实路由器也可以作为交换机。</p>
<h3 id="交换机的包接收操作"><a href="#交换机的包接收操作" class="headerlink" title="交换机的包接收操作"></a>交换机的包接收操作</h3><p>交换机里的模块将电信号转换为数字信号。</p>
<p>然后通过包末尾的fcs校验错误，没问题就放到缓存区，这部分操作基本和计算机的网卡相同，但交换机的工作方式和网卡不同。</p>
<p>计算机的网卡本身具有 MAC 地址，并通过核对收到的包的接收方 MAC 地址判断是不是发给自己的，如果不是发给自己的则丢弃；相对地，交换机的端口不核对接收方 MAC 地址，而是直接接收所有的包并存放到缓冲区中。因此，和网卡不同，<strong>交换机的端口不具有 MAC 地址</strong>。</p>
<h3 id="查询MAC-地址表"><a href="#查询MAC-地址表" class="headerlink" title="查询MAC 地址表"></a>查询<strong>MAC 地址表</strong></h3><p>如果找到，就发送到相应的端口，如果找不到，那说明该mac地址的设备还没有向我们交换机发送过包，那这时候我们主动的向除了源端口的所有端口都发送一遍，因为后面的设备他自己都有检测功能，所以不需要担心</p>
<p>这时候要么就发送到位，要么就可能离开子网了，离开子网需要用到路由器</p>
<h2 id="出境大门–路由器"><a href="#出境大门–路由器" class="headerlink" title="出境大门–路由器"></a>出境大门–路由器</h2><h3 id="路由器的包接收操作"><a href="#路由器的包接收操作" class="headerlink" title="路由器的包接收操作"></a>路由器的包接收操作</h3><p>首先，电信号到达网线接口部分，路由器中的模块会将电信号转成数字信号，然后通过包末尾的 <code>FCS</code> 进行错误校验。</p>
<p>如果没问题则检查 MAC 头部中的<strong>接收方 MAC 地址</strong>，看看是不是发给自己的包，如果是就放到接收缓冲区中，否则就丢弃这个包。</p>
<p>完成包接收操作之后，路由器就会<strong>去掉</strong>包开头的 MAC 头部。</p>
<p><strong>MAC 头部的作用就是将包送达路由器</strong>，其中的接收方 MAC 地址就是路由器端口的 MAC 地址。因此，当包到达路由器之后，MAC 头部的任务就完成了，于是 MAC 头部就会<strong>被丢弃</strong>。</p>
<p>接下来，路由器会根据 MAC 头部后方的 <code>IP</code> 头部中的内容进行包的转发操作。</p>
<h3 id="路由器的发送操作"><a href="#路由器的发送操作" class="headerlink" title="路由器的发送操作"></a>路由器的发送操作</h3><p>首先，我们需要根据<strong>路由表的网关列</strong>判断对方的地址。</p>
<ul>
<li>如果网关是一个 IP 地址，则这个IP 地址就是我们要转发到的目标地址，<strong>还未抵达终点</strong>，还需继续需要路由器转发。</li>
<li>如果网关为空，则 IP 头部中的接收方 IP 地址就是要转发到的目标地址，也是就终于找到 IP 包头里的目标地址了，说明<strong>已抵达终点</strong>。</li>
</ul>
<p>反正我们从路由表知道了ip地址，那么我们同样用这个地址去查mac地址</p>
<p>接下来是发送方 MAC 地址字段，这里填写输出端口的 MAC 地址。还有一个以太类型字段，填写 <code>0800</code> （十六进制）表示 IP 协议。</p>
<p>网络包完成后，接下来会将其转换成电信号并通过端口发送出去。这一步的工作过程和计算机也是相同的。</p>
<p>发送出去的网络包会通过<strong>交换机</strong>到达下一个路由器。由于接收方 MAC 地址就是下一个路由器的地址，所以交换机会根据这一地址将包传输到下一个路由器。</p>
<h1 id="例子"><a href="#例子" class="headerlink" title="例子"></a>例子</h1><p>这边举个例子![image-20230729000740012](&#x2F;Users&#x2F;csen&#x2F;Library&#x2F;Application Support&#x2F;typora-user-images&#x2F;image-20230729000740012.png)</p>
<p>子网1某个设备想要发送数据给子网2的某个设备</p>
<p>首先源ip和目的ip是知道的，如果只是简单的arp群发这个ip问是谁的ip地址，其实是找不到的，所以判断是否为同一子网，如果不是，就把目的mac改成网关的mac，然后数据发送到网关，这时候官网一查mac地址，发现属于子网2的设备，这时候修改源mac为自己的mac，修改目的mac为设备的地址，从子网2的网卡发出。</p>
<p>大多数情况下一个子网的默认网关就是一个，就基本代表着出口。复杂情况就需要某种选择算法了</p>

                    
                        


                    
                    
                        <p>
                            <a
                                href="/2023/07/08/%E8%BE%93%E5%85%A5%E7%BD%91%E7%BB%9C%EF%BC%8C%E6%9C%9F%E9%97%B4%E5%8F%91%E7%94%9F%E4%BA%86%E4%BB%80%E4%B9%88/#post-footer"
                                class="postShorten-excerpt_link link"
                                aria-label=""
                            >
                                Kommentieren und teilen
                            </a>
                        </p>
                    
                </div>
            
        </div>
        
    </article>
    
    
    <article class="postShorten postShorten--thumbnailimg-bottom">
        <div class="postShorten-wrap">
            
            <div class="postShorten-header">
                <h1 class="postShorten-title">
                    
                        <a
                            class="link-unstyled"
                            href="/2023/07/08/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C%E5%A4%8D%E4%B9%A02/"
                            aria-label=": 计算机网络复习2"
                        >
                            计算机网络复习2
                        </a>
                    
                </h1>
                <div class="postShorten-meta">
    <time datetime="2023-07-08T00:00:00+08:00">
	
		    08 Jul 2023
    	
    </time>
    
        <span>in </span>
        
    <a class="category-link" href="/categories/Java/">Java</a>


    
</div>

            </div>
            
                <div class="postShorten-content">
                    <h2 id="TCP"><a href="#TCP" class="headerlink" title="TCP"></a>TCP</h2><p>tcp头的格式</p>
<p>源端口目的端口</p>
<p>序列号</p>
<p>确认应答号（也是希望你在一个发送的号）</p>
<p>首部长度 保留 六个控制位 窗口大小（用于流量控制那边的）</p>
<p>校验和 紧急指针</p>
<p>选项</p>
<p>数据</p>
<p>一个tcp连接是由四元组确定的</p>
<p>最大的tcp连接数&#x3D;客户端ip*客户端端口 </p>
<h4 id="UDP只有64位，源端口目的端口包长度校验和数据"><a href="#UDP只有64位，源端口目的端口包长度校验和数据" class="headerlink" title="UDP只有64位，源端口目的端口包长度校验和数据"></a>UDP只有64位，源端口目的端口包长度校验和数据</h4><p>区别：</p>
<p>tcp	udp</p>
<p>一个需要连接 不需要连接</p>
<p>点对点 一对多&#x2F;多对多&#x2F;一对一</p>
<p>tcp有拥塞控制流量控制	udp没有无所谓</p>
<p>首部长	首部短</p>
<p>流式传输无边界	包传输有边界</p>
<p>分片msstcp	ucp在ip分片</p>
<h4 id="UDP和TCP可以共用一个端口，因为是完全独立的两个软件模块"><a href="#UDP和TCP可以共用一个端口，因为是完全独立的两个软件模块" class="headerlink" title="UDP和TCP可以共用一个端口，因为是完全独立的两个软件模块"></a>UDP和TCP可以共用一个端口，因为是完全独立的两个软件模块</h4><h4 id="为什么不能两次握手？"><a href="#为什么不能两次握手？" class="headerlink" title="为什么不能两次握手？"></a>为什么不能两次握手？</h4><h4 id="1、在两次握手的时候，服务端没有中间状态给客户端来阻止历史连接，也就是服务端会多建立一个历史连接浪费资源，因为收到syn就变成established"><a href="#1、在两次握手的时候，服务端没有中间状态给客户端来阻止历史连接，也就是服务端会多建立一个历史连接浪费资源，因为收到syn就变成established" class="headerlink" title="1、在两次握手的时候，服务端没有中间状态给客户端来阻止历史连接，也就是服务端会多建立一个历史连接浪费资源，因为收到syn就变成established"></a>1、在两次握手的时候，服务端没有中间状态给客户端来阻止历史连接，也就是服务端会多建立一个历史连接浪费资源，因为收到syn就变成established</h4><h4 id="2、同步序列号"><a href="#2、同步序列号" class="headerlink" title="2、同步序列号"></a>2、同步序列号</h4><h4 id="3、避免资源浪费，因为万一第一个syn报文阻塞了，那么就要重复发送多次syn报文，如果是两次握手，那就需要建立多个连接"><a href="#3、避免资源浪费，因为万一第一个syn报文阻塞了，那么就要重复发送多次syn报文，如果是两次握手，那就需要建立多个连接" class="headerlink" title="3、避免资源浪费，因为万一第一个syn报文阻塞了，那么就要重复发送多次syn报文，如果是两次握手，那就需要建立多个连接"></a>3、避免资源浪费，因为万一第一个syn报文阻塞了，那么就要重复发送多次syn报文，如果是两次握手，那就需要建立多个连接</h4><h4 id="为什么，每次建立连接序列号都要求不一样？"><a href="#为什么，每次建立连接序列号都要求不一样？" class="headerlink" title="为什么，每次建立连接序列号都要求不一样？"></a>为什么，每次建立连接序列号都要求不一样？</h4><p>1、防止历史报文被下一个相同四元组的连接接受（主要原因）</p>
<p>2、防止黑客伪造的相同序列号被接受</p>
<h4 id="那这个序列号是怎么随机产生的？"><a href="#那这个序列号是怎么随机产生的？" class="headerlink" title="那这个序列号是怎么随机产生的？"></a>那这个序列号是怎么随机产生的？</h4><p>rfc提高了序列号ISN随机生成算法：ISN &#x3D; M + F</p>
<p>m是计时器，四微秒+1</p>
<p>F是哈希算法根据四元组推出来的</p>
<h4 id="为什么ip会分片tcp还分片，"><a href="#为什么ip会分片tcp还分片，" class="headerlink" title="为什么ip会分片tcp还分片，"></a>为什么ip会分片tcp还分片，</h4><p>因为ip不能超时重传，所以只能靠tcp，而万一ip层丢了一部分，那么ip层就不能组装成一个完整的tcp报文（头部+数据），也就不可能发给接收方tcp层，所以发送方的tcp层就会重发整个tcp报文，所以我们最好就是自己分片，然后缺什么发什么，直接以MSS为单位就可以了</p>
<p>第一次握手丢失，会发生什么？</p>
<p>其实就是重传，重传的序列号还是要一样的，然后重传的机制需要学习</p>
<p>就是靠tcp_syn_retries决定，假设是3，就要重传三次，<strong>每次超时的时间是上一次的 2 倍</strong>。</p>
<p>第二次握手丢失，会发生什么？</p>
<p>客户端和服务端就会认为自己的没发到，客户端和服务端都触发重传机制，tcp_synack_retries</p>
<p>第三次握手没收到，会发生什么</p>
<p>这里有一点很关键，就是ack报文是不会重传的，所以服务端会认为自己的syn+ack没发到，触发重传机制</p>
<h4 id="半连接状态和全连接状态"><a href="#半连接状态和全连接状态" class="headerlink" title="半连接状态和全连接状态"></a>半连接状态和全连接状态</h4><ul>
<li>半连接队列，也称 SYN 队列；</li>
<li>全连接队列，也称 accept 队列；</li>
</ul>
<p>正常流程：</p>
<ul>
<li>当服务端接收到客户端的 SYN 报文时，会创建一个半连接的对象，然后将其加入到内核的「 SYN 队列」；</li>
<li>接着发送 SYN + ACK 给客户端，等待客户端回应 ACK 报文；</li>
<li>服务端接收到 ACK 报文后，从「 SYN 队列」取出一个半连接对象，然后创建一个新的连接对象放入到「 Accept 队列」；</li>
<li>应用通过调用 <code>accpet()</code> socket 接口，从「 Accept 队列」取出连接对象。</li>
</ul>
<p>所以这样子就出会先一些问题</p>
<p>受到SYN攻击怎么办？就是说半连接状态很多怎么办？</p>
<ul>
<li>调大 netdev_max_backlog；缓冲队列</li>
<li>增大 TCP 半连接队列；</li>
<li>开启 tcp_syncookies；不用建立半连接</li>
<li>减少 SYN+ACK 重传次数</li>
</ul>
<h3 id="TCP四次挥手"><a href="#TCP四次挥手" class="headerlink" title="TCP四次挥手"></a>TCP四次挥手</h3><p><img src="/../images/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C%E5%A4%8D%E4%B9%A02/image-20230803130523828.png" alt="image-20230803130523828"></p>
<p>为什么4次？关键是客户端给服务端发fin报文，说我已经没有数据要发个服务端了，但是这时候服务端可能还有数据要发给客户端，所以需要先处理自己的最后流程，然后给客户端发送一个fin报文，也就是说，第二次握手和第三次握手大概率是不同步的。</p>
<p>特定情况下，可以变成三次</p>
<p>第一次挥手丢失，会发生什么？</p>
<p>客户端收不到来自服务端的ack报文，那么就会触发超时重传，这个次数是由</p>
<p>tcp_orphan_retries决定的</p>
<p>第二次挥手丢失，会发生什么？</p>
<p>首先客户端还是会触发超时重传，这时候因为是单方向的，服务端不会触发超时重传</p>
<p>第三次丢失，会发生什么？</p>
<p>第三次丢失，相当于服务端一直收不到来自客户端的ack，那么服务端会触发超时重传，而客户端已经进入了wait2状态，一直等，如果超过设定的时间，自动关闭</p>
<p>第四次丢失，会发生什么？</p>
<p>服务端一直收不到，那么触发超时重传，这时候因为客户端已经是timewait状态，所以每一次重传都会重置2msl定时器，超过时间就close，而服务端同样的重传几次之后close</p>
<p>msl是报文最大生存时间，ip头有一个ttl字段，这个字段代表可以经历的最大路由数</p>
<p>msl大于等于ttl消耗为0的时间，默认60</p>
<h4 id="为什么需要这个timewait状态"><a href="#为什么需要这个timewait状态" class="headerlink" title="为什么需要这个timewait状态"></a>为什么需要这个timewait状态</h4><p>1、为了防止历史连接中的数据，被后面相同四元组的连接错误的接收，因此 TCP 设计了 TIME_WAIT 状态，状态会持续 <code>2MSL</code> 时长，这个时间<strong>足以让两个方向上的数据包都被丢弃，使得原来连接的数据包在网络中都自然消失，再出现的数据包一定都是新建立连接所产生的</strong></p>
<p>2、也就是说，TIME-WAIT 作用是<strong>等待足够的时间以确保最后的 ACK 能让被动关闭方接收，从而帮助其正常关闭。</strong></p>
<h4 id="出现大量超连接的原因"><a href="#出现大量超连接的原因" class="headerlink" title="出现大量超连接的原因"></a>出现大量超连接的原因</h4><p>没有用长链接</p>
<p>长连接超时（keepalive）</p>
<h4 id="如果建立了连接，结果客户端故障了，不发送消息，但是服务端一直establish"><a href="#如果建立了连接，结果客户端故障了，不发送消息，但是服务端一直establish" class="headerlink" title="如果建立了连接，结果客户端故障了，不发送消息，但是服务端一直establish"></a>如果建立了连接，结果客户端故障了，不发送消息，但是服务端一直establish</h4><p>tcp搞了个保活机制，隔一段时间发送探测报文，没有得到相应则认为tcp死亡，</p>
<p>但是，这个保活机制时间太长了，我们自己在应用层实现一个心跳机制</p>
<p>一般web服务软件都会提供keepalive-timeout状态</p>
<h4 id="如果服务器的进程崩溃了，那发生什么"><a href="#如果服务器的进程崩溃了，那发生什么" class="headerlink" title="如果服务器的进程崩溃了，那发生什么"></a>如果服务器的进程崩溃了，那发生什么</h4><p>其实连接信息是由内核维护的，所以服务端的内核还是会发送fin报文进行四次挥手</p>
<h3 id="超时重传、快速重传、"><a href="#超时重传、快速重传、" class="headerlink" title="超时重传、快速重传、"></a>超时重传、快速重传、</h3><p>超时重传很正常，时间RTO，两倍两倍+</p>
<p>快速重传的问题在于传一个还是传所有，这里引入了SACK机制</p>
<p>SACK就是把收到的数据信息驾到tcp头部的选项里面，告诉发送发我收到了哪些</p>
<p>后面又出现了D-SACK，这是用来告诉发送方哪些被重复接受了了</p>
<h3 id="滑动窗口"><a href="#滑动窗口" class="headerlink" title="滑动窗口"></a>滑动窗口</h3><p>窗口的实现实际上是操作系统开辟的一个缓存空间，发送方主机在等到确认应答返回之前，必须在缓冲区中保留已发送的数据。如果按期收到确认应答，此时数据就可以从缓存区清除</p>
<p>tcp头部里面既有一个字段叫窗口大小，就是用来告诉发送端自己还有多少缓冲区可以使用，所以窗口大小一般由接收方决定</p>
<h3 id="流量控制"><a href="#流量控制" class="headerlink" title="流量控制"></a>流量控制</h3><p>避免发送方的数据填满接收方</p>
<h3 id="拥塞控制"><a href="#拥塞控制" class="headerlink" title="拥塞控制"></a>拥塞控制</h3><p>避免发送方的网络填满整个网络，所以这个协议是很无私的，只要网络发生拥塞，那么tcp就会降低自己的发送量</p>
<p>慢启动 一开始是1，就是可以传1个mss，然后收到应答变成2，4，8，16…..</p>
<p>拥塞避免 触碰到慢启动门限就是用拥塞避免，变成线性的，收到一个ack cwnd增加1&#x2F;cwnd</p>
<p>超时重传，慢启动门限变成cwnd&#x2F;2，cwnd&#x3D;1重新开始慢启动</p>
<p>快速恢复，，cwnd &#x3D; cwnd&#x2F;2，慢启动门限&#x3D; cwnd</p>
<p>cwnd &#x3D; ssthresh + 3</p>
<p>收到重复的数据包 cwnd++</p>
<p>收到新的数据包说明重传成功，cwnd &#x3D; 慢启动门限，进入拥塞避免</p>
<p>如果优化tcp？</p>
<p>从三个方向，三次握手，四次挥手，还有中途的数据传输</p>
<p>三次握手，</p>
<p>客户端，减少重传次数</p>
<p>服务端，增大半连接队列的大小和全连接队列的大小，开启syncookie技术</p>
<p><img src="/../images/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C%E5%A4%8D%E4%B9%A02/image-20230803161404210.png" alt="image-20230803161404210"></p>
<p>四次挥手</p>
<p>关闭连接的方式通常有两种，分别是 RST 报文关闭和 FIN 报文关闭。</p>
<p>如果进程收到 RST 报文，就直接关闭连接了，不需要走四次挥手流程，是一个暴力关闭连接的方式。</p>
<p>安全关闭连接的方式必须通过四次挥手，它由进程调用 <code>close</code> 和 <code>shutdown</code> 函数发起 FIN 报文（shutdown 参数须传入 SHUT_WR 或者 SHUT_RDWR 才会发送 FIN）。</p>
<blockquote>
<p>调用了 close 函数意味着完全断开连接，<strong>完全断开不仅指无法传输数据，而且也不能发送数据。 此时，调用了 close 函数的一方的连接叫做「孤儿连接」，如果你用 netstat -p 命令，会发现连接对应的进程名为空。</strong></p>
<p>使用 close 函数关闭连接是不优雅的。于是，就出现了一种优雅关闭连接的 <code>shutdown</code> 函数，<strong>它可以控制只关闭一个方向的连接</strong></p>
</blockquote>
<p><img src="/../images/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C%E5%A4%8D%E4%B9%A02/image-20230803163142196.png" alt="image-20230803163142196"></p>
<p><img src="/../images/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C%E5%A4%8D%E4%B9%A02/image-20230803163236556.png" alt="image-20230803163236556"></p>
<h4 id="如何理解字节流"><a href="#如何理解字节流" class="headerlink" title="如何理解字节流"></a>如何理解字节流</h4><p>udp操作系统不会对齐拆分，所以每一个udp就是一个消息的边界，操作系统收到udp之后会把他查到队列里面，每一个队列他都是一个udp</p>
<p>然而tcp是会分片的，这时候，接收方如果不知道消息的长度或者边界，是无法读取消息的，</p>
<p>在发送端，当我们调用 send 函数完成数据“发送”以后，数据并没有被真正从网络上发送出去，只是从应用程序拷贝到了操作系统内核协议栈中。</p>
<p>至于什么时候真正被发送，<strong>取决于发送窗口、拥塞窗口以及当前发送缓冲区的大小等条件</strong>。也就是说，我们不能认为每次 send 调用发送的数据，都会作为一个整体完整地消息被发送出去</p>
<p>一般用特殊字符作为边界</p>
<p>自定义消息结构</p>
<h4 id="已经建立的tcp，收到syn会发生什么"><a href="#已经建立的tcp，收到syn会发生什么" class="headerlink" title="已经建立的tcp，收到syn会发生什么"></a>已经建立的tcp，收到syn会发生什么</h4><p>新的syn首先看看端口是不是一样，如果不一样的话，就建立新的连接，老的那个如果一直不发消息就会触发tcp保活机制</p>
<p>如果相同（可能就是宕机重传），其实会返回一个challenge ack，携带正确的序列号的确认号的ack报文，这时候客户端确认号收到这个，发现不是自己期望收到的，就会返回rst，这样，服务器就释放了连接</p>
<h3 id="如果四次挥手过程中，fin包先比数据包到了主动关闭方，那这个数据还会接受吗"><a href="#如果四次挥手过程中，fin包先比数据包到了主动关闭方，那这个数据还会接受吗" class="headerlink" title="如果四次挥手过程中，fin包先比数据包到了主动关闭方，那这个数据还会接受吗"></a>如果四次挥手过程中，fin包先比数据包到了主动关闭方，那这个数据还会接受吗</h3><p>先到的fin包其实是乱序的，所以会进入乱序队列，等数据真正的到了，才会回头检查这个fin，然后给服务端发这个。</p>
<h3 id="如果timewait状态收到syn？会怎么样？"><a href="#如果timewait状态收到syn？会怎么样？" class="headerlink" title="如果timewait状态收到syn？会怎么样？"></a>如果timewait状态收到syn？会怎么样？</h3><p>还是先看序列号时间戳吧，如果确实合法，那应该会重新进入三次握手阶段，</p>
<p>如果不合法，就会返回一个和第四次挥手一样的ack，这时候服务端收到发现不是自己的，就回复一个rst报文</p>
<h3 id="Tcp连接，断电和进程崩溃有什么区别？没有保活机制"><a href="#Tcp连接，断电和进程崩溃有什么区别？没有保活机制" class="headerlink" title="Tcp连接，断电和进程崩溃有什么区别？没有保活机制"></a>Tcp连接，断电和进程崩溃有什么区别？没有保活机制</h3><p>客户端主机崩溃，没有保活机制，那就无法感知到，一直处于establish</p>
<p>进程崩溃，内核还是会发送fin完成4次挥手</p>
<h4 id="客户端主机宕机，又迅速重启"><a href="#客户端主机宕机，又迅速重启" class="headerlink" title="客户端主机宕机，又迅速重启"></a>客户端主机宕机，又迅速重启</h4><p>在客户端主机宕机后，服务端向客户端发送的报文会得不到任何的响应，在一定时长后，服务端就会触发<strong>超时重传</strong>机制，重传未得到响应的报文。</p>
<p>服务端重传报文的过程中，客户端主机重启完成后，客户端的内核就会接收重传的报文，然后根据报文的信息传递给对应的进程：</p>
<ul>
<li>如果客户端主机上<strong>没有</strong>进程绑定该 TCP 报文的目标端口号，那么客户端内核就会<strong>回复 RST 报文，重置该 TCP 连接</strong>；</li>
<li>如果客户端主机上<strong>有</strong>进程绑定该 TCP 报文的目标端口号，由于客户端主机重启后，之前的 TCP 连接的数据结构已经丢失了，客户端内核里协议栈会发现找不到该 TCP 连接的 socket 结构体，于是就会<strong>回复 RST 报文，重置该 TCP 连接</strong>。</li>
</ul>
<p>所以，<strong>只要有一方重启完成后，收到之前 TCP 连接的报文，都会回复 RST 报文，以断开连接</strong></p>
<h4 id="拔掉网线tcp连接还在吗"><a href="#拔掉网线tcp连接还在吗" class="headerlink" title="拔掉网线tcp连接还在吗"></a>拔掉网线tcp连接还在吗</h4><p>在的，tcp连接信息是存储于内核的一个结构体，网线断了，但是结构体不会改变</p>
<ul>
<li>拔掉网线后，有数据传输；<ul>
<li>如果在重传前网线插回去了，那我觉得应该什么事情都没发生</li>
<li>如果没插回去，那么就超时重传几次之后，认为此连接死亡，就断开连接，即使后面插回来了，客户端向服务端发送请求，也不是连接的状态，那么服务端就会返回rst</li>
</ul>
</li>
<li>拔掉网线后，没有数据传输<ul>
<li>如果开启了保活机制，那就探测几次，如果有工作就重制保活时间，如果客户端没有正常工作，就断开连接</li>
<li>如果没有开启保活机制，就一直连着</li>
</ul>
</li>
</ul>
<h4 id="HTTPS-中-TLS-和-TCP-能同时握手吗？"><a href="#HTTPS-中-TLS-和-TCP-能同时握手吗？" class="headerlink" title="HTTPS 中 TLS 和 TCP 能同时握手吗？"></a>HTTPS 中 TLS 和 TCP 能同时握手吗？</h4><p>可能，但是有条件</p>
<ul>
<li><strong>客户端和服务端都开启了 TCP Fast Open 功能，且 TLS 版本是 1.3；</strong></li>
<li><strong>客户端和服务端已经完成过一次通信。</strong></li>
</ul>
<p><img src="/../images/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C%E5%A4%8D%E4%B9%A02/image-20230803205908513.png" alt="image-20230803205908513"></p>
<p>TCP Fast Open定义<br>TCP Fast Open（TFO）是用来加速连续TCP连接的数据交互的TCP协议扩展，原理如下：在TCP三次握手的过程中，当用户首次访问Server时，发送SYN包，Server根据用户IP生成Cookie（已加密），并与SYN-ACK一同发回Client；当Client随后重连时，在SYN包携带TCP Cookie；如果Server校验合法，则在用户回复ACK前就可以直接发送数据；否则按照正常三次握手进行<br><img src="/../images/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C%E5%A4%8D%E4%B9%A02/image-20230803210533146.png" alt="image-20230803210533146"></p>
<p>所以就是在第二次以后的通信过程中，tcp open fast在ack发回来之前直接进行tls1.3</p>
<h4 id="没有accept，能建立tcp连接吗"><a href="#没有accept，能建立tcp连接吗" class="headerlink" title="没有accept，能建立tcp连接吗"></a>没有accept，能建立tcp连接吗</h4><ul>
<li><strong>每一个</strong><code>socket</code>执行<code>listen</code>时，内核都会自动创建一个半连接队列和全连接队列。</li>
<li>第三次握手前，TCP连接会放在半连接队列中，直到第三次握手到来，才会被放到全连接队列中。</li>
<li><code>accept方法</code>只是为了从全连接队列中拿出一条连接，本身跟三次握手几乎<strong>毫无关系</strong>。</li>
<li>出于效率考虑，虽然都叫队列，但半连接队列其实被设计成了<strong>哈希表</strong>，而全连接队列本质是链表。</li>
<li>全连接队列满了，再来第三次握手也会丢弃，此时如果<code>tcp_abort_on_overflow=1</code>，还会直接发<code>RST</code>给客户端。</li>
<li>半连接队列满了，可能是因为受到了<code>SYN Flood</code>攻击，可以设置<code>tcp_syncookies</code>，绕开半连接队列。</li>
<li>客户端没有半连接队列和全连接队列，但有一个<strong>全局hash</strong>，可以通过它实现自连接或TCP同时打开。</li>
</ul>
<h4 id="服务端没有-listen，客户端发起连接建立，会发生什么？"><a href="#服务端没有-listen，客户端发起连接建立，会发生什么？" class="headerlink" title="服务端没有 listen，客户端发起连接建立，会发生什么？"></a>服务端没有 listen，客户端发起连接建立，会发生什么？</h4><p><strong>服务端如果只 bind 了 IP 地址和端口，而没有调用 listen 的话，然后客户端对服务端发起了连接建立，服务端会回 RST 报文</strong></p>
<h4 id="quic怎么实现可靠传输"><a href="#quic怎么实现可靠传输" class="headerlink" title="quic怎么实现可靠传输"></a>quic怎么实现可靠传输</h4><p><img src="/../images/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C%E5%A4%8D%E4%B9%A02/image-20230803212833705.png" alt="image-20230803212833705"></p>
<p>packetheader分为两种</p>
<p>Packet Header 细分这两种：</p>
<ul>
<li>Long Packet Header 用于首次建立连接。</li>
<li>Short Packet Header 用于日常传输数据。</li>
</ul>
<p><img src="/../images/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C%E5%A4%8D%E4%B9%A02/image-20230803213009597.png" alt="image-20230803213009597"></p>
<p>这里packet Number是递增的，即使重传也是递增，这样就可以分清是重传的还是延迟的，比较能清晰的计算出rtt，以及rto</p>
<p>![在前面介绍 Packet Header 时，说到 Packet Number 是严格递增，即使重传报文的 Packet Number 也是递增的，既然重传数据包的 Packet N+M 与丢失数据包的 Packet N 编号并不一致，我们怎么确定这两个数据包的内容一样呢？</p>
<p>所以引入 Frame Header 这一层，<strong>通过 Stream ID + Offset 字段信息实现数据的有序性</strong>，通过比较两个数据包的 Stream ID 与 Stream Offset ，如果都是一致，就说明这两个数据包的内容一致。</p>
<h4 id="QUIC-是如何解决-TCP-队头阻塞问题的？"><a href="#QUIC-是如何解决-TCP-队头阻塞问题的？" class="headerlink" title="QUIC 是如何解决 TCP 队头阻塞问题的？"></a>QUIC 是如何解决 TCP 队头阻塞问题的？</h4><p><strong>QUIC 给每一个 Stream 都分配了一个独立的滑动窗口，这样使得一个连接上的多个 Stream 之间没有依赖关系，都是相互独立的，各自控制的滑动窗口</strong>。</p>
<h3 id="QUIC-是如何做流量控制的？"><a href="#QUIC-是如何做流量控制的？" class="headerlink" title="QUIC 是如何做流量控制的？"></a>QUIC 是如何做流量控制的？</h3><p>TCP 流量控制是通过让「接收方」告诉「发送方」，它（接收方）的接收窗口有多大，从而让「发送方」根据「接收方」的实际接收能力控制发送的数据量。</p>
<p>但是quic是基于udp的，所以他本身没有流量控制，因此需要实现自己的流量控制</p>
<p>QUIC 实现流量控制的方式：</p>
<ul>
<li>通过 window_update 帧告诉对端自己可以接收的字节数，这样发送方就不会发送超过这个数量的数据。 如果消耗数据的长度大于了最大接收窗口的一半发送</li>
<li>通过 BlockFrame 告诉对端由于流量控制被阻塞了，无法发送数据。</li>
</ul>

                    
                        


                    
                    
                        <p>
                            <a
                                href="/2023/07/08/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C%E5%A4%8D%E4%B9%A02/#post-footer"
                                class="postShorten-excerpt_link link"
                                aria-label=""
                            >
                                Kommentieren und teilen
                            </a>
                        </p>
                    
                </div>
            
        </div>
        
    </article>
    
    
    <article class="postShorten postShorten--thumbnailimg-bottom">
        <div class="postShorten-wrap">
            
            <div class="postShorten-header">
                <h1 class="postShorten-title">
                    
                        <a
                            class="link-unstyled"
                            href="/2023/07/08/Kafka/"
                            aria-label=": Kafka知识"
                        >
                            Kafka知识
                        </a>
                    
                </h1>
                <div class="postShorten-meta">
    <time datetime="2023-07-08T00:00:00+08:00">
	
		    08 Jul 2023
    	
    </time>
    
        <span>in </span>
        
    <a class="category-link" href="/categories/Java/">Java</a>


    
</div>

            </div>
            
                <div class="postShorten-content">
                    <h1 id="1、定义"><a href="#1、定义" class="headerlink" title="1、定义"></a>1、定义</h1><p>分布式的基于发布订阅模式的消息队列</p>
<p>主要应用场景包括：<strong>缓存消峰</strong>、<strong>解耦</strong>和<strong>异步通信。</strong></p>
<p>消息队列有两种模式：</p>
<ul>
<li>点对点模式：一个主题，一个消费者，消费者主动拉取数据后，确认收到后会删除数据</li>
<li>发布订阅模式：多个主题，多个消费者独立，不会删除</li>
</ul>
<p><strong>基础架构</strong>：</p>
<p><img src="/../images/Kafka/708e86e70504f41234b05cb3cc30dea7.png" alt="image-20220902125656203"></p>
<p>1）Producer：消息生产者，就是向 Kafka broker 发消息的客户端。</p>
<p>（2）Consumer：消息消费者，向 Kafka broker 取消息的客户端。</p>
<p>（3）Consumer Group（CG）：消费者组，由多个 consumer 组成。消费者组内每个消费者负责消费不同分区的数据，一个分区只能由一个组内消费者消费；消费者组之间互不影响。所有的消费者都属于某个消费者组，即消费者组是逻辑上的一个订阅者。</p>
<p>（4）Broker：一台 Kafka 服务器就是一个 broker。一个集群由多个 broker 组成。一个broker 可以容纳多个 topic。</p>
<p>（5）Topic：可以理解为一个队列，生产者和消费者面向的都是一个 topic。</p>
<p>（6）Partition：为了实现扩展性，一个非常大的 topic 可以分布到多个 broker（即服务器）上，一个 topic 可以分为多个 partition，每个 partition 是一个有序的队列。</p>
<p>（7）Replica：副本。一个 topic 的每个分区都有若干个副本，一个 Leader 和若干个Follower。</p>
<p>（8）Leader：每个分区多个副本的“主”，生产者发送数据的对象，以及消费者消费数据的对象都是 Leader。</p>
<p>（9）Follower：每个分区多个副本中的“从”，实时从 Leader 中同步数据，保持和Leader 数据的同步。Leader 发生故障时，某个 Follower 会成为新的 Leader。</p>
<p>其实总的流程就是生产者发送数据到kafka，然后消费者从kafka拉取数据。所以架构中最主要的就是生产者、kafka集群和消费者这三个，其他的很多知识都是为了这三个服务的。</p>
<h1 id="2、生产者"><a href="#2、生产者" class="headerlink" title="2、生产者"></a>2、生产者</h1><p> 在消息发送的过程中，涉及到两个线程，main线程和sender线程，其中main线程是消息的生产线程，而sender线程是jvm单例的线程，专门用于消息的发送。</p>
<p> 在jvm的内存中开辟了一块缓存空间叫RecordAccumulator（消息累加器），用于将多条消息合并成一个批次，然后由sender线程发送给kafka集群。<br><img src="/../images/Kafka/cd41370a872e70b75435f35692925370.png" alt="image-20220902155220662"></p>
<p>当双端队列中的DQueue满足 batch.size 或者 linger.ms 条件时触发sender线程。</p>
<p>这里我们一步一步看</p>
<p>producer没什么意外，就是生产者，配置好就可以</p>
<p>然后拦截器，就是对这个消息做一个操作，末尾也会有一个，也没什么，相当于留了一个供我们修改的接口</p>
<p>序列化器：这个也没什么奇怪，发送消息，总要给消息一种形式，kafka有自带的</p>
<p>Partitioner：这个需要着重讲一下，我们事先其实是分好了区，但是发送消息的时候发送到那一个区？</p>
<p>这就涉及到发送消息分区策略：</p>
<ul>
<li><p>他有一个默认的分区器DefaultPartitioner，支持三种分区策略 1) 指定分区； 2）指定key，计算hash得分区； 3）指定随机粘性分区（下图）；<img src="/../images/Kafka/18a0b6ba56db8e5b16b3d6fac9ba7fb7.png" alt="image-20220902163808502"></p>
</li>
<li><p>还可以自定义分区器（见代码）</p>
</li>
<li><p>~~~<br>public class MyPartitioner implements Partitioner {<br>&#x2F;**<br> * @param topic 主题<br> * @param key 消息的 key<br> * @param keyBytes 消息的 key 序列化后的字节数组<br> * @param value 消息的 value<br> * @param valueBytes 消息的 value 序列化后的字节数组<br> * @param cluster 集群元数据可以查看分区信息<br> *&#x2F;<br>@Override<br>public int partition(String topic, Object key, byte[] keyBytes, Object value, byte[] valueBytes, Cluster cluster) {<br>    String string &#x3D; value.toString();<br>    if (string.contains(“vi”)){<br>        return 2;<br>    }else{<br>        return 1;<br>    }<br>}<br>}</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line"></span><br><span class="line">  </span><br><span class="line"></span><br><span class="line">然后我们就要依赖</span><br><span class="line"></span><br><span class="line">## **消息累加器（RecordAccumulator）**</span><br><span class="line"></span><br><span class="line">![image-20220902174419992](../images/Kafka/f20e0b29414b41978048b0c263c2f6a4.png)</span><br><span class="line"></span><br><span class="line"> 为了提高生产者的吞吐量，我们通过累加器将多条消息合并成一批统一发送。在broker中将消息批量存入。减少多次的网络IO。</span><br><span class="line"></span><br><span class="line"> 消息累加器默认32m，如果生产者的发送速率大于sender发送的速率，消息就会堆满累加器。生产者就会阻塞，或者报错，报错取决于阻塞时间的配置。</span><br><span class="line"></span><br><span class="line"> 累加器的存储形式为ConcurrentMap&lt;TopicPartition, Deque&lt;ProducerBatch&gt;&gt;，可以看出来就是一个分区对应一个双端队列，队列中存储的是ProducerBatch一般大小是16k根据batch.size配置，新的消息会append到ProducerBatch中，满16k就会创建新的ProducerBatch，并且触发sender线程进行发送。</span><br><span class="line"></span><br><span class="line"> 如果消息量非常大，生成了大量的ProducerBatch，在发送后，又需要JVM通过GC回收这些ProducerBatch就变得非常影响性能，所以kafka通过 BufferPool作为内存池来管理ProducerBatch的创建和回收，需要申请一个新的ProducerBatch空间时，调用 free.allocate(size, maxTimeToBlock)找内存池申请空间。</span><br><span class="line"></span><br><span class="line">如果单条消息大于16k，那么就不会复用内存池了，会生成一个更大的ProducerBatch专门存放大消息，发送完后GC回收该内存空间。</span><br><span class="line"></span><br><span class="line">接着就是</span><br><span class="line"></span><br><span class="line">## **消息发送线程（Sender）**</span><br><span class="line"></span><br><span class="line"> 消息保存在内存后，Sender线程就会把符合条件的消息按照批次进行发送， Sender线程默认容纳5个未确认的消息，消息发送失败后会进行重试。</span><br><span class="line"></span><br><span class="line">## 生产者提高吞吐量</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br></pre></td></tr></table></figure>
<p> &#x2F;&#x2F; batch.size：批次大小，默认 16K<br>properties.put(ProducerConfig.BATCH_SIZE_CONFIG, 16384);<br>&#x2F;&#x2F; linger.ms：等待时间，默认 0<br>properties.put(ProducerConfig.LINGER_MS_CONFIG, 1);<br>&#x2F;&#x2F; RecordAccumulator：缓冲区大小，默认 32M：buffer.memory<br>properties.put(ProducerConfig.BUFFER_MEMORY_CONFIG,33554432);</p>
</li>
</ul>
<p>&#x2F;&#x2F; compression.type：压缩，默认 none，可配置值 gzip、snappy、lz4 和 zstd<br>properties.put(ProducerConfig.COMPRESSION_TYPE_CONFIG, “snappy”);</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line"></span><br><span class="line">发送方发送消息到kafka集群，这一段路 也保证数据的可靠性</span><br><span class="line"></span><br><span class="line">## 生产经验—数据可靠性</span><br><span class="line"></span><br><span class="line">### 消息确认机制-ACK</span><br><span class="line"></span><br><span class="line">producer提供了三种消息确认的模式，通过配置acks来实现</span><br><span class="line"></span><br><span class="line">acks为0时， 表示生产者将数据发送出去就不管了，不等待任何返回。这种情况下数据传输效率最高，但是数据可靠性最低，当 server挂掉的时候就会丢数据；</span><br><span class="line"></span><br><span class="line">acks为1时（默认），表示数据发送到Kafka后，经过leader成功接收消息的的确认，才算发送成功，如果leader宕机了，就会丢失数据。</span><br><span class="line"></span><br><span class="line">acks为-1/all时，表示生产者需要等待ISR中的所有follower都确认接收到数据后才算发送完成，这样数据不会丢失，因此可靠性最高，性能最低。</span><br><span class="line"></span><br><span class="line">数据完全可靠条件 = ACK级别设置为-1 + 分区副本大于等于2 + ISR里应答的最小副本数量大于等于2</span><br><span class="line"></span><br><span class="line">![image-20220902172535966](../images/Kafka/a5c1a40450861d56bfc5cce44746a8a6.png)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">AR = ISR + ORS</span><br><span class="line"></span><br><span class="line">ISR 表示在指定时间内和leader保存数据同步的集合；</span><br><span class="line"></span><br><span class="line">ORS表示不能在指定的时间内和leader保持数据同步集合，称为OSR(Out-Sync Relipca set)。</span><br><span class="line"></span><br><span class="line">### 数据去重-幂等性</span><br><span class="line"></span><br><span class="line">1）幂等性原理</span><br><span class="line"></span><br><span class="line">在一般的MQ模型中，常有以下的消息通信概念</span><br><span class="line"></span><br><span class="line">至少一次（At Least Once）： ACK级别设置为-1 + 分区副本大于等于2 + ISR里应答的最小副本数量&gt;=2。可以保证数据不丢失，但是不能保证数据不重复。</span><br><span class="line">最多一次（At Most Once）：ACK级别设置为0 。可以保证数据不重复，但是不能保证数据不丢失。•</span><br><span class="line">精确一次（Exactly Once）：至少一次 + 幂等性 。 Kafka 0.11版本引入一项重大特性：幂等性和事务。</span><br><span class="line"> 幂等性，简单地说就是对接口的多次调用所产生的结果和调用一次是一致的。生产者在进行重试的时候有可能会重复写入消息，而使用Kafka 的幂等性功能之后就可以避免这种情况。（不产生重复数据）</span><br><span class="line"></span><br><span class="line"> 重复数据的判断标准：具有&lt;PID, Partition, SeqNumber&gt;相同主键的消息提交时，Broker只会持久化一条。其</span><br><span class="line"></span><br><span class="line">中ProducerId（pid）是Kafka每次重启都会分配一个新的；Partition 表示分区号；Sequence Number 序列化号，是单调自增的。</span><br><span class="line"></span><br><span class="line"> broker中会在内存维护一个pid+分区对应的序列号。如果收到的序列号正好比内存序列号大一，才存储消息，如果小于内存序列号，意味着消息重复，那么会丢弃消息，并应答。如果远大于内存序列号，意味着消息丢失，会抛出异常。</span><br><span class="line"></span><br><span class="line">所以幂等解决的是sender到broker间，由于网络波动可能造成的重发问题。用幂等来标识唯一消息。</span><br><span class="line"></span><br><span class="line">并且幂等性只能保证的是在单分区单会话内不重复。</span><br><span class="line"></span><br><span class="line">2）如何使用幂等性</span><br><span class="line"></span><br><span class="line"> 开启幂等性功能的方式很简单，只需要显式地将生产者客户端参数enable.idempotence设置为true即可(这个参数的默认值为true)，并且还需要确保生产者客户端的retries、acks、max.in.filght.request.per.connection参数不被配置错，默认值就是对的。</span><br><span class="line"></span><br><span class="line">### 消息事务</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">由于幂等性不能跨分区运作，为了保证同时发的多条消息，要么全成功，要么全失败。kafka引入了事务的概念。</span><br><span class="line"></span><br><span class="line">开启事务需要producer设置transactional.id的值并同时开启幂等性。</span><br><span class="line"></span><br><span class="line">通过事务协调器，来实现事务，工作流程如下：</span><br><span class="line"></span><br><span class="line">![image-20220902183826203](../images/Kafka/4d210e935a7af0d15c3caa53e08f4e9e.png)</span><br><span class="line"></span><br><span class="line">### 消息顺序</span><br><span class="line"></span><br><span class="line">kafka只能保证单分区下的消息顺序性，为了保证消息的顺序性，需要做到如下几点。</span><br><span class="line"></span><br><span class="line">如果未开启幂等性，需要 max.in.flight.requests.per.connection 设置为1。（缓冲队列最多放置1个请求）</span><br><span class="line"></span><br><span class="line">如果开启幂等性，需要 max.in.flight.requests.per.connection 设置为小于5。</span><br><span class="line"></span><br><span class="line">这是因为broker端会缓存producer主题分区下的五个request，保证最近5个request是有序的。</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"># 3、Broker</span><br><span class="line"></span><br><span class="line">## Broker设计</span><br><span class="line"></span><br><span class="line"> 我们都知道kafka能堆积非常大的数据，一台服务器，肯定是放不下的。由此出现的集群的概念，集群不仅可以让消息负载均衡，还能提高消息存取的吞吐量。kafka集群中，会有多台broker，每台broker分别在不同的机器上。为了提高吞吐量，每个topic也会都多个分区，同时为了保持可靠性，每个分区还会有多个副本。这些分区副本被均匀的散落在每个broker上，其中每个分区副本中有一个副本为leader，其他的为follower。</span><br><span class="line"></span><br><span class="line">![image-20220902195939625](../images/Kafka/37643c8b56fe0f32a3b9d7c803f85b0b.png)</span><br><span class="line"></span><br><span class="line">## Zookeeper</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line">Zookeeper在Kafka中扮演了重要的角色，kafka使用zookeeper进行元数据管理，保存broker注册信息，包括主题（Topic）、分区（Partition）信息等，选择分区leader。</span><br><span class="line"></span><br><span class="line">![image-20220902200249692](../images/Kafka/b1f0ebc535b00384be6bf81540c5f416.png)</span><br><span class="line"></span><br><span class="line">## Broker选举Leader</span><br><span class="line"></span><br><span class="line">Kafka由三个方面会涉及到选举：</span><br><span class="line"></span><br><span class="line">- broker（控制器）选leader</span><br><span class="line"></span><br><span class="line">- 分区多副本选leader</span><br><span class="line">- 消费者选Leader</span><br><span class="line"></span><br><span class="line"> 在kafka集群中由很多的broker（也叫做控制器），但是他们之间需要选举出一个leader，其他的都是follower。broker的leader有很重要的作用，诸如：创建、删除主题、增加分区并分配leader分区；集群broker管理，包括新增、关闭和故障处理；分区重分配（auto.leader.rebalance.enable=true，后面会介绍），分区leader选举。</span><br><span class="line"></span><br><span class="line"> 每个broker都有唯一的brokerId，他们在启动后会去竞争注册zookeeper上的Controller结点，谁先抢到，谁就是broker leader。而其他broker会监听该结点事件，以便后续leader下线后触发重新选举。</span><br><span class="line"></span><br><span class="line">- broker（控制器）选leader</span><br><span class="line"></span><br><span class="line">![image-20220902200901222](../images/Kafka/12b4f076e8f82c66b00ec8782433649f.png)</span><br><span class="line"></span><br><span class="line">- 分区多副本选leader![image-20220902201352868](../images/Kafka/e5c14b9c17123faf3eefa58a22ab0668-20230928225949575.png)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line">## 副本机制</span><br><span class="line"></span><br><span class="line">- replica ：副本，同一分区的不同副本保存的是相同的消息，为保证集群中的某个节点发生故障时，该节点上的 partition 数据不丢失 ，提高副本可靠性，且 kafka 仍然能够继续工作，kafka 提供了副本机制，一个 topic 的每个分区都有若干个副本，一个 leader 和若干个 follower。</span><br><span class="line"></span><br><span class="line">- Leader ：每个分区的多个副本中的&quot;主副本&quot;，生产者以及消费者只与 Leader 交互。</span><br><span class="line">- Follower ：每个分区的多个副本中的&quot;从副本&quot;，负责实时从 Leader 中同步数据，保持和 Leader 数据的同步。Leader 发生故障时，从 Follower 副本中重新选举新的 Leader 副本对外提供服务。</span><br><span class="line">- **LEO**:每个副本都有内部的LEO，代表当前队列消息的最后一条偏移量offset + 1。</span><br><span class="line">- **HW**:高水位，代表所有ISR中的LEO最低的那个offset，也是消费者可见的最大消息offset。</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line">![image-20220902201925254](../images/Kafka/1c5cd091fee1ef3c76fcc1c13dccf7de.png)</span><br><span class="line"></span><br><span class="line"> Kafka 集群中有一个 broker 的 Controller 会被选举为 Controller Leader (4.2.2) ，负责管理集群Broker 的上下线，所有 topic 的分区副本分配和 Leader 选举等工作</span><br><span class="line"></span><br><span class="line"> Broker中Controller 的信息同步工作是依赖于 Zookeeper 的 ./broker/topic 目录下的信息。</span><br><span class="line"></span><br><span class="line">## 副本故障处理</span><br><span class="line"></span><br><span class="line">### **1.follower故障流程**</span><br><span class="line"></span><br><span class="line">![image-20220902210759125](../images/Kafka/b01dad78f006b40d82e719fe71caeb78.png)</span><br><span class="line"></span><br><span class="line">### 2.leader故障流程</span><br><span class="line"></span><br><span class="line">旧Leader先被从ISR队列中踢出，然后从ISR中选出一个新的Leader来；此时为了保证多个副本之间的数据一致性，其他的follower会先将各自的log文件中高于HW的部分截取掉，然后从新的leader同步数据（由此可知这只能保证副本之间数据一致性，并不能保证数据不丢失或者不重复）。体现了设置ACK-all的重要性。</span><br><span class="line">![image-20220902210830344](../images/Kafka/1f96e55810be5ff8cbf64c04b5d37315.png)</span><br><span class="line"></span><br><span class="line">## kafka分区策略</span><br><span class="line"></span><br><span class="line">如果 kafka 服务器只有 4 个节点，那么设置 kafka 的分区数大于服务器台数，在 kafka底层如何分配存储副本呢？</span><br><span class="line"></span><br><span class="line">- 这里如果用默认的就是如下</span><br><span class="line"></span><br><span class="line">![image-20220902211334365](../images/Kafka/15514da0f22aca9e3017fa2305733ba4.png)</span><br><span class="line"></span><br><span class="line">- 也可以手动指定~~~</span><br><span class="line"></span><br></pre></td></tr></table></figure>
<p>$ vim increase-replication-factor.json<br>输入如下内容：<br>{<br>“version”:1,<br>“partitions”:[<br>{“topic”:”three”,”partition”:0,”replicas”:[0,1]},<br>{“topic”:”three”,”partition”:1,”replicas”:[0,1]},<br>{“topic”:”three”,”partition”:2,”replicas”:[1,0]},<br>{“topic”:”three”,”partition”:3,”replicas”:[1,0]}]<br>}</p>
<p>~~~</p>
<h4 id="分区自动调整"><a href="#分区自动调整" class="headerlink" title="分区自动调整"></a><strong>分区自动调整</strong></h4><p>随着一些broker故障，会慢慢出现leader集中在某台broker上的情况，造成集群负载不均衡，这时候就需要分区平衡。</p>
<p><img src="/../images/Kafka/watermark,type_d3F5LXplbmhlaQ,shadow_50,text_Q1NETiBA6Zi_5piM5Zac5qyi5ZCD6buE5qGD,size_20,color_FFFFFF,t_70,g_se,x_16.png" alt="在这里插入图片描述"></p>
<h2 id="文件存储"><a href="#文件存储" class="headerlink" title="文件存储"></a>文件存储</h2><h5 id="①文件存储机制"><a href="#①文件存储机制" class="headerlink" title="①文件存储机制"></a>①文件存储机制</h5><p><img src="/../images/Kafka/watermark,type_d3F5LXplbmhlaQ,shadow_50,text_Q1NETiBA6Zi_5piM5Zac5qyi5ZCD6buE5qGD,size_20,color_FFFFFF,t_70,g_se,x_16-20230928232748011.png" alt="在这里插入图片描述"></p>
<h5 id="②思考：Topic-数据到底存储-在什么位置？"><a href="#②思考：Topic-数据到底存储-在什么位置？" class="headerlink" title="②思考：Topic 数据到底存储 在什么位置？"></a>②思考：Topic 数据到底存储 在什么位置？</h5><p><img src="/../images/Kafka/watermark,type_d3F5LXplbmhlaQ,shadow_50,text_Q1NETiBA6Zi_5piM5Zac5qyi5ZCD6buE5qGD,size_20,color_FFFFFF,t_70,g_se,x_16-20230928232838576.png" alt="在这里插入图片描述"></p>
<h5 id="③index-文件和-log-文件详解"><a href="#③index-文件和-log-文件详解" class="headerlink" title="③index 文件和 log 文件详解"></a>③index 文件和 log 文件详解</h5><p><img src="/../images/Kafka/watermark,type_d3F5LXplbmhlaQ,shadow_50,text_Q1NETiBA6Zi_5piM5Zac5qyi5ZCD6buE5qGD,size_20,color_FFFFFF,t_70,g_se,x_16-20230928233003817.png" alt="在这里插入图片描述"></p>
<h2 id="文件清理策略"><a href="#文件清理策略" class="headerlink" title="文件清理策略"></a>文件清理策略</h2><p>Kafka将消息存储在磁盘中，为了控制磁盘占用空间的不断增加就需要对消息做一定的清理操作。Kafka 中每一个分区副本都对应一个Log，而Log又可以分为多个日志分段，这样也便于日志的清理操作。Kafka提供了两种日志清理策略。</p>
<p>日志删除(delete) :按照一定的保留策略直接删除不符合条件的日志分段。<br>日志压缩(compact) :针对每个消息的key进行整合，对于有相同key的不同value值，只保留最后一个版本。</p>
<p><img src="/../images/Kafka/watermark,type_d3F5LXplbmhlaQ,shadow_50,text_Q1NETiBA6Zi_5piM5Zac5qyi5ZCD6buE5qGD,size_20,color_FFFFFF,t_70,g_se,x_16-20230928233204011.png" alt="在这里插入图片描述"></p>
<p><img src="/../images/Kafka/watermark,type_d3F5LXplbmhlaQ,shadow_50,text_Q1NETiBA6Zi_5piM5Zac5qyi5ZCD6buE5qGD,size_20,color_FFFFFF,t_70,g_se,x_16-20230928233315113.png" alt="在这里插入图片描述"></p>
<h2 id="Kafka高效读数据"><a href="#Kafka高效读数据" class="headerlink" title="Kafka高效读数据"></a><strong>Kafka高效读数据</strong></h2><p>kafka之所以可以快速读写的原因如下：</p>
<ol>
<li>kafka是分布式集群，采用分区方式，并行操作</li>
<li>读取数据采用稀疏索引，可以快速定位消费数据</li>
<li>顺序写磁盘</li>
<li>页缓冲和零拷贝</li>
</ol>
<p><img src="/../images/Kafka/eeb8531c34ed091d57d9be10590839c5.png" alt="image-20220902214803709"></p>
<p><img src="/../images/Kafka/watermark,type_d3F5LXplbmhlaQ,shadow_50,text_Q1NETiBA6Zi_5piM5Zac5qyi5ZCD6buE5qGD,size_20,color_FFFFFF,t_70,g_se,x_16-20230928233417216.png" alt="在这里插入图片描述"></p>
<h1 id="4、kafka消费者"><a href="#4、kafka消费者" class="headerlink" title="4、kafka消费者"></a>4、kafka消费者</h1><h2 id="1、Kafka-消费方式"><a href="#1、Kafka-消费方式" class="headerlink" title="1、Kafka 消费方式"></a>1、Kafka 消费方式</h2><p>​	<img src="/../images/Kafka/watermark,type_d3F5LXplbmhlaQ,shadow_50,text_Q1NETiBA6Zi_5piM5Zac5qyi5ZCD6buE5qGD,size_20,color_FFFFFF,t_70,g_se,x_16-20230928234825729.png" alt="在这里插入图片描述"></p>
<h2 id="2、消费者工作流程"><a href="#2、消费者工作流程" class="headerlink" title="2、消费者工作流程"></a>2、消费者工作流程</h2><h5 id="①消费者总体工作流程"><a href="#①消费者总体工作流程" class="headerlink" title="①消费者总体工作流程"></a>①消费者总体工作流程</h5><p><img src="/../images/Kafka/watermark,type_d3F5LXplbmhlaQ,shadow_50,text_Q1NETiBA6Zi_5piM5Zac5qyi5ZCD6buE5qGD,size_20,color_FFFFFF,t_70,g_se,x_16-20230928234848009.png" alt="在这里插入图片描述"></p>
<h5 id="②消费者组原理"><a href="#②消费者组原理" class="headerlink" title="②消费者组原理"></a>②消费者组原理</h5><p> <img src="/../images/Kafka/watermark,type_d3F5LXplbmhlaQ,shadow_50,text_Q1NETiBA6Zi_5piM5Zac5qyi5ZCD6buE5qGD,size_20,color_FFFFFF,t_70,g_se,x_16-20230928235013969.png" alt="在这里插入图片描述"></p>
<p><img src="/../images/Kafka/watermark,type_d3F5LXplbmhlaQ,shadow_50,text_Q1NETiBA6Zi_5piM5Zac5qyi5ZCD6buE5qGD,size_20,color_FFFFFF,t_70,g_se,x_16-20230928235020544.png" alt="在这里插入图片描述"></p>
<p><strong>消费者组初始化流程</strong></p>
<p><img src="/../images/Kafka/watermark,type_d3F5LXplbmhlaQ,shadow_50,text_Q1NETiBA6Zi_5piM5Zac5qyi5ZCD6buE5qGD,size_20,color_FFFFFF,t_70,g_se,x_16-20230928235058845.png" alt="在这里插入图片描述"></p>
<p><strong>消费者组详细消费流程</strong></p>
<p><img src="/../images/Kafka/watermark,type_d3F5LXplbmhlaQ,shadow_50,text_Q1NETiBA6Zi_5piM5Zac5qyi5ZCD6buE5qGD,size_20,color_FFFFFF,t_70,g_se,x_16-20230928235306060.png" alt="在这里插入图片描述"></p>
<h2 id="3、消费者api"><a href="#3、消费者api" class="headerlink" title="3、消费者api"></a>3、消费者api</h2><h2 id="4、生产经验-——-分区的分配"><a href="#4、生产经验-——-分区的分配" class="headerlink" title="4、生产经验 —— 分区的分配"></a>4、生产经验 —— 分区的分配</h2><p><img src="/../images/Kafka/watermark,type_d3F5LXplbmhlaQ,shadow_50,text_Q1NETiBA6Zi_5piM5Zac5qyi5ZCD6buE5qGD,size_20,color_FFFFFF,t_70,g_se,x_16-20230928235523539.png" alt="在这里插入图片描述"></p>
<p><img src="/../images/Kafka/watermark,type_d3F5LXplbmhlaQ,shadow_50,text_Q1NETiBA6Zi_5piM5Zac5qyi5ZCD6buE5qGD,size_20,color_FFFFFF,t_70,g_se,x_16-20230928235554746.png" alt="在这里插入图片描述"></p>
<p><strong>Range 分区分配策略案例</strong></p>
<p> <img src="/../images/Kafka/watermark,type_d3F5LXplbmhlaQ,shadow_50,text_Q1NETiBA6Zi_5piM5Zac5qyi5ZCD6buE5qGD,size_20,color_FFFFFF,t_70,g_se,x_16-20230928235731478.png" alt="在这里插入图片描述"></p>
<p><img src="/../images/Kafka/29f6564651824fe69bba934f8e5e83b6.png" alt="在这里插入图片描述"></p>
<h5 id="Range-分区分配再平衡案例"><a href="#Range-分区分配再平衡案例" class="headerlink" title="Range 分区分配再平衡案例"></a><strong>Range 分区分配再平衡案例</strong></h5><p><img src="/../images/Kafka/watermark,type_d3F5LXplbmhlaQ,shadow_50,text_Q1NETiBA6Zi_5piM5Zac5qyi5ZCD6buE5qGD,size_20,color_FFFFFF,t_70,g_se,x_16-20230928235744058.png" alt="在这里插入图片描述"></p>
<h5 id="RoundRobin-以及再平衡原理"><a href="#RoundRobin-以及再平衡原理" class="headerlink" title="RoundRobin 以及再平衡原理"></a>RoundRobin 以及再平衡原理</h5><h5 id=""><a href="#" class="headerlink" title=""></a></h5><p><img src="/../images/Kafka/watermark,type_d3F5LXplbmhlaQ,shadow_50,text_Q1NETiBA6Zi_5piM5Zac5qyi5ZCD6buE5qGD,size_20,color_FFFFFF,t_70,g_se,x_16-20230929000334551.png" alt="在这里插入图片描述"></p>
<p><img src="/../images/Kafka/watermark,type_d3F5LXplbmhlaQ,shadow_50,text_Q1NETiBA6Zi_5piM5Zac5qyi5ZCD6buE5qGD,size_20,color_FFFFFF,t_70,g_se,x_16-20230929000415710.png" alt="在这里插入图片描述"></p>
<h5 id="Sticky-以及再平衡"><a href="#Sticky-以及再平衡" class="headerlink" title="Sticky 以及再平衡"></a>Sticky 以及再平衡</h5><p><img src="/../images/Kafka/watermark,type_d3F5LXplbmhlaQ,shadow_50,text_Q1NETiBA6Zi_5piM5Zac5qyi5ZCD6buE5qGD,size_20,color_FFFFFF,t_70,g_se,x_16-20230929000640458.png" alt="在这里插入图片描述"></p>
<p><img src="/../images/Kafka/watermark,type_d3F5LXplbmhlaQ,shadow_50,text_Q1NETiBA6Zi_5piM5Zac5qyi5ZCD6buE5qGD,size_20,color_FFFFFF,t_70,g_se,x_16-20230929000653360.png" alt="在这里插入图片描述"></p>
<p><img src="/../images/Kafka/watermark,type_d3F5LXplbmhlaQ,shadow_50,text_Q1NETiBA6Zi_5piM5Zac5qyi5ZCD6buE5qGD,size_20,color_FFFFFF,t_70,g_se,x_16-20230929000715131.png" alt="在这里插入图片描述"></p>
<p><img src="/../images/Kafka/watermark,type_d3F5LXplbmhlaQ,shadow_50,text_Q1NETiBA6Zi_5piM5Zac5qyi5ZCD6buE5qGD,size_20,color_FFFFFF,t_70,g_se,x_16-20230929000728390.png" alt="在这里插入图片描述"></p>
<h2 id="5、offset-位移"><a href="#5、offset-位移" class="headerlink" title="5、offset 位移"></a>5、offset 位移</h2><h5 id="1、offset-的默认维护"><a href="#1、offset-的默认维护" class="headerlink" title="1、offset 的默认维护"></a>1、offset 的默认维护</h5><p><img src="/../images/Kafka/watermark,type_d3F5LXplbmhlaQ,shadow_50,text_Q1NETiBA6Zi_5piM5Zac5qyi5ZCD6buE5qGD,size_20,color_FFFFFF,t_70,g_se,x_16-20230929000851750.png" alt="在这里插入图片描述"></p>
<p>__consumer_offsets 主题里面采用 key 和 value 的方式存储数据。</p>
<p>key 是group.id+topic+分区号，value 就是当前 offset 的值。</p>
<p>每隔一段时间，kafka 内部会对这个 topic 进行compact，也就是每个 group.id+topic+分区号就保留最新数据。</p>
<h5 id="①消费-offset-案例"><a href="#①消费-offset-案例" class="headerlink" title="①消费 offset 案例"></a>①消费 offset 案例</h5><p><img src="/../images/Kafka/watermark,type_d3F5LXplbmhlaQ,shadow_50,text_Q1NETiBA6Zi_5piM5Zac5qyi5ZCD6buE5qGD,size_20,color_FFFFFF,t_70,g_se,x_16-20230929000928260.png" alt="在这里插入图片描述"></p>
<h5 id="②自动提交-offset"><a href="#②自动提交-offset" class="headerlink" title="②自动提交 offset"></a>②自动提交 offset</h5><p><img src="/../images/Kafka/watermark,type_d3F5LXplbmhlaQ,shadow_50,text_Q1NETiBA6Zi_5piM5Zac5qyi5ZCD6buE5qGD,size_20,color_FFFFFF,t_70,g_se,x_16-20230929001005340.png" alt="在这里插入图片描述"></p>
<h5 id="③手动交-提交-offset"><a href="#③手动交-提交-offset" class="headerlink" title="③手动交 提交 offset"></a>③手动交 提交 offset</h5><p><img src="/../images/Kafka/watermark,type_d3F5LXplbmhlaQ,shadow_50,text_Q1NETiBA6Zi_5piM5Zac5qyi5ZCD6buE5qGD,size_20,color_FFFFFF,t_70,g_se,x_16-20230929001022624.png" alt="在这里插入图片描述"></p>
<h5 id="④指定-Offset-消费"><a href="#④指定-Offset-消费" class="headerlink" title="④指定 Offset 消费"></a>④指定 Offset 消费</h5><p><img src="/../images/Kafka/watermark,type_d3F5LXplbmhlaQ,shadow_50,text_Q1NETiBA6Zi_5piM5Zac5qyi5ZCD6buE5qGD,size_20,color_FFFFFF,t_70,g_se,x_16-20230929001046545.png" alt="在这里插入图片描述"></p>
<p><img src="/../images/Kafka/watermark,type_d3F5LXplbmhlaQ,shadow_50,text_Q1NETiBA6Zi_5piM5Zac5qyi5ZCD6buE5qGD,size_20,color_FFFFFF,t_70,g_se,x_16-20230929001143065.png" alt="在这里插入图片描述"></p>
<h5 id="⑤指定时间消费"><a href="#⑤指定时间消费" class="headerlink" title="⑤指定时间消费"></a>⑤指定时间消费</h5><p>其实就是通过时间得到offset然后指定offset</p>
<h5 id="⑥漏消费和重复消费"><a href="#⑥漏消费和重复消费" class="headerlink" title="⑥漏消费和重复消费"></a>⑥漏消费和重复消费</h5><p><strong>重复消费</strong>：已经消费了数据，但是 offset没提交。</p>
<p><strong>漏消费</strong>：先提交 offset后消费，有可能会造成数据的漏消费</p>
<p><img src="/../images/Kafka/watermark,type_d3F5LXplbmhlaQ,shadow_50,text_Q1NETiBA6Zi_5piM5Zac5qyi5ZCD6buE5qGD,size_20,color_FFFFFF,t_70,g_se,x_16-20230929001250173.png" alt="在这里插入图片描述"></p>
<p><img src="/../images/Kafka/watermark,type_d3F5LXplbmhlaQ,shadow_50,text_Q1NETiBA6Zi_5piM5Zac5qyi5ZCD6buE5qGD,size_20,color_FFFFFF,t_70,g_se,x_16-20230929001509066.png" alt="在这里插入图片描述"></p>
<h4 id="数据积压-（-消费者-如何提高吞吐量）"><a href="#数据积压-（-消费者-如何提高吞吐量）" class="headerlink" title="数据积压 （ 消费者 如何提高吞吐量）"></a>数据积压 （ 消费者 如何提高吞吐量）</h4><p><img src="/../images/Kafka/watermark,type_d3F5LXplbmhlaQ,shadow_50,text_Q1NETiBA6Zi_5piM5Zac5qyi5ZCD6buE5qGD,size_20,color_FFFFFF,t_70,g_se,x_16-20230929001531640.png" alt="在这里插入图片描述"></p>

                    
                        


                    
                    
                        <p>
                            <a
                                href="/2023/07/08/Kafka/#post-footer"
                                class="postShorten-excerpt_link link"
                                aria-label=""
                            >
                                Kommentieren und teilen
                            </a>
                        </p>
                    
                </div>
            
        </div>
        
    </article>
    
    <div class="pagination-bar">
    <ul class="pagination">
        
        
          <li class="pagination-next">
            <a
                class="btn btn--default btn--small"
                href="/archives/2023/page/2/"
                aria-label="ÄLTERE BEITRÄGE"
            >
              <span>ÄLTERE BEITRÄGE</span>
              <i class="fa fa-angle-right text-base icon-ml"></i>
            </a>
          </li>
        
        <li class="pagination-number">Seite 1 von 3</li>
    </ul>
</div>

</section>



                <footer id="footer" class="main-content-wrap">
    <span class="copyrights">
        Copyrights &copy; 2023 CSEN. All Rights Reserved.
    </span>
</footer>

            </div>
            
        </div>
        


    
        
    

<div id="about">
    <div id="about-card">
        <div id="about-btn-close">
            <i class="fa fa-times"></i>
        </div>
        
            <img id="about-card-picture" src="/assets/images/head.jpg" alt="Bild des Autors"/>
        
            <h4 id="about-card-name">CSEN</h4>
        
            <div id="about-card-bio"><p>author.bio</p>
</div>
        
        
            <div id="about-card-job">
                <i class="fa fa-briefcase"></i>
                <br/>
                <p>author.job</p>

            </div>
        
        
            <div id="about-card-location">
                <i class="fa fa-map-marker-alt"></i>
                <br/>
                浙江温州
            </div>
        
    </div>
</div>

        
        
<div id="cover" style="background-image:url('/assets/images/cover.jpg');"></div>
        <!--SCRIPTS-->

<script src="/assets/js/script-39paoi2hupf5wmw7ojejrxpco6edftjriz5ezbtp4grymrdceksftgan2adp.min.js"></script>

<!--SCRIPTS END-->





    </body>
</html>
