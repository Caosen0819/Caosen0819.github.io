
<!DOCTYPE html>
<html lang="zh-CH">
    
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1">
    <meta name="generator" content="森">
    <title>Archiv: 2023/7 - 森</title>
    <meta name="author" content="CSEN">
    
    
    
    <script type="application/ld+json">{}</script>
    <meta name="description" content="潮起潮落，云卷云舒">
<meta property="og:type" content="blog">
<meta property="og:title" content="森">
<meta property="og:url" content="http://example.com/archives/2023/07/index.html">
<meta property="og:site_name" content="森">
<meta property="og:description" content="潮起潮落，云卷云舒">
<meta property="og:locale" content="zh_CH">
<meta property="article:author" content="CSEN">
<meta name="twitter:card" content="summary">
    
    
        
    
    
        <meta property="og:image" content="http://example.com/assets/images/head.jpg"/>
    
    
    
    
    <!--STYLES-->
    
<link rel="stylesheet" href="/assets/css/style-w816scvuzwavitjylabixcb3ofuoklqul47j3rgwu1r0mxrxvbdehvp2jk5s.min.css">

    <!--STYLES END-->
    

    

    
</head>

    <body>
        <div id="blog">
            <!-- Define author's picture -->


    
        
            
        
    

<header id="header" data-behavior="1">
    <i id="btn-open-sidebar" class="fa fa-lg fa-bars"></i>
    <div class="header-title">
        <a
            class="header-title-link"
            href="/"
            aria-label=""
        >
            森
        </a>
    </div>
    
        
            <a
                class="header-right-picture "
                href="#about"
                aria-label="Öffne den Link: /#about"
            >
        
        
            <img class="header-picture" src="/assets/images/head.jpg" alt="Bild des Autors"/>
        
        </a>
    
</header>

            <!-- Define author's picture -->



        
    

<nav id="sidebar" data-behavior="1">
    <div class="sidebar-container">
        
            <div class="sidebar-profile">
                <a
                    href="/#about"
                    aria-label="Lesen Sie mehr über den Autor"
                >
                    <img class="sidebar-profile-picture" src="/assets/images/head.jpg" alt="Bild des Autors"/>
                </a>
                <h4 class="sidebar-profile-name">CSEN</h4>
                
                    <h5 class="sidebar-profile-bio"><p>author.bio</p>
</h5>
                
            </div>
        
        
            <ul class="sidebar-buttons">
            
                <li class="sidebar-button">
                    
                        <a
                            class="sidebar-button-link "
                            href="/"
                            
                            rel="noopener"
                            title="首页"
                        >
                        <i class="sidebar-button-icon fa fa-home" aria-hidden="true"></i>
                        <span class="sidebar-button-desc">首页</span>
                    </a>
            </li>
            
                <li class="sidebar-button">
                    
                        <a
                            class="sidebar-button-link "
                            href="/all-categories"
                            
                            rel="noopener"
                            title="分类"
                        >
                        <i class="sidebar-button-icon fa fa-bookmark" aria-hidden="true"></i>
                        <span class="sidebar-button-desc">分类</span>
                    </a>
            </li>
            
                <li class="sidebar-button">
                    
                        <a
                            class="sidebar-button-link "
                            href="/all-tags"
                            
                            rel="noopener"
                            title="标签"
                        >
                        <i class="sidebar-button-icon fa fa-tags" aria-hidden="true"></i>
                        <span class="sidebar-button-desc">标签</span>
                    </a>
            </li>
            
                <li class="sidebar-button">
                    
                        <a
                            class="sidebar-button-link "
                            href="/all-archives"
                            
                            rel="noopener"
                            title="档案"
                        >
                        <i class="sidebar-button-icon fa fa-archive" aria-hidden="true"></i>
                        <span class="sidebar-button-desc">档案</span>
                    </a>
            </li>
            
                <li class="sidebar-button">
                    
                        <a
                            class="sidebar-button-link open-algolia-search"
                            href="#search"
                            
                            rel="noopener"
                            title="搜索"
                        >
                        <i class="sidebar-button-icon fa fa-search" aria-hidden="true"></i>
                        <span class="sidebar-button-desc">搜索</span>
                    </a>
            </li>
            
                <li class="sidebar-button">
                    
                        <a
                            class="sidebar-button-link "
                            href="#about"
                            
                            rel="noopener"
                            title="关于"
                        >
                        <i class="sidebar-button-icon fa fa-question" aria-hidden="true"></i>
                        <span class="sidebar-button-desc">关于</span>
                    </a>
            </li>
            
        </ul>
        
            <ul class="sidebar-buttons">
            
                <li class="sidebar-button">
                    
                        <a
                            class="sidebar-button-link "
                            href="https://github.com/Caosen0819"
                            
                                target="_blank"
                            
                            rel="noopener"
                            title=".github"
                        >
                        <i class="sidebar-button-icon fab fa-github" aria-hidden="true"></i>
                        <span class="sidebar-button-desc">.github</span>
                    </a>
            </li>
            
        </ul>
        
    </div>
</nav>

            
            <div id="main" data-behavior="1"
                 class="
                        hasCoverMetaIn
                        ">
                
    <section class="postShorten-group main-content-wrap">
    
    
    <article class="postShorten postShorten--thumbnailimg-bottom">
        <div class="postShorten-wrap">
            
            <div class="postShorten-header">
                <h1 class="postShorten-title">
                    
                        <a
                            class="link-unstyled"
                            href="/2023/07/08/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C%E5%A4%8D%E4%B9%A01/"
                            aria-label=": 计算机网络复习1"
                        >
                            计算机网络复习1
                        </a>
                    
                </h1>
                <div class="postShorten-meta">
    <time datetime="2023-07-08T00:00:00+08:00">
	
		    08 Jul 2023
    	
    </time>
    
        <span>in </span>
        
    <a class="category-link" href="/categories/Java/">Java</a>


    
</div>

            </div>
            
                <div class="postShorten-content">
                    <p>计算机网络整体的学习可以按照tcpip网络模型进行学习。我们的总结也是这样的</p>
<p>Tcp&#x2F;ip网络模型分别是应用层、传输层、网络层、数据链路层</p>
<p>这里面前三层比较重要，数据链路层复杂的方面涉及实际的物理知识所以我们只对逻辑思想上做一个学习，</p>
<p>那每一层分别学的是什么呢？</p>
<p>应用层：http  https tls</p>
<p>传输层：tcp udp </p>
<p>网络层：ipv4 v6</p>
<p>基本上就是这样子</p>
<p>TCP 连接传输协议，这是传输层的，很多应用层的协议在传输层都是使用这个的，比如http</p>
<p>那tcp和udp的差距是，tcp相比udp多了很多为了可靠的连接所增加的特性，比如流量控制，超时重传，拥塞控制，就是为了数据能可靠的传到对方，但是过程中究竟是请求-应答模式还是什么模式，那就是后面的不同版本做出的更新。</p>
<p>udp他不在乎这个数据究竟有没有到对面，只负责发送，所以实时性号，效率高。但是他并不是不能做到可靠传输，因为udp只是传输层，我们还可以在应用层做出一定的限制来保证传输是可靠的，比如quic协议，当然这是困难的。</p>
<p>除此之外，还有一个很大的不同就是tcp是会分片的，但是udp是不会分片。在这里我们还要知道的一点是在网络层，也就是ip协议中还是会分片的，MTU。但是对于tcp来说因为你要是在ip层才分片，我为了保证可靠，我假设12345 丢了一个2，那我就要12345全部重新发，这样不好，所以我们就在tcp层也分片，大小是mss。而udp不用可靠，所以他不用分片。</p>
<p>网络层，主要的作用其实就是路由和寻址，加上ip头，规定好源ip，目的ip等信息，</p>
<p>网络接口层，是提供链路级别的传输服务，因为源ip和目的ip知道了，但是在以太网中实际上是不行的，IP会变，我们需要一个确切的信息，这个就是mac地址，</p>
<p>那我们这里用输入网址到显示，来串联一下整体的流程：</p>
<h4 id="1、解析url"><a href="#1、解析url" class="headerlink" title="1、解析url"></a>1、解析url</h4><p>解析之后得到三个信息，一个协议，一个是web服务器地址，一个是请求文件的路径（可选）</p>
<p>那对于我们前两个是最重要的，</p>
<p>这时候我们客户端生产自己的http请求报文，格式如下，方法get，url没有默认index什么的，版本http1.1，字段名就很多，然后是数据，这个数据也是后面一种包装的根数据。</p>
<p><img src="/../images/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C%E5%A4%8D%E4%B9%A01/image-20230728193306158.png" alt="image-20230728193306158">	</p>
<p>如图所示，一个是请求一个是响应报文</p>
<p>到这里消息成功生产，那我们生产出一个消息之后就要开始发送？那应该怎么发？往哪里发？</p>
<p>这就需要下面的知识。</p>
<h2 id="地址查询-——-DNS"><a href="#地址查询-——-DNS" class="headerlink" title="地址查询 —— DNS"></a>地址查询 —— DNS</h2><p>基于我们已经拿到的web服务器域名，我们可以先去浏览器缓存里面找有没有，如果有，就直接返回，如果没有那就问操作系统的缓存再去看hosts文件，如果都没有，那就看走下面</p>
<p>客户端首先会发出一个 DNS 请求，问 <a target="_blank" rel="noopener" href="http://www.xx.com/">www.xx.com</a> 的 IP 是啥，发给本地 DNS 服务器（也就是客户端的 TCP&#x2F;IP 设置中填写的 DNS 服务器地址）。</p>
<p>本地域名服务器收到客户端的请求后，如果缓存里的表格能找到 <a target="_blank" rel="noopener" href="http://www.xx.com,则它直接返回/">www.xx.com，则它直接返回</a> IP 地址。如果没有，本地 DNS 会去问它的根域名服务器：“老大， 能告诉我 <a target="_blank" rel="noopener" href="http://www.xx.com/">www.xx.com</a> 的 IP 地址吗？” 根域名服务器是最高层次的，它不直接用于域名解析，但能指明一条道路。</p>
<p>根 DNS 收到来自本地 DNS 的请求后，发现后置是 .com，说：“<a target="_blank" rel="noopener" href="http://www.xx.com/">www.xx.com</a> 这个域名归 .com 区域管理”，我给你 .com 顶级域名服务器地址给你，你去问问它吧。”</p>
<p>本地 DNS 收到顶级域名服务器的地址后，发起请求问“老二， 你能告诉我 <a target="_blank" rel="noopener" href="http://www.xx.com/">www.xx.com</a> 的 IP 地址吗？”</p>
<p>顶级域名服务器说：“我给你负责 <a target="_blank" rel="noopener" href="http://www.xx.com/">www.xx.com</a> 区域的权威 DNS 服务器的地址，你去问它应该能问到”。</p>
<p>本地 DNS 于是转向问权威 DNS 服务器：“老三，<a href="http://www.xx.com对应的IP是啥呀？”">www.xx.com对应的IP是啥呀？”</a> server.com 的权威 DNS 服务器，它是域名解析结果的原出处。为啥叫权威呢？就是我的域名我做主。</p>
<p>权威 DNS 服务器查询后将对应的 IP 地址 X.X.X.X 告诉本地 DNS。</p>
<p>本地 DNS 再将 IP 地址返回客户端，客户端和目标建立连接</p>
<p><img src="/../images/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C%E5%A4%8D%E4%B9%A01/image-20230728193808617.png" alt="image-20230728193808617"></p>
<p>通过dns或者缓存获取到ip地址之后，我们就要为发送做一些准备，首先浏览器通过调用 Socket 库，来委托协议栈工作。</p>
<p><img src="/../images/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C%E5%A4%8D%E4%B9%A01/image-20230728193955912.png" alt="image-20230728193955912"></p>
<p>说是协议栈，其实就是中间tcp udp ip这些协议。那下面我们就来仔细的看看</p>
<h2 id="TCP"><a href="#TCP" class="headerlink" title="TCP"></a>TCP</h2><p>tcp段的头如下所示：</p>
<p><img src="/../images/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C%E5%A4%8D%E4%B9%A01/image-20230728194108402.png" alt="image-20230728194108402"></p>
<p>TCP 传输数据之前，要先三次握手建立连接</p>
<p>前提：客户端 为closed状态，服务端变成listen状态</p>
<p>连接：</p>
<p>1、客户端向服务端发送连接syn，之后客户端处于syn-sent状态；</p>
<p>2、服务端接收到这个消息之后，会返回一个syn+ack，之后服务端处于syn-rcvd状态</p>
<p>3、客户端收到这个之后，再给服务端发送一个对syn的ack，之后客户端处于establish状态</p>
<p>服务端收到ack也变成了establish状态</p>
<p>所以三次握手目的是<strong>保证双方都有发送和接收的能力</strong>。</p>
<p>假设我们已经建立了连接，我们要发送消息，但是消息要遵循tcp协议，他的消息大小是有限制的，不是每一次都可以发送全部消息。具体要求如下：</p>
<p><img src="/../images/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C%E5%A4%8D%E4%B9%A01/image-20230728195857751.png" alt="image-20230728195857751"></p>
<ul>
<li><code>MTU</code>：一个网络包的最大长度，以太网中一般为 <code>1500</code> 字节。</li>
<li><code>MSS</code>：除去 IP 和 TCP 头部之后，一个网络包所能容纳的 TCP 数据的最大长度</li>
</ul>
<p>所以如果http请求消息超过mss，那么就要分段发送。</p>
<p>到这里我们得到了一个tcp的报文段或者说包，下面我们就要把这个包发送给网络层，因为在传输层我们就是服务应用层，然后对好端口，确定好协议，之后的事情就不归传输层管控了。</p>
<p>到这里，我们的数据包的格式如下所示：</p>
<p><img src="/../images/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C%E5%A4%8D%E4%B9%A01/image-20230728200405680.png" alt="image-20230728200405680"></p>
<h2 id="定位IP"><a href="#定位IP" class="headerlink" title="定位IP"></a>定位IP</h2><p>ip协议的最重要的功能就是寻址和路由，他要做到这两点就需要你遵循ip协议，那么遵循的要求就是你加一个ip头<img src="/../images/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C%E5%A4%8D%E4%B9%A01/image-20230728200452235.png" alt="image-20230728200452235"></p>
<p>加上ip头之后我们就知道了我们的源ip和目的ip地址，那么起点站和终点站就已经知道了</p>
<p>可以现在又有一个小问题，那就是路径怎么规划呢？这时候就需要用到Mac地址</p>
<h2 id="mac地址"><a href="#mac地址" class="headerlink" title="mac地址"></a>mac地址</h2><p><img src="/../images/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C%E5%A4%8D%E4%B9%A01/image-20230728202408619.png" alt="image-20230728202408619"></p>
<ul>
<li>先查询 ARP 缓存，如果其中已经保存了对方的 MAC 地址，就不需要发送 ARP 查询，直接使用 ARP 缓存中的地址。</li>
<li>而当 ARP 缓存中不存在对方 MAC 地址时，则发送 ARP 广播查询</li>
</ul>
<p>也就是说到了网络接口层，要发了，结果不知道往哪里发，这时候就按照上面两步得到mac地址</p>
<p>因为上面已经得到了ip地址，所以直接喊话：这个 IP 地址是谁的？请把你的 MAC 地址告诉我，就得到mac地址了。</p>
<p>到这里数据包还差最后一层包装</p>
<h2 id="出口–网卡"><a href="#出口–网卡" class="headerlink" title="出口–网卡"></a>出口–网卡</h2><p><img src="/../images/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C%E5%A4%8D%E4%B9%A01/image-20230728204942674.png" alt="image-20230728204942674"></p>
<p>最后一层包装就是上面图片提到的报头和起始帧分界符和fcs帧校验序列</p>
<p>网卡驱动获取网络包之后，会将其<strong>复制</strong>到网卡内的缓存区中，接着会在其<strong>开头加上报头和起始帧分界符，在末尾加上用于检测错误的帧校验序列</strong>。</p>
<p>到这里数据包就真正的包装结束了，最后网卡会将包转为电信号，通过网线发送出去。！！</p>
<h2 id="送别者—交换机"><a href="#送别者—交换机" class="headerlink" title="送别者—交换机"></a>送别者—交换机</h2><p>交换机的设计是将网络包<strong>原样</strong>转发到目的地。交换机工作在 MAC 层，也称为<strong>二层网络设备</strong>。</p>
<p>一般在网线接口啊这些地方，其实路由器也可以作为交换机。</p>
<h3 id="交换机的包接收操作"><a href="#交换机的包接收操作" class="headerlink" title="交换机的包接收操作"></a>交换机的包接收操作</h3><p>交换机里的模块将电信号转换为数字信号。</p>
<p>然后通过包末尾的fcs校验错误，没问题就放到缓存区，这部分操作基本和计算机的网卡相同，但交换机的工作方式和网卡不同。</p>
<p>计算机的网卡本身具有 MAC 地址，并通过核对收到的包的接收方 MAC 地址判断是不是发给自己的，如果不是发给自己的则丢弃；相对地，交换机的端口不核对接收方 MAC 地址，而是直接接收所有的包并存放到缓冲区中。因此，和网卡不同，<strong>交换机的端口不具有 MAC 地址</strong>。</p>
<h3 id="查询MAC-地址表"><a href="#查询MAC-地址表" class="headerlink" title="查询MAC 地址表"></a>查询<strong>MAC 地址表</strong></h3><p>如果找到，就发送到相应的端口，如果找不到，那说明该mac地址的设备还没有向我们交换机发送过包，那这时候我们主动的向除了源端口的所有端口都发送一遍，因为后面的设备他自己都有检测功能，所以不需要担心</p>
<p>这时候要么就发送到位，要么就可能离开子网了，离开子网需要用到路由器</p>
<h2 id="出境大门–路由器"><a href="#出境大门–路由器" class="headerlink" title="出境大门–路由器"></a>出境大门–路由器</h2><h3 id="路由器的包接收操作"><a href="#路由器的包接收操作" class="headerlink" title="路由器的包接收操作"></a>路由器的包接收操作</h3><p>首先，电信号到达网线接口部分，路由器中的模块会将电信号转成数字信号，然后通过包末尾的 <code>FCS</code> 进行错误校验。</p>
<p>如果没问题则检查 MAC 头部中的<strong>接收方 MAC 地址</strong>，看看是不是发给自己的包，如果是就放到接收缓冲区中，否则就丢弃这个包。</p>
<p>完成包接收操作之后，路由器就会<strong>去掉</strong>包开头的 MAC 头部。</p>
<p><strong>MAC 头部的作用就是将包送达路由器</strong>，其中的接收方 MAC 地址就是路由器端口的 MAC 地址。因此，当包到达路由器之后，MAC 头部的任务就完成了，于是 MAC 头部就会<strong>被丢弃</strong>。</p>
<p>接下来，路由器会根据 MAC 头部后方的 <code>IP</code> 头部中的内容进行包的转发操作。</p>
<h3 id="路由器的发送操作"><a href="#路由器的发送操作" class="headerlink" title="路由器的发送操作"></a>路由器的发送操作</h3><p>首先，我们需要根据<strong>路由表的网关列</strong>判断对方的地址。</p>
<ul>
<li>如果网关是一个 IP 地址，则这个IP 地址就是我们要转发到的目标地址，<strong>还未抵达终点</strong>，还需继续需要路由器转发。</li>
<li>如果网关为空，则 IP 头部中的接收方 IP 地址就是要转发到的目标地址，也是就终于找到 IP 包头里的目标地址了，说明<strong>已抵达终点</strong>。</li>
</ul>
<p>反正我们从路由表知道了ip地址，那么我们同样用这个地址去查mac地址</p>
<p>接下来是发送方 MAC 地址字段，这里填写输出端口的 MAC 地址。还有一个以太类型字段，填写 <code>0800</code> （十六进制）表示 IP 协议。</p>
<p>网络包完成后，接下来会将其转换成电信号并通过端口发送出去。这一步的工作过程和计算机也是相同的。</p>
<p>发送出去的网络包会通过<strong>交换机</strong>到达下一个路由器。由于接收方 MAC 地址就是下一个路由器的地址，所以交换机会根据这一地址将包传输到下一个路由器。</p>
<h1 id="例子"><a href="#例子" class="headerlink" title="例子"></a>例子</h1><p>这边举个例子<img src="/../images/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C%E5%A4%8D%E4%B9%A01/image-20230729000740012.png" alt="image-20230729000740012"></p>
<p>子网1某个设备想要发送数据给子网2的某个设备</p>
<p>首先源ip和目的ip是知道的，如果只是简单的arp群发这个ip问是谁的ip地址，其实是找不到的，所以判断是否为同一子网，如果不是，就把目的mac改成网关的mac，然后数据发送到网关，这时候官网一查mac地址，发现属于子网2的设备，这时候修改源mac为自己的mac，修改目的mac为设备的地址，从子网2的网卡发出。</p>
<p>大多数情况下一个子网的默认网关就是一个，就基本代表着出口。复杂情况就需要某种选择算法了</p>
<h2 id="Http"><a href="#Http" class="headerlink" title="Http"></a>Http</h2><p>下面我们来讲一下http 也叫超文本传输协议，就是两点之间超越普通文本范畴的文本（包括文本视频图片等等）的一种协议</p>
<h4 id="http常见状态码"><a href="#http常见状态码" class="headerlink" title="http常见状态码"></a>http常见状态码</h4><p>1XX 代表提示信息，表示这是处理的中间状体，后续还有操作</p>
<p>2XX 这个就是成功的状态吗</p>
<p>​	200 普通的正常的成功</p>
<p>​	204 没有body的成功，就是响应头里面没有body数据的意思</p>
<p>​	206 用于分快下载，断点续传，</p>
<p>3XX 代表重定向</p>
<p>​	 301 永久重定向</p>
<p>​	302 临时重定向</p>
<p>​	304缓存重定向，也就是配合协商缓存那一块</p>
<p>4XX 带表客户端的报文错误</p>
<p>​	400 比较笼统的</p>
<p>​	403 禁止范围</p>
<p>​	404 没找到</p>
<p>5XX 代表服务器端端报文错误</p>
<p>​	500 同样比较笼统</p>
<p>​	501 目前不支持</p>
<p>​	502 自身服务器没问题，后续转发的服务器有问题</p>
<p>​	503 请稍后再访问</p>
<h4 id="常见的字段"><a href="#常见的字段" class="headerlink" title="常见的字段"></a>常见的字段</h4><p>host</p>
<p>content-length</p>
<p>content-type</p>
<p>connection </p>
<p>content-encodeing</p>
<h4 id="Http缓存"><a href="#Http缓存" class="headerlink" title="Http缓存"></a>Http缓存</h4><p>包括强制缓存和协商缓存</p>
<p>强制缓存就是浏览器判断缓存没有过期，那我就直接使用浏览器的缓存</p>
<p>实现可以用两个响应头部的字段表示Cache-control和Expires，前者相对时间，后者绝对时间，前者优先级更高，更加精细</p>
<p>协商缓存也是有两种方法</p>
<p>1、请求头部里面的if modified since 和响应头部last- modified</p>
<p>先问浏览器缓存，如果没过期那就是强制缓存，如果过期了，响应信息的头部会有last modified，然后我们会带这个ifmodifiedsince：时间，去访问服务器，服务器看到之后，就拿自己的Last modified去对比 如果没改，返回304，如果改了，返回200</p>
<p>2、Etag 唯一标识</p>
<p>流程一样，但是etag优先级更高，因为 if modified since还是基于时间，而时间本身可能有一些限制。</p>
<p>1、有可能没有修改文件，但是文件的最后修改时间会变化</p>
<p>2、秒级以内的操作也许不能充分做出响应</p>
<h4 id="Http优缺点"><a href="#Http优缺点" class="headerlink" title="Http优缺点"></a>Http优缺点</h4><p>优点：简单，灵活易扩充，应用广泛跨平台</p>
<p>缺点：</p>
<p>1、http无状态的，所以导致一系列相联的操作可能每一次都要反问数据库，那就非常的繁琐</p>
<p>在此基础上出现了cookie技术，他就是通过在请求和响应报文里面增加cookie信息，来控制客户端的状态</p>
<p>2、明文传输。毫无隐私</p>
<p>3、不安全 也是最重要的原因</p>
<p>账号信息不安全</p>
<p>不验证对方的身份</p>
<p>无法证明报文的完整性</p>
<p>对于1.0改进：</p>
<p>1、http1.1在http1.0的基础上提出了长连接，之前是《请求-应答》模式就是你发完应答完，关闭连接，想要进行下一次通信，那就得重新建立连接，现在可以建立一次连接之后，就可以 发收发收发收 只要一方没有明确提出断开连接，那么就一直连着</p>
<p>2、管道通信，http1.1支持管道，就是所有请求都处于管道内部，我们可以发发发，而不需要等他先回复再发第二个，你可以发发发，减少了时间</p>
<p>但是这里有一个问题，http是基于tcp的所以服务端会按照顺序接收请求。</p>
<p>所以说，http1.1可以解决发送端的对头阻塞，但是无法解决接受端的对头阻塞</p>
<p>然而！然而！http1.1默认不开启管道，</p>
<h2 id="HTTPS"><a href="#HTTPS" class="headerlink" title="HTTPS"></a>HTTPS</h2><p>但是安全性的那三个缺点依旧无法得到改善，所以提出了https &#x3D; http + tls</p>
<p>https完美的解决了：窃听风险、篡改风险、冒充风险，其实就是（防止号不会没，内容数据不会被插入一些垃圾广告，访问的网站不是冒充）</p>
<p>所以给予上面这句话，我们可以知道tls他其实做了三件事情：信息加密，校验机制，身份证书</p>
<h3 id="TLS"><a href="#TLS" class="headerlink" title="TLS"></a>TLS</h3><h4 id="1、信息加密"><a href="#1、信息加密" class="headerlink" title="1、信息加密"></a>1、信息加密</h4><p>使用的是混合加密，采用对称加密和非对称加密的结合体，混合加密，就是两种都用到了，非对称加密是在tls握手的时候，对称加密是在传输数据的时候。</p>
<p>非对成加密安全，非对称加密速度更快。</p>
<h4 id="2、校验机制，身份证书，这两个可以一起讲"><a href="#2、校验机制，身份证书，这两个可以一起讲" class="headerlink" title="2、校验机制，身份证书，这两个可以一起讲"></a>2、校验机制，身份证书，这两个可以一起讲</h4><p>对内容先哈希算法，然后用私钥加密哈希结果得到的结果叫数字签名，把数字签名和原本的内容和在一起就相当于认证了</p>
<p>然后现在还是缺一个身份验证的问题，就是这个私钥到底对不对？</p>
<p>这时候需要一个权威机关，就叫CA</p>
<p>整体流程：服务器发送公钥和数字签名发到CA里面，CA用自己的私钥加密服务器的公钥和数字签名，这个就是证书！然后客户端发来请求的时候，服务器就把自己的证书发过去，客户端收到证书，用CA的公钥解密，得到了服务器的公钥和服务器的数字证签名，这个签名我们上面讲了一个是原始内容一个是私钥对于哈希值的加密，那我们怎么验证呢？就是用公钥去解密加密项得到一个哈希值，再对原始内容做同样的哈希操作，判断两个哈希值到底一不一样，一样代表认证成功，否则，认证失败。</p>
<h4 id="TLS的连接"><a href="#TLS的连接" class="headerlink" title="TLS的连接"></a>TLS的连接</h4><p>tls的密钥交换算法不同，那么连接步骤也不同，我们会介绍两种</p>
<h4 id="RSA"><a href="#RSA" class="headerlink" title="RSA"></a>RSA</h4><h5 id="1、客户端-gt-服务端。client-随机数-tls版本好-密码套件，密码套件可以说是一组配置的整合信息罢了"><a href="#1、客户端-gt-服务端。client-随机数-tls版本好-密码套件，密码套件可以说是一组配置的整合信息罢了" class="headerlink" title="1、客户端 &gt; 服务端。client 随机数 + tls版本好+密码套件，密码套件可以说是一组配置的整合信息罢了"></a>1、客户端 &gt; 服务端。client 随机数 + tls版本好+密码套件，密码套件可以说是一组配置的整合信息罢了</h5><h5 id="2、客户端-lt-服务端。server随机数-确认版本号-确认密码套件-自己的数字证书Done"><a href="#2、客户端-lt-服务端。server随机数-确认版本号-确认密码套件-自己的数字证书Done" class="headerlink" title="2、客户端 &lt; 服务端。server随机数+确认版本号+确认密码套件+自己的数字证书Done"></a>2、客户端 &lt; 服务端。server随机数+确认版本号+确认密码套件+自己的数字证书Done</h5><p>当然这里收到之后，先校验，校验流程如下：</p>
<p>首先我们知道了数字签名有原始内容和对于哈希值加密的数字签名，我们对原始内容加密（签名算法），对数字签名解密（CA公钥）</p>
<p>当然，其中有一个问题就是证书的信任问题？为什么？</p>
<p>因为我们得到的证书不一定是CA签发的，假如是中间机构签发的百度证书，那么我们就不能用内置的本地CA证书中的公钥去认证，所以我们先找签发机构，发现是一个中间机构，我们向中间机构请求证书，收到证书后发现这个机构的签发者是CA，那么我们可以用CA去认证中间的这个证书，这个证书被认证了 ，那么百度的也没认证了。</p>
<h4 id="3、客户端-gt-服务端-使用服务器的公钥加密pre-master随机数发给服务端"><a href="#3、客户端-gt-服务端-使用服务器的公钥加密pre-master随机数发给服务端" class="headerlink" title="3、客户端 &gt; 服务端 使用服务器的公钥加密pre-master随机数发给服务端"></a>3、客户端 &gt; 服务端 使用服务器的公钥加密pre-master随机数发给服务端</h4><h5 id="4、客户端-lt-服务端-服务端发送-加密算法改变通知，和握手结束通知"><a href="#4、客户端-lt-服务端-服务端发送-加密算法改变通知，和握手结束通知" class="headerlink" title="4、客户端 &lt; 服务端 服务端发送 加密算法改变通知，和握手结束通知"></a>4、客户端 &lt; 服务端 服务端发送 加密算法改变通知，和握手结束通知</h5><p>这样，两边就都有了三个随机数，算出会话密钥</p>
<p>之后的通信就用会话密钥了</p>
<p>上面这个就是RSA的基本流程，但是基于RSA的https依旧存在《前向安全》的问题，如果服务端私钥泄密，那么所有的tls通讯就将被破解</p>
<h4 id="ECDHE"><a href="#ECDHE" class="headerlink" title="ECDHE"></a>ECDHE</h4><p>1、客户端 &gt; 服务端。client Hello消息。随机数+tls版本好+密码套件。</p>
<p>2、客户端 &lt; 服务端。serverhello消息，随机数+确认版本号+确认密码套件。certificate消息（证书）。ServerKeyExchange消息（选择名为25519的椭圆曲线基点G，生成随机数作为私钥保留本地，用G点和私钥算出公钥，对公钥做签名）。Server Hello Done。</p>
<p>3、客户端 &gt; 服务端 校验证书，用服务端给的信息生成自己的公钥，发送client key exchange发给服务端</p>
<p>至此，双方都有各自的公钥，自己的私钥，曲线基点，所以能算出x</p>
<p>最终的会话密钥（客户端随机数，服务端随机数，x）</p>
<p>算好后，客户端会发一个change cipher spec，开始使用对成算法加密通信</p>
<p>接着，客户端再发一个excryted handshake message消息，把之前的摘要加密，让服务端做个验证。</p>
<p>4、最后，服务端也会有一个同样的操作，发「<strong>Change Cipher Spec</strong>」和「<strong>Encrypted Handshake Message</strong>」消息，如果双方都验证加密和解密没问题，那么握手正式完成。于是，就可以正常收发加密的 HTTP 请求和响应了。</p>
<p>RSA和ECDHE的区别</p>
<ul>
<li>RSA 密钥协商算法「不支持」前向保密，ECDHE 密钥协商算法「支持」前向保密；</li>
<li>使用了 RSA 密钥协商算法，TLS 完成四次握手后，才能进行应用数据传输，而对于 ECDHE 算法，客户端可以不用等服务端的最后一次 TLS 握手，就可以提前发出加密的 HTTP 数据，节省了一个消息的往返时间（这个是 RFC 文档规定的，具体原因文档没有说明，所以这点我也不太明白）；</li>
<li>使用 ECDHE， 在 TLS 第 2 次握手中，会出现服务器端发出的「Server Key Exchange」消息，而 RSA 握手过程没有该消息</li>
</ul>
<h4 id="https怎么实现数据的完整性？"><a href="#https怎么实现数据的完整性？" class="headerlink" title="https怎么实现数据的完整性？"></a>https怎么实现数据的完整性？</h4><p>刚才我们提到了TLS可以解决三个问题，包括完整性，</p>
<p>其实TLS在实现上包括了握手协议和记录协议</p>
<p>​	握手协议就是四次握手+后续加密来保护应用程序</p>
<p>​	记录协议负责保护数据的完整性和来源</p>
<p>所以我们来看记录协议：，他的实现就是负责对消息（http数据）的压缩，加密和数据认证<img src="/../images/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C%E5%A4%8D%E4%B9%A01/image-20230802185945107.png" alt="	"></p>
<p>这里还是应用层，消息被分割后进行压缩，加上消息验证码，加密，加密后加上一个报头，后面就是交给tcp层，传输层</p>
<h4 id="HTTPS一定安全吗"><a href="#HTTPS一定安全吗" class="headerlink" title="HTTPS一定安全吗"></a>HTTPS一定安全吗</h4><p>理论上这个协议是安全的，https其实就是加了个tls协议，那就是问这个tls是不是安全的</p>
<p>而tls就是按四次握手</p>
<p>1、第一种方法：返回的证书，他大概率是伪造的，但是我们如果叫接受了，那就不一样了，你接受了服务器的证书，相当于信任了，那后面的通信就会被监听</p>
<p>2、直接植入根证书也会导致这种情况</p>
<p>所以关键就是对于证书的认证</p>
<h3 id="http1-1-gt-http-2-gt-http3"><a href="#http1-1-gt-http-2-gt-http3" class="headerlink" title="http1.1  -&gt; http 2 -&gt; http3"></a>http1.1  -&gt; http 2 -&gt; http3</h3><h5 id="http1-1在http1-0的基础上增了长连接和管道，解决了发送方的对头阻塞"><a href="#http1-1在http1-0的基础上增了长连接和管道，解决了发送方的对头阻塞" class="headerlink" title="http1.1在http1.0的基础上增了长连接和管道，解决了发送方的对头阻塞"></a>http1.1在http1.0的基础上增了长连接和管道，解决了发送方的对头阻塞</h5><p>缺点：header是没有压缩的，只压缩了body部分，接收方会有对头阻塞，服务端智能被动响应</p>
<h5 id="http2在是基于https的，所以安全性肯定有保障"><a href="#http2在是基于https的，所以安全性肯定有保障" class="headerlink" title="http2在是基于https的，所以安全性肯定有保障"></a>http2在是基于https的，所以安全性肯定有保障</h5><p>1、头部压缩</p>
<p>http1.1报文是【header+body】对于body部分可以通过content- encoding指定比如gzip，但是http1.1对Header不做出处理</p>
<p>http2会压缩头部，如果同时发送多个请求，头是一样的化，协议就会帮你压缩消除重复的部分</p>
<p>这就是HPACK算法，HPACK包括三个部分（静态字典、动态字典、huffman编码）</p>
<p>2、二进制格式</p>
<p>http2不像是http1是纯文本的报文，而是全部改成了二进制，头部和数据题都是二进制，统称帧</p>
<p>3、并发传输，引入了流的机制</p>
<p>一条tcp连接有多个流，每个流可以包含一个或者多个message，这个message就是请求或者响应，message里面有一个或者多个frame帧，不同的http请求有独一无二的帧，所以可以乱序发送，后面会按照streamid组装，<strong>同一 Stream 内部的帧必须是严格有序的</strong></p>
<p>4、服务器主动推送</p>
<p>缺点：</p>
<p>他是基于tcp协议的，tcp是字节流，所以必须保证收到的数据是完整连续的，才会把数据交给应用，如果有一个数据卡住了，那么后面的流都要卡住，那就会触发超时重传，一个tcp连接的http请求都要等待的这个重传成功。</p>
<h5 id="http3，就把tcp换成了udp，但是为了可靠，推出了QUIC"><a href="#http3，就把tcp换成了udp，但是为了可靠，推出了QUIC" class="headerlink" title="http3，就把tcp换成了udp，但是为了可靠，推出了QUIC"></a>http3，就把tcp换成了udp，但是为了可靠，推出了QUIC</h5><p>1、没有对头阻塞</p>
<p>借鉴了http2的流，就是每一个流都有一个自己的滑动窗口，某个流内部的确还是会阻塞，但是各个流之间是相互独立的，一个流阻塞了，另外的流不会阻塞，这样就保证了没有对头阻塞</p>
<p>2、更快连接</p>
<p>因为http2里面tcp和tls是分层的先三次握手然后四次握手，这样需要3个rtt</p>
<p>然后在http3厘米quic内部适合tls一起的，而且只需要一个rtt就可以完成密钥的协商，用的是tls1.3，1.3版本有话了过程，就是说，第一次发送的时候就已经把签名算法、随机数都发给服务端了。</p>
<p>，甚至在第二次可以达到0rtt</p>
<p>3、连接迁移</p>
<p>tcp是四元组，而quic是基于dcp的，他是考连接id来标记通信，所以ip换了也没事</p>
<p>4、头部压缩变成了QPACK，静态表变成91项，动态编码方式换了，</p>
<h4 id="http1-1请求怎么优化"><a href="#http1-1请求怎么优化" class="headerlink" title="http1.1请求怎么优化"></a>http1.1请求怎么优化</h4><p>一方面是http发送的问题，一方面是他本身数据的问题</p>
<p>1、首先肯定是避免http请求：缓存技术</p>
<p>2、减少重定向，这个就是把重定向请求交给代理服务器</p>
<p>3、合并请求，就是把多个访问小文件的请求合并成一个大的</p>
<p>4、延迟发送，只访问看得到的资源</p>
<p>5、无损压缩，accept- encoding：gzip br </p>
<p>6、有损压缩，webP png</p>
<h4 id="https怎么优化"><a href="#https怎么优化" class="headerlink" title="https怎么优化"></a>https怎么优化</h4><p>https对于http多了一个tls，关键就是通过非对成加密握手得到对成加密的会话密钥</p>
<ul>
<li>提高cpu</li>
<li>升级linux </li>
<li>对密钥交换过程进行优化</li>
<li>RSA要四次握手，慢，安全性不高，我们可以缓存eche密钥交换算法，曲线选择x25519，对成加密算法，也可以换aes128</li>
<li>tls升级1.3，升级的地方在于hello和公钥交换两个消息合并成一个消息</li>
<li>证书优化，分为传输优化和验证优化。</li>
</ul>
<p>传输：服务器证书选择椭圆曲线</p>
<p>验证：验证的过程中不仅需要ca还需要是否被ca吊销；crl是吊销列表，ca定期更新，但是实时性不好，ocsp，向ca fan song请求，返回状态，这个增加了请求开销，万一网络不好或者ca繁忙就会出现延迟；oscp stapling，服务器向ca定期查证书状态，然后在握手阶段就直接发给客户端，这样客户端就不用再去请求了。</p>
<ul>
<li>会话复用：session id 和session ticket</li>
</ul>
<p>session id：首次连接后，在内存缓存会话密钥，用session id标识，再次连接的时候，会在hello消息中带上这个，服务器收到这个就从缓存里面找，直接回复会话状态，跳过中间流程</p>
<p>缺点是，内存压力大</p>
<p>session ticket：类似于cookie，把缓存的工作交给客户端，首次连接，会加密这个发给客户端缓存起来，第二次连接，客户端会发送ticket，服务器解密后验证日期是否有效，没问题就恢复会话。</p>

                    
                        


                    
                    
                        <p>
                            <a
                                href="/2023/07/08/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C%E5%A4%8D%E4%B9%A01/#post-footer"
                                class="postShorten-excerpt_link link"
                                aria-label=""
                            >
                                Kommentieren und teilen
                            </a>
                        </p>
                    
                </div>
            
        </div>
        
    </article>
    
    
    <article class="postShorten postShorten--thumbnailimg-bottom">
        <div class="postShorten-wrap">
            
            <div class="postShorten-header">
                <h1 class="postShorten-title">
                    
                        <a
                            class="link-unstyled"
                            href="/2023/07/08/MYSQL%E5%A4%8D%E4%B9%A01/"
                            aria-label=": Mysql复习1"
                        >
                            Mysql复习1
                        </a>
                    
                </h1>
                <div class="postShorten-meta">
    <time datetime="2023-07-08T00:00:00+08:00">
	
		    08 Jul 2023
    	
    </time>
    
        <span>in </span>
        
    <a class="category-link" href="/categories/Java/">Java</a>


    
</div>

            </div>
            
                <div class="postShorten-content">
                    <p>执行一个mysql语句会发生什么？</p>
<h3 id="连接器"><a href="#连接器" class="headerlink" title="连接器"></a>连接器</h3><p>你要有一个和数据库的连接，这时候，接待你的就是连接器</p>
<p>mysql -h ip -P port -u user -p</p>
<p>然后这个连接是tcp连接，所以会比较麻烦，那这样子的话，我就们尽量使用长连接</p>
<p>然而在mysql在执行过程中临时使用的内内存是管理在连接对象里面的，这些资源只有在连接断开的时候才会释放，如果长连接一直进行，可能导致内存占用过大，被系统强行杀掉OOM，可以考虑两种方式解决：</p>
<p>1、定期的断开长连接，比如在程序中加一个判断内存是否占用过大的查询</p>
<p>2、如果你用的是 MySQL 5.7 或更新版本，可以在每次执行一个比较大的操作后，通过执行 mysql_reset_connection 来重新初始化连接资源。这个过程不需要重连和重新做权限验证，但是会将连接恢复到刚刚创建完时的状态。</p>
<h3 id=""><a href="#" class="headerlink" title=""></a></h3><h3 id="查询缓存"><a href="#查询缓存" class="headerlink" title="查询缓存"></a>查询缓存</h3><p>8.0以后不用了，因为缓存命中率很低的，比如一条更新语句会使得缓存里面的所有相关的表全部失效，</p>
<h3 id="分析器"><a href="#分析器" class="headerlink" title="分析器"></a>分析器</h3><p>包括词法分析和语法分析</p>
<p>词法分析就是分析是什么，代表什么意思</p>
<p>语法分析就是分析符不符合语法要求</p>
<h3 id="优化器"><a href="#优化器" class="headerlink" title="优化器"></a>优化器</h3><p>优化器就是确定一个执行效率高的执行方案，比如选择索引、连接表的顺序等等</p>
<h3 id="执行器"><a href="#执行器" class="headerlink" title="执行器"></a>执行器</h3><p>真正的执行</p>
<p>但是更新操作还会涉及两个表的操作，一个是redo log 一个是binlog</p>
<p>这两种日志有以下三点不同。</p>
<ol>
<li>redo log 是 InnoDB 引擎特有的；binlog 是 MySQL 的 Server 层实现的，所有引擎都可以使用。</li>
<li>redo log 是物理日志，记录的是“在某个数据页上做了什么修改”；binlog 是逻辑日志，记录的是这个语句的原始逻辑，比如“给 ID&#x3D;2 这一行的 c 字段加 1 ”。</li>
<li>redo log 是循环写的，空间固定会用完；binlog 是可以追加写入的。“追加写”是指 binlog 文件写到一定大小后会切换到下一个，并不会覆盖以前的日志。</li>
</ol>
<p>这两个日志的配合是使用两阶段提交</p>
<p><img src="/Users/csen/Documents/Amusement/Sen-Blog/source/images/MYSQL1/image-20230805142953314.png" alt="image-20230805142953314"></p>
<p>可以发现将redo log的写入分成了两个阶段，一个是prepare 一个commit</p>
<p>在两阶段提交的情况下，是怎么实现崩溃恢复的呢？<br>首先比较重要的一点是，在写入redo log时，会顺便记录XID，即当前事务id。在写入binlog时，也会写入XID。</p>
<p>如果在写入redo log之前崩溃，那么此时redo log与binlog中都没有，是一致的情况，崩溃也无所谓。</p>
<p>如果在写入redo log prepare阶段后立马崩溃，之后会在崩恢复时，由于redo log没有被标记为commit。于是拿着redo log中的XID去binlog中查找，此时肯定是找不到的，那么执行回滚操作。</p>
<p>如果在写入binlog后立马崩溃，在恢复时，由redo log中的XID可以找到对应的binlog，这个时候直接提交即可。</p>
<p>总的来说，在崩溃恢复后，只要redo log不是处于commit阶段，那么就拿着redo log中的XID去binlog中寻找，找得到就提交，否则就回滚。</p>
<p>在这样的机制下，两阶段提交能在崩溃恢复时，能够对提交中断的事务进行补偿，来确保redo log与binlog的数据一致性。</p>
<h3 id="binlog-记录内容"><a href="#binlog-记录内容" class="headerlink" title="binlog 记录内容"></a>binlog <strong>记录内容</strong></h3><p>binlog应该说是Mysql里最核心的日志， 它记录了除了查询语句(select、show)之外的所有的 <code>DDL</code> 和 <code>DML</code> 语句,也就意味着我们基本上所有对数据库的操作变更都会记录到binlog里面。binlog以事件形式记录，不仅记录了操作的语句，同时还记录了语句所执行的消耗的时间。 binlog 有三种记录格式，分别是ROW、STATEMENT、MIXED。</p>
<p><strong>1、ROW：</strong> 基于变更的数据行进行记录，如果一个update语句修改一百行数据，那么这种模式下就会记录100行对应的记录日志。</p>
<p><strong>2、STATEMENT：</strong>基于SQL语句级别的记录日志，相对于ROW模式，STATEMENT模式下只会记录这个update 的语句。所以此模式下会非常节省日志空间，也避免着大量的IO操作。</p>
<p><strong>3、MIXED：</strong> 混合模式，此模式是ROW模式和STATEMENT模式的混合体，一般的语句修改使用statment格式保存binlog，如一些函数，statement无法完成主从复制的操作，则采用row格式保存binlog。</p>
<p>这三种模式需要注意的是：使用 row 格式的 binlog 时，在进行数据同步或恢复的时候不一致的问题更容易被发现，因为它是基于数据行记录的。而使用 mixed 或者 statement 格式的 binlog 时，很多事务操作都是基于SQL逻辑记录，我们都知道一个SQL在不同的时间点执行它们产生的数据变化和影响是不一样的，所以这种情况下，数据同步或恢复的时候就容易出现不一致的情况。</p>
<h2 id="锁"><a href="#锁" class="headerlink" title="锁"></a>锁</h2><h3 id="全局锁"><a href="#全局锁" class="headerlink" title="全局锁"></a>全局锁</h3><p>典型的使用场景就是做全库的逻辑备份，对所有的表进行 行锁定，从而获取一致性视图，保证数据的完整性。加了全局锁就是只能读</p>
<ul>
<li><p>一旦加了全局锁之后，其他的DDL、 DML全部都处于阻塞状态，但是可以执行DQL语句，也就是处于只读状态，而数据备份就是查询操作。 那么数据在进行逻辑备份的过程中，数据库中的数据就是不会发生变化的，这样就保证了数据的一致性 和完整性 .</p>
</li>
<li><p>语法</p>
<p>1、加全局锁</p>
<figure class="highlight sql"><table><tr><td class="code"><pre><span class="line">flush tables <span class="keyword">with</span> read lock;</span><br></pre></td></tr></table></figure>

<p>2、数据备份</p>
<figure class="highlight sql"><table><tr><td class="code"><pre><span class="line">mysqldump <span class="operator">-</span>uroot <span class="operator">-</span>pxxx db_name <span class="operator">-</span><span class="operator">&gt;</span> xxx.sql;</span><br></pre></td></tr></table></figure>

<p>3、释放锁</p>
<figure class="highlight sql"><table><tr><td class="code"><pre><span class="line">unlock tables;</span><br></pre></td></tr></table></figure></li>
</ul>
<h4 id="数据库中加全局锁，是一个比较重的操作，存在的问题有："><a href="#数据库中加全局锁，是一个比较重的操作，存在的问题有：" class="headerlink" title="数据库中加全局锁，是一个比较重的操作，存在的问题有："></a>数据库中加全局锁，是一个比较重的操作，存在的问题有：</h4><ul>
<li>如果在主库上备份，那么在备份期间都不能执行更新，业务基本上就得停摆。</li>
<li>如果在从库上备份，那么在备份期间从库不能执行主库同步过来的二进制日志（binlog），会导致主从延迟。</li>
</ul>
<p>在InnoDB引擎中，我们可以在备份时加上参数 –single-transaction 参数来完成不加锁的一致 性数据备份。</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">mysqldump --single-transaction -uroot -pxxx db_name -&gt; xxx.sql;</span><br><span class="line"></span><br></pre></td></tr></table></figure>

<h2 id="表级锁"><a href="#表级锁" class="headerlink" title="表级锁"></a>表级锁</h2><p>表级锁，主要分为3类：</p>
<ul>
<li>表锁</li>
<li>元数据锁（meta data lock，MDL）</li>
<li>意向锁</li>
</ul>
<p>表锁</p>
<p>对于表锁，又可以分为2类：</p>
<ul>
<li>表共享读锁（read lock）</li>
<li>表独占写锁（write lock）</li>
</ul>
<p>结论: 读锁不会阻塞其他客户端的读，但是会阻塞写。写锁既会阻塞其他客户端的读，又会阻塞 其他客户端的写。</p>
<h3 id="元数据锁"><a href="#元数据锁" class="headerlink" title="元数据锁"></a>元数据锁</h3><p>再来说说<strong>元数据锁</strong>（MDL）。</p>
<p>我们不需要显示的使用 MDL，因为当我们对数据库表进行操作时，会自动给这个表加上 MDL：</p>
<ul>
<li>对一张表进行 CRUD 操作时，加的是 <strong>MDL 读锁</strong>；</li>
<li>对一张表做结构变更操作的时候，加的是 <strong>MDL 写锁</strong>；</li>
</ul>
<p>MDL 是为了保证当用户对表执行 CRUD 操作时，防止其他线程对这个表结构做了变更。</p>
<p>当有线程在执行 select 语句（ 加 MDL 读锁）的期间，如果有其他线程要更改该表的结构（ 申请 MDL 写锁），那么将会被阻塞，直到执行完 select 语句（ 释放 MDL 读锁）。</p>
<p>反之，当有线程对表结构进行变更（ 加 MDL 写锁）的期间，如果有其他线程执行了 CRUD 操作（ 申请 MDL 读锁），那么就会被阻塞，直到表结构变更完成（ 释放 MDL 写锁）。</p>
<blockquote>
<p>MDL 不需要显示调用，那它是在什么时候释放的?</p>
</blockquote>
<p>MDL 是在事务提交后才会释放，这意味着<strong>事务执行期间，MDL 是一直持有的</strong>。</p>
<p>MDL 加锁过程是系统自动控制，无需显式使用，在访问一张表的时候会自动加上。MDL 锁主要作用是维 护表元数据的数据一致性，在表上有活动事务的时候，不可以对元数据进行写入操作。为了避免DML与 DDL冲突，保证读写的正确性。</p>
<h3 id="意向锁"><a href="#意向锁" class="headerlink" title="意向锁"></a>意向锁</h3><p>我觉得意向锁主要还是解决行锁和表锁之间的冲突问题。</p>
<ul>
<li>在使用 InnoDB 引擎的表里对某些记录加上「共享锁」之前，需要先在表级别加上一个「意向共享锁」；</li>
<li>在使用 InnoDB 引擎的表里对某些纪录加上「独占锁」之前，需要先在表级别加上一个「意向独占锁」；</li>
</ul>
<p>也就是，当执行插入、更新、删除操作，需要先对表加上「意向独占锁」，然后对该记录加行级独占锁。</p>
<p><img src="/../images/MYSQL%E5%A4%8D%E4%B9%A01/20e0f35589584352bd15e817668a0886.png" alt="img"></p>
<p><img src="/../images/MYSQL%E5%A4%8D%E4%B9%A01/6e6b275c2d6d4dfcbbb338be4f61bee9.png" alt="img"></p>
<p>所以，<strong>意向锁的目的是为了快速判断表里是否有记录被加锁</strong>。</p>
<h2 id="行锁"><a href="#行锁" class="headerlink" title="行锁"></a>行锁</h2><p>InnoDB实现了以下两种类型的行锁：</p>
<ul>
<li>共享锁（S）：允许一个事务去读一行，阻止其他事务获得相同数据集的排它锁。</li>
<li>排他锁（X）：允许获取排他锁的事务更新数据，阻止其他事务获得相同数据集的共享锁和排他 锁</li>
</ul>
<p><img src="/Users/csen/Documents/Amusement/Sen-Blog/source/images/MYSQL1/image-20230805221422216.png" alt="image-20230805221422216"></p>
<h1 id="隔离性与隔离级别"><a href="#隔离性与隔离级别" class="headerlink" title="隔离性与隔离级别"></a>隔离性与隔离级别</h1><p><a target="_blank" rel="noopener" href="https://blog.csdn.net/weixin_35794878/article/details/125741468">https://blog.csdn.net/weixin_35794878/article/details/125741468</a></p>
<p>事务就是要保证一组数据库操作，要么全部成功，要么全部失败。在 MySQL 中，事务支持是在引擎层实现的。你现在知道，MySQL 是一个支持多引擎的系统，但并不是所有的引擎都支持事务。比如 MySQL 原生的 MyISAM 引擎就不支持事务，这也是 MyISAM 被 InnoDB 取代的重要原因之一</p>
<p>在谈隔离级别之前，你首先要知道，你隔离得越严实，效率就会越低。因此很多时候，我们都要在二者之间寻找一个平衡点。SQL 标准的事务隔离级别包括：读未提交（read uncommitted）、读提交（read committed）、可重复读（repeatable read）和串行化（serializable ）。下面我逐一为你解释：</p>
<ul>
<li>读未提交是指，一个事务还没提交时，它做的变更就能被别的事务看到。</li>
<li>读提交是指，一个事务提交之后，它做的变更才会被其他事务看到。</li>
<li>可重复读是指，一个事务执行过程中看到的数据，总是跟这个事务在启动时看到的数据是一致的。当然在可重复读隔离级别下，未提交变更对其他事务也是不可见的。</li>
<li>串行化，顾名思义是对于同一行记录，“写”会加“写锁”，“读”会加“读锁”。当出现读写锁冲突的时候，后访问的事务必须等前一个事务执行完成，才能继续执行。</li>
</ul>
<h1 id="事务隔离的实现"><a href="#事务隔离的实现" class="headerlink" title="事务隔离的实现"></a>事务隔离的实现</h1><h2 id="实现隔离级别的方式："><a href="#实现隔离级别的方式：" class="headerlink" title="实现隔离级别的方式："></a>实现隔离级别的方式：</h2><p>事务有四个隔离级别</p>
<p><strong>一级封锁协议 (对应 read uncommited)</strong> 　<br>一级封锁协议是：事务在对需要修改的数据上面（就是在发生修改的瞬间）对其加共享锁（其他事务不能更改，但是可以读取-导致“脏读”），直到事务结束才释放。事务结束包括正常结束（COMMIT）和非正常结束（ROLLBACK）。</p>
<p><strong>二级封锁协议 （对应read commited)</strong>　<br>二级封锁协议是：1）事务在对需要更新的数据上（就是发生更新的瞬间）加排他锁（直到事务结束），防止其他事务读取未提交的数据，这样，也就避免了“脏读”的情况。2）事务对当前被读取的数据上面加共享锁（当读到时加上共享锁），一旦读完该行，立即释放该该行的共享锁-从数据库的底层实现更深入的来理解，既是，数据库会对游标当前的数据上加共享锁，但是当游标离开当前行的时候，立即释放该行的共享锁。</p>
<p><strong>三级封锁协议 （对应reapetable read ）</strong>（默认）<br>三级封锁协议是：二级封锁协议加上事务在读取数据的瞬间必须先对其加共享锁，但是直到事务结束才释放，这样保证了可重复读（既是其他的事务职能读取该数据，但是不能更新该数据）。</p>
<p><strong>最强封锁协议（对应Serialization)</strong><br>四级封锁协议是对三级封锁协议的增强，其实现机制也最为简单，直接对事务中所读取或者更改的数据所在的表加表锁，也就是说，其他事务不能读写该表中的任何数据。这样所有的脏读，不可重复读，幻读，都得以避免</p>
<h3 id="MVCC。"><a href="#MVCC。" class="headerlink" title="MVCC。"></a>MVCC。</h3><p><strong>MVCC</strong> 在 <strong>MySQL InnoDB</strong> 中的实现主要是为了提高数据库并发性能，用更好的方式去处理读-写冲突，做到即使有读写冲突时，也能做到不加锁，非阻塞并发读。可认为MVCC是行级锁的一个变种，但是它在很多情况下避免了加锁操作，因此额外开销更低。</p>
<p>什么是当前读和快照读？<br>在学习 MVCC 多版本并发控制之前，我们必须先了解一下，什么是 MySQL InnoDB 下的当前读和快照读?</p>
<p>当前读<br>像 select lock in share mode (共享锁), select for update; update; insert; delete (排他锁)这些操作都是一种当前读，为什么叫当前读？就是它读取的是记录的最新版本，读取时还要保证其他并发事务不能修改当前记录，会对读取的记录进行加锁</p>
<p>快照读<br>像不加锁的 select 操作就是快照读，即不加锁的非阻塞读；快照读的前提是隔离级别不是串行级别，串行级别下的快照读会退化成当前读；之所以出现快照读的情况，是基于提高并发性能的考虑，快照读的实现是基于多版本并发控制，即 MVCC ,可以认为 MVCC 是行锁的一个变种，但它在很多情况下，避免了加锁操作，降低了开销；既然是基于多版本，即快照读可能读到的并不一定是数据的最新版本，而有可能是之前的历史版本</p>
<p>说白了 MVCC 就是为了实现读-写冲突不加锁，而这个读指的就是快照读, 而非当前读，当前读实际上是一种加锁的操作，是悲观锁的实现<br>当前读，快照读和MVCC的关系</p>
<p>MVCC 多版本并发控制是 「维持一个数据的多个版本，使得读写操作没有冲突」 的概念，只是一个抽象概念，并非实现</p>
<p>因为 MVCC 只是一个抽象概念，要实现这么一个概念，MySQL 就需要提供具体的功能去实现它，「快照读就是 MySQL 实现 MVCC 理想模型的其中一个非阻塞读功能」。而相对而言，当前读就是悲观锁的具体功能实现</p>
<p>要说的再细致一些，快照读本身也是一个抽象概念，再深入研究。MVCC 模型在 MySQL 中的具体实现则是由 3 个隐式字段，undo 日志 ， Read View 等去完成的，具体可以看下面的 MVCC 实现原理</p>
<p>MVCC 能解决什么问题，好处是？<br>数据库并发场景有三种，分别为：</p>
<p>读-读：不存在任何问题，也不需要并发控制<br>读-写：有线程安全问题，可能会造成事务隔离性问题，可能遇到脏读，幻读，不可重复读<br>写-写：有线程安全问题，可能会存在更新丢失问题，比如第一类更新丢失，第二类更新丢失<br>MVCC 带来的好处是？<br>多版本并发控制（MVCC）是一种用来解决读-写冲突的无锁并发控制，也就是为事务分配单向增长的时间戳，为每个修改保存一个版本，版本与事务时间戳关联，读操作只读该事务开始前的数据库的快照。 所以 MVCC 可以为数据库解决以下问题</p>
<p>在并发读写数据库时，可以做到在读操作时不用阻塞写操作，写操作也不用阻塞读操作，提高了数据库并发读写的性能<br>同时还可以解决脏读，幻读，不可重复读等事务隔离问题，但不能解决更新丢失问题<br>小结一下咯<br>简而言之，MVCC 就是因为大佬们，不满意只让数据库采用悲观锁这样性能不佳的形式去解决读-写冲突问题，而提出的解决方案，所以在数据库中，因为有了 MVCC，所以我们可以形成两个组合：</p>
<ul>
<li><code>MVCC + 悲观锁</code><br>MVCC解决读写冲突，悲观锁解决写写冲突</li>
<li><code>MVCC + 乐观锁</code><br>MVCC 解决读写冲突，乐观锁解决写写冲突</li>
</ul>
<p>这种组合的方式就可以最大程度的提高数据库并发性能，并解决读写冲突，和写写冲突导致的问题</p>
<p>MVCC只在repeatable read和read committed两个隔离级别下工作。其他两个隔离级别都和MVCC不兼容，因为read uncommitted总是读取最新的数据行，而不是符合当前事务版本的数据行。而serializable则会对所有读取的行都加锁。</p>
<p><strong>READ COMMITTED —— 每次读取数据前都生成一个ReadView</strong></p>
<p><strong>REPEATABLE READ —— 在第一次读取数据时生成一个ReadView</strong></p>

                    
                        


                    
                    
                        <p>
                            <a
                                href="/2023/07/08/MYSQL%E5%A4%8D%E4%B9%A01/#post-footer"
                                class="postShorten-excerpt_link link"
                                aria-label=""
                            >
                                Kommentieren und teilen
                            </a>
                        </p>
                    
                </div>
            
        </div>
        
    </article>
    
    
    <article class="postShorten postShorten--thumbnailimg-bottom">
        <div class="postShorten-wrap">
            
            <div class="postShorten-header">
                <h1 class="postShorten-title">
                    
                        <a
                            class="link-unstyled"
                            href="/2023/07/08/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C%E5%A4%8D%E4%B9%A03/"
                            aria-label=": 计算机网络复习3"
                        >
                            计算机网络复习3
                        </a>
                    
                </h1>
                <div class="postShorten-meta">
    <time datetime="2023-07-08T00:00:00+08:00">
	
		    08 Jul 2023
    	
    </time>
    
        <span>in </span>
        
    <a class="category-link" href="/categories/Java/">Java</a>


    
</div>

            </div>
            
                <div class="postShorten-content">
                    <h3 id="这一章节就来学习IP协议"><a href="#这一章节就来学习IP协议" class="headerlink" title="这一章节就来学习IP协议"></a>这一章节就来学习IP协议</h3><p>我们知道两个不相连的网络之间的传输其实靠的是ip地址，两个直连的设备之间的用的协议MAC头，</p>
<p>ipv4是32位</p>
<p>我们把这些分成了5类，包括a类，b类，c类，d类，e类</p>
<p>a类是0开头，b类是10开头，c类是11开头，d类是1110开头，然后e类是1111开头</p>
<p>d类用于多播，多播是可以穿透网段的，e类用于留存</p>
<p>然后每个网络号对应的主机号的数量其实是2的主机号次幂-2，因为，主机号全为0指定某个网络，主机号全为1指代某个网络下的所有主机，用于广播</p>
<p>广播是用于对链路中相互连接的主机发送消息</p>
<p>在本网络中的广播叫做本地广播，不同网络之间的叫直接广播、</p>
<p>这种分类方式的好处就是简单，清晰</p>
<p>但是有缺点：</p>
<p>首先同一层次下，没有分类</p>
<p>第二，不能和现实网络很好的适配</p>
<p>所以提出了无分类地址cidr</p>
<p><img src="/../images/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C%E5%A4%8D%E4%B9%A03/image-20230804145043580.png" alt="image-20230804145043580"></p>
<p>我们知道可以通过子网掩码划分出网络号和主机号，那实际上子网掩码还有一个作用，那就是<strong>划分子网</strong>。</p>
<p><strong>子网划分实际上是将主机地址分为两个部分：子网网络地址和子网主机地址</strong></p>
<p>其实就是在a类b类上再分而已</p>
<p>dhcp</p>
<p>先说明一点，DHCP 客户端进程监听的是 68 端口号，DHCP 服务端进程监听的是 67 端口号。</p>
<p>这 4 个步骤：</p>
<ul>
<li>客户端首先发起 <strong>DHCP 发现报文（DHCP DISCOVER）</strong> 的 IP 数据报，由于客户端没有 IP 地址，也不知道 DHCP 服务器的地址，所以使用的是 UDP <strong>广播</strong>通信，其使用的广播目的地址是 255.255.255.255（端口 67） 并且使用 0.0.0.0（端口 68） 作为源 IP 地址。DHCP 客户端将该 IP 数据报传递给链路层，链路层然后将帧广播到所有的网络中设备。</li>
<li>DHCP 服务器收到 DHCP 发现报文时，用 <strong>DHCP 提供报文（DHCP OFFER）</strong> 向客户端做出响应。该报文仍然使用 IP 广播地址 255.255.255.255，该报文信息携带服务器提供可租约的 IP 地址、子网掩码、默认网关、DNS 服务器以及 <strong>IP 地址租用期</strong>。</li>
<li>客户端收到一个或多个服务器的 DHCP 提供报文后，从中选择一个服务器，并向选中的服务器发送 <strong>DHCP 请求报文（DHCP REQUEST</strong>进行响应，回显配置的参数。</li>
<li>最后，服务端用 <strong>DHCP ACK 报文</strong>对 DHCP 请求报文进行响应，应答所要求的参数。</li>
</ul>
<p>一旦客户端收到 DHCP ACK 后，交互便完成了，并且客户端能够在租用期内使用 DHCP 服务器分配的 IP 地址。</p>

                    
                        


                    
                    
                        <p>
                            <a
                                href="/2023/07/08/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C%E5%A4%8D%E4%B9%A03/#post-footer"
                                class="postShorten-excerpt_link link"
                                aria-label=""
                            >
                                Kommentieren und teilen
                            </a>
                        </p>
                    
                </div>
            
        </div>
        
    </article>
    
    
    <article class="postShorten postShorten--thumbnailimg-bottom">
        <div class="postShorten-wrap">
            
            <div class="postShorten-header">
                <h1 class="postShorten-title">
                    
                        <a
                            class="link-unstyled"
                            href="/2023/07/08/%E8%BE%93%E5%85%A5%E7%BD%91%E7%BB%9C%EF%BC%8C%E6%9C%9F%E9%97%B4%E5%8F%91%E7%94%9F%E4%BA%86%E4%BB%80%E4%B9%88/"
                            aria-label=": 输入网络，期间发生了什么？"
                        >
                            输入网络，期间发生了什么？
                        </a>
                    
                </h1>
                <div class="postShorten-meta">
    <time datetime="2023-07-08T00:00:00+08:00">
	
		    08 Jul 2023
    	
    </time>
    
        <span>in </span>
        
    <a class="category-link" href="/categories/Java/">Java</a>


    
</div>

            </div>
            
                <div class="postShorten-content">
                    <h1 id="输入网络，期间发生了什么，或者说两个设备之间是怎么传输的？"><a href="#输入网络，期间发生了什么，或者说两个设备之间是怎么传输的？" class="headerlink" title="输入网络，期间发生了什么，或者说两个设备之间是怎么传输的？"></a>输入网络，期间发生了什么，或者说两个设备之间是怎么传输的？</h1><h2 id="1、解析url"><a href="#1、解析url" class="headerlink" title="1、解析url"></a>1、解析url</h2><p>首先，就是对我们输入的url进行解析，一般可以得到三个信息：协议，web服务器，文件的路径</p>
<p>拿到这三个信息之后我们就可以包装成一个http请求信息</p>
<p>![image-20230728193306158](&#x2F;Users&#x2F;csen&#x2F;Library&#x2F;Application Support&#x2F;typora-user-images&#x2F;image-20230728193306158.png)</p>
<p>如图所示，一个是请求一个是响应报文</p>
<p>那我们生产出一个消息之后就要开始发送？那应该怎么发？往哪里发？</p>
<p>这就需要下面的知识。</p>
<h2 id="地址查询-——-DNS"><a href="#地址查询-——-DNS" class="headerlink" title="地址查询 —— DNS"></a>地址查询 —— DNS</h2><p>基于我们已经拿到的web服务器域名，我们可以先去浏览器缓存里面找有没有，如果有，就直接返回，如果没有那就问操作系统的缓存再去看hosts文件，如果都没有，那就看走下面</p>
<p>客户端首先会发出一个 DNS 请求，问 <a target="_blank" rel="noopener" href="http://www.xx.com/">www.xx.com</a> 的 IP 是啥，并发给本地 DNS 服务器（也就是客户端的 TCP&#x2F;IP 设置中填写的 DNS 服务器地址）。</p>
<p>本地域名服务器收到客户端的请求后，如果缓存里的表格能找到 <a target="_blank" rel="noopener" href="http://www.xx.com,则它直接返回/">www.xx.com，则它直接返回</a> IP 地址。如果没有，本地 DNS 会去问它的根域名服务器：“老大， 能告诉我 <a target="_blank" rel="noopener" href="http://www.xx.com/">www.xx.com</a> 的 IP 地址吗？” 根域名服务器是最高层次的，它不直接用于域名解析，但能指明一条道路。</p>
<p>根 DNS 收到来自本地 DNS 的请求后，发现后置是 .com，说：“<a target="_blank" rel="noopener" href="http://www.xx.com/">www.xx.com</a> 这个域名归 .com 区域管理”，我给你 .com 顶级域名服务器地址给你，你去问问它吧。”</p>
<p>本地 DNS 收到顶级域名服务器的地址后，发起请求问“老二， 你能告诉我 <a target="_blank" rel="noopener" href="http://www.xx.com/">www.xx.com</a> 的 IP 地址吗？”</p>
<p>顶级域名服务器说：“我给你负责 <a target="_blank" rel="noopener" href="http://www.xx.com/">www.xx.com</a> 区域的权威 DNS 服务器的地址，你去问它应该能问到”。</p>
<p>本地 DNS 于是转向问权威 DNS 服务器：“老三，<a href="http://www.xx.com对应的IP是啥呀？”">www.xx.com对应的IP是啥呀？”</a> server.com 的权威 DNS 服务器，它是域名解析结果的原出处。为啥叫权威呢？就是我的域名我做主。</p>
<p>权威 DNS 服务器查询后将对应的 IP 地址 X.X.X.X 告诉本地 DNS。</p>
<p>本地 DNS 再将 IP 地址返回客户端，客户端和目标建立连接</p>
<p>![image-20230728193808617](&#x2F;Users&#x2F;csen&#x2F;Library&#x2F;Application Support&#x2F;typora-user-images&#x2F;image-20230728193808617.png)</p>
<p>通过dns或者缓存获取到ip地址之后，我们就要为发送做一些准备，首先浏览器通过调用 Socket 库，来委托协议栈工作。</p>
<p>![image-20230728193955912](&#x2F;Users&#x2F;csen&#x2F;Library&#x2F;Application Support&#x2F;typora-user-images&#x2F;image-20230728193955912.png)</p>
<p>说是协议栈，其实就是中间tcp udp ip这些协议。那下面我们就来仔细的看看</p>
<h2 id="TCP"><a href="#TCP" class="headerlink" title="TCP"></a>TCP</h2><p>tcp段的头如下所示：</p>
<p>![image-20230728194108402](&#x2F;Users&#x2F;csen&#x2F;Library&#x2F;Application Support&#x2F;typora-user-images&#x2F;image-20230728194108402.png)</p>
<p>TCP 传输数据之前，要先三次握手建立连接</p>
<p>前提：客户端 为closed状态，服务端变成listen状态</p>
<p>连接：</p>
<p>1、客户端向服务端发送连接syn，之后客户端处于syn-sent状态；</p>
<p>2、服务端接收到这个消息之后，会返回一个syn+ack，之后服务端处于syn-rcvd状态</p>
<p>3、客户端收到这个之后，再给服务端发送一个对syn的ack，之后客户端处于establish状态</p>
<p>服务端收到ack也变成了establish状态</p>
<p>所以三次握手目的是<strong>保证双方都有发送和接收的能力</strong>。</p>
<p>假设我们已经建立了连接，我们要发送消息，但是消息要遵循tcp协议，他的消息大小是有限制的，不是每一次都可以发送全部消息。具体要求如下：</p>
<p>![image-20230728195857751](&#x2F;Users&#x2F;csen&#x2F;Library&#x2F;Application Support&#x2F;typora-user-images&#x2F;image-20230728195857751.png)</p>
<ul>
<li><code>MTU</code>：一个网络包的最大长度，以太网中一般为 <code>1500</code> 字节。</li>
<li><code>MSS</code>：除去 IP 和 TCP 头部之后，一个网络包所能容纳的 TCP 数据的最大长度</li>
</ul>
<p>所以如果http请求消息超过mss，那么就要分段发送。</p>
<p>到这里我们得到了一个tcp的报文段或者说包，下面我们就要把这个包发送给网络层，因为在传输层我们就是服务应用层，然后对好端口，确定好协议，之后的事情就不归传输层管控了。</p>
<p>到这里，我们的数据包的格式如下所示：</p>
<p>![image-20230728200405680](&#x2F;Users&#x2F;csen&#x2F;Library&#x2F;Application Support&#x2F;typora-user-images&#x2F;image-20230728200405680.png)</p>
<h2 id="定位IP"><a href="#定位IP" class="headerlink" title="定位IP"></a>定位IP</h2><p>ip协议的最重要的功能就是寻址和路由，他要做到这两点就需要你遵循ip协议，那么遵循的要求就是你加一个ip头![image-20230728200452235](&#x2F;Users&#x2F;csen&#x2F;Library&#x2F;Application Support&#x2F;typora-user-images&#x2F;image-20230728200452235.png)</p>
<p>加上ip头之后我们就知道了我们的源ip和目的ip地址，那么起点站和终点站就已经知道了</p>
<p>可以现在又有一个小问题，那就是路径怎么规划呢？这时候就需要用到Mac地址</p>
<h2 id="mac地址"><a href="#mac地址" class="headerlink" title="mac地址"></a>mac地址</h2><p>![image-20230728202408619](&#x2F;Users&#x2F;csen&#x2F;Library&#x2F;Application Support&#x2F;typora-user-images&#x2F;image-20230728202408619.png)</p>
<ul>
<li>先查询 ARP 缓存，如果其中已经保存了对方的 MAC 地址，就不需要发送 ARP 查询，直接使用 ARP 缓存中的地址。</li>
<li>而当 ARP 缓存中不存在对方 MAC 地址时，则发送 ARP 广播查询</li>
</ul>
<p>也就是说到了网络接口层，要发了，结果不知道往哪里发，这时候就按照上面两步得到mac地址</p>
<p>因为上面已经得到了ip地址，所以直接喊话：这个 IP 地址是谁的？请把你的 MAC 地址告诉我，就得到mac地址了。</p>
<p>到这里数据包还差最后一层包装</p>
<h2 id="出口–网卡"><a href="#出口–网卡" class="headerlink" title="出口–网卡"></a>出口–网卡</h2><p>![image-20230728204942674](&#x2F;Users&#x2F;csen&#x2F;Library&#x2F;Application Support&#x2F;typora-user-images&#x2F;image-20230728204942674.png)</p>
<p>最后一层包装就是上面图片提到的报头和起始帧分界符和fcs帧校验序列</p>
<p>网卡驱动获取网络包之后，会将其<strong>复制</strong>到网卡内的缓存区中，接着会在其<strong>开头加上报头和起始帧分界符，在末尾加上用于检测错误的帧校验序列</strong>。</p>
<p>到这里数据包就真正的包装结束了，最后网卡会将包转为电信号，通过网线发送出去。！！</p>
<h2 id="送别者—交换机"><a href="#送别者—交换机" class="headerlink" title="送别者—交换机"></a>送别者—交换机</h2><p>交换机的设计是将网络包<strong>原样</strong>转发到目的地。交换机工作在 MAC 层，也称为<strong>二层网络设备</strong>。</p>
<p>一般在网线接口啊这些地方，其实路由器也可以作为交换机。</p>
<h3 id="交换机的包接收操作"><a href="#交换机的包接收操作" class="headerlink" title="交换机的包接收操作"></a>交换机的包接收操作</h3><p>交换机里的模块将电信号转换为数字信号。</p>
<p>然后通过包末尾的fcs校验错误，没问题就放到缓存区，这部分操作基本和计算机的网卡相同，但交换机的工作方式和网卡不同。</p>
<p>计算机的网卡本身具有 MAC 地址，并通过核对收到的包的接收方 MAC 地址判断是不是发给自己的，如果不是发给自己的则丢弃；相对地，交换机的端口不核对接收方 MAC 地址，而是直接接收所有的包并存放到缓冲区中。因此，和网卡不同，<strong>交换机的端口不具有 MAC 地址</strong>。</p>
<h3 id="查询MAC-地址表"><a href="#查询MAC-地址表" class="headerlink" title="查询MAC 地址表"></a>查询<strong>MAC 地址表</strong></h3><p>如果找到，就发送到相应的端口，如果找不到，那说明该mac地址的设备还没有向我们交换机发送过包，那这时候我们主动的向除了源端口的所有端口都发送一遍，因为后面的设备他自己都有检测功能，所以不需要担心</p>
<p>这时候要么就发送到位，要么就可能离开子网了，离开子网需要用到路由器</p>
<h2 id="出境大门–路由器"><a href="#出境大门–路由器" class="headerlink" title="出境大门–路由器"></a>出境大门–路由器</h2><h3 id="路由器的包接收操作"><a href="#路由器的包接收操作" class="headerlink" title="路由器的包接收操作"></a>路由器的包接收操作</h3><p>首先，电信号到达网线接口部分，路由器中的模块会将电信号转成数字信号，然后通过包末尾的 <code>FCS</code> 进行错误校验。</p>
<p>如果没问题则检查 MAC 头部中的<strong>接收方 MAC 地址</strong>，看看是不是发给自己的包，如果是就放到接收缓冲区中，否则就丢弃这个包。</p>
<p>完成包接收操作之后，路由器就会<strong>去掉</strong>包开头的 MAC 头部。</p>
<p><strong>MAC 头部的作用就是将包送达路由器</strong>，其中的接收方 MAC 地址就是路由器端口的 MAC 地址。因此，当包到达路由器之后，MAC 头部的任务就完成了，于是 MAC 头部就会<strong>被丢弃</strong>。</p>
<p>接下来，路由器会根据 MAC 头部后方的 <code>IP</code> 头部中的内容进行包的转发操作。</p>
<h3 id="路由器的发送操作"><a href="#路由器的发送操作" class="headerlink" title="路由器的发送操作"></a>路由器的发送操作</h3><p>首先，我们需要根据<strong>路由表的网关列</strong>判断对方的地址。</p>
<ul>
<li>如果网关是一个 IP 地址，则这个IP 地址就是我们要转发到的目标地址，<strong>还未抵达终点</strong>，还需继续需要路由器转发。</li>
<li>如果网关为空，则 IP 头部中的接收方 IP 地址就是要转发到的目标地址，也是就终于找到 IP 包头里的目标地址了，说明<strong>已抵达终点</strong>。</li>
</ul>
<p>反正我们从路由表知道了ip地址，那么我们同样用这个地址去查mac地址</p>
<p>接下来是发送方 MAC 地址字段，这里填写输出端口的 MAC 地址。还有一个以太类型字段，填写 <code>0800</code> （十六进制）表示 IP 协议。</p>
<p>网络包完成后，接下来会将其转换成电信号并通过端口发送出去。这一步的工作过程和计算机也是相同的。</p>
<p>发送出去的网络包会通过<strong>交换机</strong>到达下一个路由器。由于接收方 MAC 地址就是下一个路由器的地址，所以交换机会根据这一地址将包传输到下一个路由器。</p>
<h1 id="例子"><a href="#例子" class="headerlink" title="例子"></a>例子</h1><p>这边举个例子![image-20230729000740012](&#x2F;Users&#x2F;csen&#x2F;Library&#x2F;Application Support&#x2F;typora-user-images&#x2F;image-20230729000740012.png)</p>
<p>子网1某个设备想要发送数据给子网2的某个设备</p>
<p>首先源ip和目的ip是知道的，如果只是简单的arp群发这个ip问是谁的ip地址，其实是找不到的，所以判断是否为同一子网，如果不是，就把目的mac改成网关的mac，然后数据发送到网关，这时候官网一查mac地址，发现属于子网2的设备，这时候修改源mac为自己的mac，修改目的mac为设备的地址，从子网2的网卡发出。</p>
<p>大多数情况下一个子网的默认网关就是一个，就基本代表着出口。复杂情况就需要某种选择算法了</p>

                    
                        


                    
                    
                        <p>
                            <a
                                href="/2023/07/08/%E8%BE%93%E5%85%A5%E7%BD%91%E7%BB%9C%EF%BC%8C%E6%9C%9F%E9%97%B4%E5%8F%91%E7%94%9F%E4%BA%86%E4%BB%80%E4%B9%88/#post-footer"
                                class="postShorten-excerpt_link link"
                                aria-label=""
                            >
                                Kommentieren und teilen
                            </a>
                        </p>
                    
                </div>
            
        </div>
        
    </article>
    
    
    <article class="postShorten postShorten--thumbnailimg-bottom">
        <div class="postShorten-wrap">
            
            <div class="postShorten-header">
                <h1 class="postShorten-title">
                    
                        <a
                            class="link-unstyled"
                            href="/2023/07/08/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C%E5%A4%8D%E4%B9%A02/"
                            aria-label=": 计算机网络复习2"
                        >
                            计算机网络复习2
                        </a>
                    
                </h1>
                <div class="postShorten-meta">
    <time datetime="2023-07-08T00:00:00+08:00">
	
		    08 Jul 2023
    	
    </time>
    
        <span>in </span>
        
    <a class="category-link" href="/categories/Java/">Java</a>


    
</div>

            </div>
            
                <div class="postShorten-content">
                    <h2 id="TCP"><a href="#TCP" class="headerlink" title="TCP"></a>TCP</h2><p>tcp头的格式</p>
<p>源端口目的端口</p>
<p>序列号</p>
<p>确认应答号（也是希望你在一个发送的号）</p>
<p>首部长度 保留 六个控制位 窗口大小（用于流量控制那边的）</p>
<p>校验和 紧急指针</p>
<p>选项</p>
<p>数据</p>
<p>一个tcp连接是由四元组确定的</p>
<p>最大的tcp连接数&#x3D;客户端ip*客户端端口 </p>
<h4 id="UDP只有64位，源端口目的端口包长度校验和数据"><a href="#UDP只有64位，源端口目的端口包长度校验和数据" class="headerlink" title="UDP只有64位，源端口目的端口包长度校验和数据"></a>UDP只有64位，源端口目的端口包长度校验和数据</h4><p>区别：</p>
<p>tcp	udp</p>
<p>一个需要连接 不需要连接</p>
<p>点对点 一对多&#x2F;多对多&#x2F;一对一</p>
<p>tcp有拥塞控制流量控制	udp没有无所谓</p>
<p>首部长	首部短</p>
<p>流式传输无边界	包传输有边界</p>
<p>分片msstcp	ucp在ip分片</p>
<h4 id="UDP和TCP可以共用一个端口，因为是完全独立的两个软件模块"><a href="#UDP和TCP可以共用一个端口，因为是完全独立的两个软件模块" class="headerlink" title="UDP和TCP可以共用一个端口，因为是完全独立的两个软件模块"></a>UDP和TCP可以共用一个端口，因为是完全独立的两个软件模块</h4><h4 id="为什么不能两次握手？"><a href="#为什么不能两次握手？" class="headerlink" title="为什么不能两次握手？"></a>为什么不能两次握手？</h4><h4 id="1、在两次握手的时候，服务端没有中间状态给客户端来阻止历史连接，也就是服务端会多建立一个历史连接浪费资源，因为收到syn就变成established"><a href="#1、在两次握手的时候，服务端没有中间状态给客户端来阻止历史连接，也就是服务端会多建立一个历史连接浪费资源，因为收到syn就变成established" class="headerlink" title="1、在两次握手的时候，服务端没有中间状态给客户端来阻止历史连接，也就是服务端会多建立一个历史连接浪费资源，因为收到syn就变成established"></a>1、在两次握手的时候，服务端没有中间状态给客户端来阻止历史连接，也就是服务端会多建立一个历史连接浪费资源，因为收到syn就变成established</h4><h4 id="2、同步序列号"><a href="#2、同步序列号" class="headerlink" title="2、同步序列号"></a>2、同步序列号</h4><h4 id="3、避免资源浪费，因为万一第一个syn报文阻塞了，那么就要重复发送多次syn报文，如果是两次握手，那就需要建立多个连接"><a href="#3、避免资源浪费，因为万一第一个syn报文阻塞了，那么就要重复发送多次syn报文，如果是两次握手，那就需要建立多个连接" class="headerlink" title="3、避免资源浪费，因为万一第一个syn报文阻塞了，那么就要重复发送多次syn报文，如果是两次握手，那就需要建立多个连接"></a>3、避免资源浪费，因为万一第一个syn报文阻塞了，那么就要重复发送多次syn报文，如果是两次握手，那就需要建立多个连接</h4><h4 id="为什么，每次建立连接序列号都要求不一样？"><a href="#为什么，每次建立连接序列号都要求不一样？" class="headerlink" title="为什么，每次建立连接序列号都要求不一样？"></a>为什么，每次建立连接序列号都要求不一样？</h4><p>1、防止历史报文被下一个相同四元组的连接接受（主要原因）</p>
<p>2、防止黑客伪造的相同序列号被接受</p>
<h4 id="那这个序列号是怎么随机产生的？"><a href="#那这个序列号是怎么随机产生的？" class="headerlink" title="那这个序列号是怎么随机产生的？"></a>那这个序列号是怎么随机产生的？</h4><p>rfc提高了序列号ISN随机生成算法：ISN &#x3D; M + F</p>
<p>m是计时器，四微秒+1</p>
<p>F是哈希算法根据四元组推出来的</p>
<h4 id="为什么ip会分片tcp还分片，"><a href="#为什么ip会分片tcp还分片，" class="headerlink" title="为什么ip会分片tcp还分片，"></a>为什么ip会分片tcp还分片，</h4><p>因为ip不能超时重传，所以只能靠tcp，而万一ip层丢了一部分，那么ip层就不能组装成一个完整的tcp报文（头部+数据），也就不可能发给接收方tcp层，所以发送方的tcp层就会重发整个tcp报文，所以我们最好就是自己分片，然后缺什么发什么，直接以MSS为单位就可以了</p>
<p>第一次握手丢失，会发生什么？</p>
<p>其实就是重传，重传的序列号还是要一样的，然后重传的机制需要学习</p>
<p>就是靠tcp_syn_retries决定，假设是3，就要重传三次，<strong>每次超时的时间是上一次的 2 倍</strong>。</p>
<p>第二次握手丢失，会发生什么？</p>
<p>客户端和服务端就会认为自己的没发到，客户端和服务端都触发重传机制，tcp_synack_retries</p>
<p>第三次握手没收到，会发生什么</p>
<p>这里有一点很关键，就是ack报文是不会重传的，所以服务端会认为自己的syn+ack没发到，触发重传机制</p>
<h4 id="半连接状态和全连接状态"><a href="#半连接状态和全连接状态" class="headerlink" title="半连接状态和全连接状态"></a>半连接状态和全连接状态</h4><ul>
<li>半连接队列，也称 SYN 队列；</li>
<li>全连接队列，也称 accept 队列；</li>
</ul>
<p>正常流程：</p>
<ul>
<li>当服务端接收到客户端的 SYN 报文时，会创建一个半连接的对象，然后将其加入到内核的「 SYN 队列」；</li>
<li>接着发送 SYN + ACK 给客户端，等待客户端回应 ACK 报文；</li>
<li>服务端接收到 ACK 报文后，从「 SYN 队列」取出一个半连接对象，然后创建一个新的连接对象放入到「 Accept 队列」；</li>
<li>应用通过调用 <code>accpet()</code> socket 接口，从「 Accept 队列」取出连接对象。</li>
</ul>
<p>所以这样子就出会先一些问题</p>
<p>受到SYN攻击怎么办？就是说半连接状态很多怎么办？</p>
<ul>
<li>调大 netdev_max_backlog；缓冲队列</li>
<li>增大 TCP 半连接队列；</li>
<li>开启 tcp_syncookies；不用建立半连接</li>
<li>减少 SYN+ACK 重传次数</li>
</ul>
<h3 id="TCP四次挥手"><a href="#TCP四次挥手" class="headerlink" title="TCP四次挥手"></a>TCP四次挥手</h3><p><img src="/../images/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C%E5%A4%8D%E4%B9%A02/image-20230803130523828.png" alt="image-20230803130523828"></p>
<p>为什么4次？关键是客户端给服务端发fin报文，说我已经没有数据要发个服务端了，但是这时候服务端可能还有数据要发给客户端，所以需要先处理自己的最后流程，然后给客户端发送一个fin报文，也就是说，第二次握手和第三次握手大概率是不同步的。</p>
<p>特定情况下，可以变成三次</p>
<p>第一次挥手丢失，会发生什么？</p>
<p>客户端收不到来自服务端的ack报文，那么就会触发超时重传，这个次数是由</p>
<p>tcp_orphan_retries决定的</p>
<p>第二次挥手丢失，会发生什么？</p>
<p>首先客户端还是会触发超时重传，这时候因为是单方向的，服务端不会触发超时重传</p>
<p>第三次丢失，会发生什么？</p>
<p>第三次丢失，相当于服务端一直收不到来自客户端的ack，那么服务端会触发超时重传，而客户端已经进入了wait2状态，一直等，如果超过设定的时间，自动关闭</p>
<p>第四次丢失，会发生什么？</p>
<p>服务端一直收不到，那么触发超时重传，这时候因为客户端已经是timewait状态，所以每一次重传都会重置2msl定时器，超过时间就close，而服务端同样的重传几次之后close</p>
<p>msl是报文最大生存时间，ip头有一个ttl字段，这个字段代表可以经历的最大路由数</p>
<p>msl大于等于ttl消耗为0的时间，默认60</p>
<h4 id="为什么需要这个timewait状态"><a href="#为什么需要这个timewait状态" class="headerlink" title="为什么需要这个timewait状态"></a>为什么需要这个timewait状态</h4><p>1、为了防止历史连接中的数据，被后面相同四元组的连接错误的接收，因此 TCP 设计了 TIME_WAIT 状态，状态会持续 <code>2MSL</code> 时长，这个时间<strong>足以让两个方向上的数据包都被丢弃，使得原来连接的数据包在网络中都自然消失，再出现的数据包一定都是新建立连接所产生的</strong></p>
<p>2、也就是说，TIME-WAIT 作用是<strong>等待足够的时间以确保最后的 ACK 能让被动关闭方接收，从而帮助其正常关闭。</strong></p>
<h4 id="出现大量超连接的原因"><a href="#出现大量超连接的原因" class="headerlink" title="出现大量超连接的原因"></a>出现大量超连接的原因</h4><p>没有用长链接</p>
<p>长连接超时（keepalive）</p>
<h4 id="如果建立了连接，结果客户端故障了，不发送消息，但是服务端一直establish"><a href="#如果建立了连接，结果客户端故障了，不发送消息，但是服务端一直establish" class="headerlink" title="如果建立了连接，结果客户端故障了，不发送消息，但是服务端一直establish"></a>如果建立了连接，结果客户端故障了，不发送消息，但是服务端一直establish</h4><p>tcp搞了个保活机制，隔一段时间发送探测报文，没有得到相应则认为tcp死亡，</p>
<p>但是，这个保活机制时间太长了，我们自己在应用层实现一个心跳机制</p>
<p>一般web服务软件都会提供keepalive-timeout状态</p>
<h4 id="如果服务器的进程崩溃了，那发生什么"><a href="#如果服务器的进程崩溃了，那发生什么" class="headerlink" title="如果服务器的进程崩溃了，那发生什么"></a>如果服务器的进程崩溃了，那发生什么</h4><p>其实连接信息是由内核维护的，所以服务端的内核还是会发送fin报文进行四次挥手</p>
<h3 id="超时重传、快速重传、"><a href="#超时重传、快速重传、" class="headerlink" title="超时重传、快速重传、"></a>超时重传、快速重传、</h3><p>超时重传很正常，时间RTO，两倍两倍+</p>
<p>快速重传的问题在于传一个还是传所有，这里引入了SACK机制</p>
<p>SACK就是把收到的数据信息驾到tcp头部的选项里面，告诉发送发我收到了哪些</p>
<p>后面又出现了D-SACK，这是用来告诉发送方哪些被重复接受了了</p>
<h3 id="滑动窗口"><a href="#滑动窗口" class="headerlink" title="滑动窗口"></a>滑动窗口</h3><p>窗口的实现实际上是操作系统开辟的一个缓存空间，发送方主机在等到确认应答返回之前，必须在缓冲区中保留已发送的数据。如果按期收到确认应答，此时数据就可以从缓存区清除</p>
<p>tcp头部里面既有一个字段叫窗口大小，就是用来告诉发送端自己还有多少缓冲区可以使用，所以窗口大小一般由接收方决定</p>
<h3 id="流量控制"><a href="#流量控制" class="headerlink" title="流量控制"></a>流量控制</h3><p>避免发送方的数据填满接收方</p>
<h3 id="拥塞控制"><a href="#拥塞控制" class="headerlink" title="拥塞控制"></a>拥塞控制</h3><p>避免发送方的网络填满整个网络，所以这个协议是很无私的，只要网络发生拥塞，那么tcp就会降低自己的发送量</p>
<p>慢启动 一开始是1，就是可以传1个mss，然后收到应答变成2，4，8，16…..</p>
<p>拥塞避免 触碰到慢启动门限就是用拥塞避免，变成线性的，收到一个ack cwnd增加1&#x2F;cwnd</p>
<p>超时重传，慢启动门限变成cwnd&#x2F;2，cwnd&#x3D;1重新开始慢启动</p>
<p>快速恢复，，cwnd &#x3D; cwnd&#x2F;2，慢启动门限&#x3D; cwnd</p>
<p>cwnd &#x3D; ssthresh + 3</p>
<p>收到重复的数据包 cwnd++</p>
<p>收到新的数据包说明重传成功，cwnd &#x3D; 慢启动门限，进入拥塞避免</p>
<p>如果优化tcp？</p>
<p>从三个方向，三次握手，四次挥手，还有中途的数据传输</p>
<p>三次握手，</p>
<p>客户端，减少重传次数</p>
<p>服务端，增大半连接队列的大小和全连接队列的大小，开启syncookie技术</p>
<p><img src="/../images/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C%E5%A4%8D%E4%B9%A02/image-20230803161404210.png" alt="image-20230803161404210"></p>
<p>四次挥手</p>
<p>关闭连接的方式通常有两种，分别是 RST 报文关闭和 FIN 报文关闭。</p>
<p>如果进程收到 RST 报文，就直接关闭连接了，不需要走四次挥手流程，是一个暴力关闭连接的方式。</p>
<p>安全关闭连接的方式必须通过四次挥手，它由进程调用 <code>close</code> 和 <code>shutdown</code> 函数发起 FIN 报文（shutdown 参数须传入 SHUT_WR 或者 SHUT_RDWR 才会发送 FIN）。</p>
<blockquote>
<p>调用了 close 函数意味着完全断开连接，<strong>完全断开不仅指无法传输数据，而且也不能发送数据。 此时，调用了 close 函数的一方的连接叫做「孤儿连接」，如果你用 netstat -p 命令，会发现连接对应的进程名为空。</strong></p>
<p>使用 close 函数关闭连接是不优雅的。于是，就出现了一种优雅关闭连接的 <code>shutdown</code> 函数，<strong>它可以控制只关闭一个方向的连接</strong></p>
</blockquote>
<p><img src="/../images/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C%E5%A4%8D%E4%B9%A02/image-20230803163142196.png" alt="image-20230803163142196"></p>
<p><img src="/../images/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C%E5%A4%8D%E4%B9%A02/image-20230803163236556.png" alt="image-20230803163236556"></p>
<h4 id="如何理解字节流"><a href="#如何理解字节流" class="headerlink" title="如何理解字节流"></a>如何理解字节流</h4><p>udp操作系统不会对齐拆分，所以每一个udp就是一个消息的边界，操作系统收到udp之后会把他查到队列里面，每一个队列他都是一个udp</p>
<p>然而tcp是会分片的，这时候，接收方如果不知道消息的长度或者边界，是无法读取消息的，</p>
<p>在发送端，当我们调用 send 函数完成数据“发送”以后，数据并没有被真正从网络上发送出去，只是从应用程序拷贝到了操作系统内核协议栈中。</p>
<p>至于什么时候真正被发送，<strong>取决于发送窗口、拥塞窗口以及当前发送缓冲区的大小等条件</strong>。也就是说，我们不能认为每次 send 调用发送的数据，都会作为一个整体完整地消息被发送出去</p>
<p>一般用特殊字符作为边界</p>
<p>自定义消息结构</p>
<h4 id="已经建立的tcp，收到syn会发生什么"><a href="#已经建立的tcp，收到syn会发生什么" class="headerlink" title="已经建立的tcp，收到syn会发生什么"></a>已经建立的tcp，收到syn会发生什么</h4><p>新的syn首先看看端口是不是一样，如果不一样的话，就建立新的连接，老的那个如果一直不发消息就会触发tcp保活机制</p>
<p>如果相同（可能就是宕机重传），其实会返回一个challenge ack，携带正确的序列号的确认号的ack报文，这时候客户端确认号收到这个，发现不是自己期望收到的，就会返回rst，这样，服务器就释放了连接</p>
<h3 id="如果四次挥手过程中，fin包先比数据包到了主动关闭方，那这个数据还会接受吗"><a href="#如果四次挥手过程中，fin包先比数据包到了主动关闭方，那这个数据还会接受吗" class="headerlink" title="如果四次挥手过程中，fin包先比数据包到了主动关闭方，那这个数据还会接受吗"></a>如果四次挥手过程中，fin包先比数据包到了主动关闭方，那这个数据还会接受吗</h3><p>先到的fin包其实是乱序的，所以会进入乱序队列，等数据真正的到了，才会回头检查这个fin，然后给服务端发这个。</p>
<h3 id="如果timewait状态收到syn？会怎么样？"><a href="#如果timewait状态收到syn？会怎么样？" class="headerlink" title="如果timewait状态收到syn？会怎么样？"></a>如果timewait状态收到syn？会怎么样？</h3><p>还是先看序列号时间戳吧，如果确实合法，那应该会重新进入三次握手阶段，</p>
<p>如果不合法，就会返回一个和第四次挥手一样的ack，这时候服务端收到发现不是自己的，就回复一个rst报文</p>
<h3 id="Tcp连接，断电和进程崩溃有什么区别？没有保活机制"><a href="#Tcp连接，断电和进程崩溃有什么区别？没有保活机制" class="headerlink" title="Tcp连接，断电和进程崩溃有什么区别？没有保活机制"></a>Tcp连接，断电和进程崩溃有什么区别？没有保活机制</h3><p>客户端主机崩溃，没有保活机制，那就无法感知到，一直处于establish</p>
<p>进程崩溃，内核还是会发送fin完成4次挥手</p>
<h4 id="客户端主机宕机，又迅速重启"><a href="#客户端主机宕机，又迅速重启" class="headerlink" title="客户端主机宕机，又迅速重启"></a>客户端主机宕机，又迅速重启</h4><p>在客户端主机宕机后，服务端向客户端发送的报文会得不到任何的响应，在一定时长后，服务端就会触发<strong>超时重传</strong>机制，重传未得到响应的报文。</p>
<p>服务端重传报文的过程中，客户端主机重启完成后，客户端的内核就会接收重传的报文，然后根据报文的信息传递给对应的进程：</p>
<ul>
<li>如果客户端主机上<strong>没有</strong>进程绑定该 TCP 报文的目标端口号，那么客户端内核就会<strong>回复 RST 报文，重置该 TCP 连接</strong>；</li>
<li>如果客户端主机上<strong>有</strong>进程绑定该 TCP 报文的目标端口号，由于客户端主机重启后，之前的 TCP 连接的数据结构已经丢失了，客户端内核里协议栈会发现找不到该 TCP 连接的 socket 结构体，于是就会<strong>回复 RST 报文，重置该 TCP 连接</strong>。</li>
</ul>
<p>所以，<strong>只要有一方重启完成后，收到之前 TCP 连接的报文，都会回复 RST 报文，以断开连接</strong></p>
<h4 id="拔掉网线tcp连接还在吗"><a href="#拔掉网线tcp连接还在吗" class="headerlink" title="拔掉网线tcp连接还在吗"></a>拔掉网线tcp连接还在吗</h4><p>在的，tcp连接信息是存储于内核的一个结构体，网线断了，但是结构体不会改变</p>
<ul>
<li>拔掉网线后，有数据传输；<ul>
<li>如果在重传前网线插回去了，那我觉得应该什么事情都没发生</li>
<li>如果没插回去，那么就超时重传几次之后，认为此连接死亡，就断开连接，即使后面插回来了，客户端向服务端发送请求，也不是连接的状态，那么服务端就会返回rst</li>
</ul>
</li>
<li>拔掉网线后，没有数据传输<ul>
<li>如果开启了保活机制，那就探测几次，如果有工作就重制保活时间，如果客户端没有正常工作，就断开连接</li>
<li>如果没有开启保活机制，就一直连着</li>
</ul>
</li>
</ul>
<h4 id="HTTPS-中-TLS-和-TCP-能同时握手吗？"><a href="#HTTPS-中-TLS-和-TCP-能同时握手吗？" class="headerlink" title="HTTPS 中 TLS 和 TCP 能同时握手吗？"></a>HTTPS 中 TLS 和 TCP 能同时握手吗？</h4><p>可能，但是有条件</p>
<ul>
<li><strong>客户端和服务端都开启了 TCP Fast Open 功能，且 TLS 版本是 1.3；</strong></li>
<li><strong>客户端和服务端已经完成过一次通信。</strong></li>
</ul>
<p><img src="/../images/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C%E5%A4%8D%E4%B9%A02/image-20230803205908513.png" alt="image-20230803205908513"></p>
<p>TCP Fast Open定义<br>TCP Fast Open（TFO）是用来加速连续TCP连接的数据交互的TCP协议扩展，原理如下：在TCP三次握手的过程中，当用户首次访问Server时，发送SYN包，Server根据用户IP生成Cookie（已加密），并与SYN-ACK一同发回Client；当Client随后重连时，在SYN包携带TCP Cookie；如果Server校验合法，则在用户回复ACK前就可以直接发送数据；否则按照正常三次握手进行<br><img src="/../images/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C%E5%A4%8D%E4%B9%A02/image-20230803210533146.png" alt="image-20230803210533146"></p>
<p>所以就是在第二次以后的通信过程中，tcp open fast在ack发回来之前直接进行tls1.3</p>
<h4 id="没有accept，能建立tcp连接吗"><a href="#没有accept，能建立tcp连接吗" class="headerlink" title="没有accept，能建立tcp连接吗"></a>没有accept，能建立tcp连接吗</h4><ul>
<li><strong>每一个</strong><code>socket</code>执行<code>listen</code>时，内核都会自动创建一个半连接队列和全连接队列。</li>
<li>第三次握手前，TCP连接会放在半连接队列中，直到第三次握手到来，才会被放到全连接队列中。</li>
<li><code>accept方法</code>只是为了从全连接队列中拿出一条连接，本身跟三次握手几乎<strong>毫无关系</strong>。</li>
<li>出于效率考虑，虽然都叫队列，但半连接队列其实被设计成了<strong>哈希表</strong>，而全连接队列本质是链表。</li>
<li>全连接队列满了，再来第三次握手也会丢弃，此时如果<code>tcp_abort_on_overflow=1</code>，还会直接发<code>RST</code>给客户端。</li>
<li>半连接队列满了，可能是因为受到了<code>SYN Flood</code>攻击，可以设置<code>tcp_syncookies</code>，绕开半连接队列。</li>
<li>客户端没有半连接队列和全连接队列，但有一个<strong>全局hash</strong>，可以通过它实现自连接或TCP同时打开。</li>
</ul>
<h4 id="服务端没有-listen，客户端发起连接建立，会发生什么？"><a href="#服务端没有-listen，客户端发起连接建立，会发生什么？" class="headerlink" title="服务端没有 listen，客户端发起连接建立，会发生什么？"></a>服务端没有 listen，客户端发起连接建立，会发生什么？</h4><p><strong>服务端如果只 bind 了 IP 地址和端口，而没有调用 listen 的话，然后客户端对服务端发起了连接建立，服务端会回 RST 报文</strong></p>
<h4 id="quic怎么实现可靠传输"><a href="#quic怎么实现可靠传输" class="headerlink" title="quic怎么实现可靠传输"></a>quic怎么实现可靠传输</h4><p><img src="/../images/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C%E5%A4%8D%E4%B9%A02/image-20230803212833705.png" alt="image-20230803212833705"></p>
<p>packetheader分为两种</p>
<p>Packet Header 细分这两种：</p>
<ul>
<li>Long Packet Header 用于首次建立连接。</li>
<li>Short Packet Header 用于日常传输数据。</li>
</ul>
<p><img src="/../images/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C%E5%A4%8D%E4%B9%A02/image-20230803213009597.png" alt="image-20230803213009597"></p>
<p>这里packet Number是递增的，即使重传也是递增，这样就可以分清是重传的还是延迟的，比较能清晰的计算出rtt，以及rto</p>
<p>![在前面介绍 Packet Header 时，说到 Packet Number 是严格递增，即使重传报文的 Packet Number 也是递增的，既然重传数据包的 Packet N+M 与丢失数据包的 Packet N 编号并不一致，我们怎么确定这两个数据包的内容一样呢？</p>
<p>所以引入 Frame Header 这一层，<strong>通过 Stream ID + Offset 字段信息实现数据的有序性</strong>，通过比较两个数据包的 Stream ID 与 Stream Offset ，如果都是一致，就说明这两个数据包的内容一致。</p>
<h4 id="QUIC-是如何解决-TCP-队头阻塞问题的？"><a href="#QUIC-是如何解决-TCP-队头阻塞问题的？" class="headerlink" title="QUIC 是如何解决 TCP 队头阻塞问题的？"></a>QUIC 是如何解决 TCP 队头阻塞问题的？</h4><p><strong>QUIC 给每一个 Stream 都分配了一个独立的滑动窗口，这样使得一个连接上的多个 Stream 之间没有依赖关系，都是相互独立的，各自控制的滑动窗口</strong>。</p>
<h3 id="QUIC-是如何做流量控制的？"><a href="#QUIC-是如何做流量控制的？" class="headerlink" title="QUIC 是如何做流量控制的？"></a>QUIC 是如何做流量控制的？</h3><p>TCP 流量控制是通过让「接收方」告诉「发送方」，它（接收方）的接收窗口有多大，从而让「发送方」根据「接收方」的实际接收能力控制发送的数据量。</p>
<p>但是quic是基于udp的，所以他本身没有流量控制，因此需要实现自己的流量控制</p>
<p>QUIC 实现流量控制的方式：</p>
<ul>
<li>通过 window_update 帧告诉对端自己可以接收的字节数，这样发送方就不会发送超过这个数量的数据。 如果消耗数据的长度大于了最大接收窗口的一半发送</li>
<li>通过 BlockFrame 告诉对端由于流量控制被阻塞了，无法发送数据。</li>
</ul>

                    
                        


                    
                    
                        <p>
                            <a
                                href="/2023/07/08/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C%E5%A4%8D%E4%B9%A02/#post-footer"
                                class="postShorten-excerpt_link link"
                                aria-label=""
                            >
                                Kommentieren und teilen
                            </a>
                        </p>
                    
                </div>
            
        </div>
        
    </article>
    
    
    <article class="postShorten postShorten--thumbnailimg-bottom">
        <div class="postShorten-wrap">
            
            <div class="postShorten-header">
                <h1 class="postShorten-title">
                    
                        <a
                            class="link-unstyled"
                            href="/2023/07/08/Kafka/"
                            aria-label=": Kafka知识"
                        >
                            Kafka知识
                        </a>
                    
                </h1>
                <div class="postShorten-meta">
    <time datetime="2023-07-08T00:00:00+08:00">
	
		    08 Jul 2023
    	
    </time>
    
        <span>in </span>
        
    <a class="category-link" href="/categories/Java/">Java</a>


    
</div>

            </div>
            
                <div class="postShorten-content">
                    <h1 id="1、定义"><a href="#1、定义" class="headerlink" title="1、定义"></a>1、定义</h1><p>分布式的基于发布订阅模式的消息队列</p>
<p>主要应用场景包括：<strong>缓存消峰</strong>、<strong>解耦</strong>和<strong>异步通信。</strong></p>
<p>消息队列有两种模式：</p>
<ul>
<li>点对点模式：一个主题，一个消费者，消费者主动拉取数据后，确认收到后会删除数据</li>
<li>发布订阅模式：多个主题，多个消费者独立，不会删除</li>
</ul>
<p><strong>基础架构</strong>：</p>
<p><img src="/../images/Kafka/708e86e70504f41234b05cb3cc30dea7.png" alt="image-20220902125656203"></p>
<p>1）Producer：消息生产者，就是向 Kafka broker 发消息的客户端。</p>
<p>（2）Consumer：消息消费者，向 Kafka broker 取消息的客户端。</p>
<p>（3）Consumer Group（CG）：消费者组，由多个 consumer 组成。消费者组内每个消费者负责消费不同分区的数据，一个分区只能由一个组内消费者消费；消费者组之间互不影响。所有的消费者都属于某个消费者组，即消费者组是逻辑上的一个订阅者。</p>
<p>（4）Broker：一台 Kafka 服务器就是一个 broker。一个集群由多个 broker 组成。一个broker 可以容纳多个 topic。</p>
<p>（5）Topic：可以理解为一个队列，生产者和消费者面向的都是一个 topic。</p>
<p>（6）Partition：为了实现扩展性，一个非常大的 topic 可以分布到多个 broker（即服务器）上，一个 topic 可以分为多个 partition，每个 partition 是一个有序的队列。</p>
<p>（7）Replica：副本。一个 topic 的每个分区都有若干个副本，一个 Leader 和若干个Follower。</p>
<p>（8）Leader：每个分区多个副本的“主”，生产者发送数据的对象，以及消费者消费数据的对象都是 Leader。</p>
<p>（9）Follower：每个分区多个副本中的“从”，实时从 Leader 中同步数据，保持和Leader 数据的同步。Leader 发生故障时，某个 Follower 会成为新的 Leader。</p>
<p>其实总的流程就是生产者发送数据到kafka，然后消费者从kafka拉取数据。所以架构中最主要的就是生产者、kafka集群和消费者这三个，其他的很多知识都是为了这三个服务的。</p>
<h1 id="2、生产者"><a href="#2、生产者" class="headerlink" title="2、生产者"></a>2、生产者</h1><p> 在消息发送的过程中，涉及到两个线程，main线程和sender线程，其中main线程是消息的生产线程，而sender线程是jvm单例的线程，专门用于消息的发送。</p>
<p> 在jvm的内存中开辟了一块缓存空间叫RecordAccumulator（消息累加器），用于将多条消息合并成一个批次，然后由sender线程发送给kafka集群。<br><img src="/../images/Kafka/cd41370a872e70b75435f35692925370.png" alt="image-20220902155220662"></p>
<p>当双端队列中的DQueue满足 batch.size 或者 linger.ms 条件时触发sender线程。</p>
<p>这里我们一步一步看</p>
<p>producer没什么意外，就是生产者，配置好就可以</p>
<p>然后拦截器，就是对这个消息做一个操作，末尾也会有一个，也没什么，相当于留了一个供我们修改的接口</p>
<p>序列化器：这个也没什么奇怪，发送消息，总要给消息一种形式，kafka有自带的</p>
<p>Partitioner：这个需要着重讲一下，我们事先其实是分好了区，但是发送消息的时候发送到那一个区？</p>
<p>这就涉及到发送消息分区策略：</p>
<ul>
<li><p>他有一个默认的分区器DefaultPartitioner，支持三种分区策略 1) 指定分区； 2）指定key，计算hash得分区； 3）指定随机粘性分区（下图）；<img src="/../images/Kafka/18a0b6ba56db8e5b16b3d6fac9ba7fb7.png" alt="image-20220902163808502"></p>
</li>
<li><p>还可以自定义分区器（见代码）</p>
</li>
<li><p>~~~<br>public class MyPartitioner implements Partitioner {<br>&#x2F;**<br> * @param topic 主题<br> * @param key 消息的 key<br> * @param keyBytes 消息的 key 序列化后的字节数组<br> * @param value 消息的 value<br> * @param valueBytes 消息的 value 序列化后的字节数组<br> * @param cluster 集群元数据可以查看分区信息<br> *&#x2F;<br>@Override<br>public int partition(String topic, Object key, byte[] keyBytes, Object value, byte[] valueBytes, Cluster cluster) {<br>    String string &#x3D; value.toString();<br>    if (string.contains(“vi”)){<br>        return 2;<br>    }else{<br>        return 1;<br>    }<br>}<br>}</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line"></span><br><span class="line">  </span><br><span class="line"></span><br><span class="line">然后我们就要依赖</span><br><span class="line"></span><br><span class="line">## **消息累加器（RecordAccumulator）**</span><br><span class="line"></span><br><span class="line">![image-20220902174419992](../images/Kafka/f20e0b29414b41978048b0c263c2f6a4.png)</span><br><span class="line"></span><br><span class="line"> 为了提高生产者的吞吐量，我们通过累加器将多条消息合并成一批统一发送。在broker中将消息批量存入。减少多次的网络IO。</span><br><span class="line"></span><br><span class="line"> 消息累加器默认32m，如果生产者的发送速率大于sender发送的速率，消息就会堆满累加器。生产者就会阻塞，或者报错，报错取决于阻塞时间的配置。</span><br><span class="line"></span><br><span class="line"> 累加器的存储形式为ConcurrentMap&lt;TopicPartition, Deque&lt;ProducerBatch&gt;&gt;，可以看出来就是一个分区对应一个双端队列，队列中存储的是ProducerBatch一般大小是16k根据batch.size配置，新的消息会append到ProducerBatch中，满16k就会创建新的ProducerBatch，并且触发sender线程进行发送。</span><br><span class="line"></span><br><span class="line"> 如果消息量非常大，生成了大量的ProducerBatch，在发送后，又需要JVM通过GC回收这些ProducerBatch就变得非常影响性能，所以kafka通过 BufferPool作为内存池来管理ProducerBatch的创建和回收，需要申请一个新的ProducerBatch空间时，调用 free.allocate(size, maxTimeToBlock)找内存池申请空间。</span><br><span class="line"></span><br><span class="line">如果单条消息大于16k，那么就不会复用内存池了，会生成一个更大的ProducerBatch专门存放大消息，发送完后GC回收该内存空间。</span><br><span class="line"></span><br><span class="line">接着就是</span><br><span class="line"></span><br><span class="line">## **消息发送线程（Sender）**</span><br><span class="line"></span><br><span class="line"> 消息保存在内存后，Sender线程就会把符合条件的消息按照批次进行发送， Sender线程默认容纳5个未确认的消息，消息发送失败后会进行重试。</span><br><span class="line"></span><br><span class="line">## 生产者提高吞吐量</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br></pre></td></tr></table></figure>
<p> &#x2F;&#x2F; batch.size：批次大小，默认 16K<br>properties.put(ProducerConfig.BATCH_SIZE_CONFIG, 16384);<br>&#x2F;&#x2F; linger.ms：等待时间，默认 0<br>properties.put(ProducerConfig.LINGER_MS_CONFIG, 1);<br>&#x2F;&#x2F; RecordAccumulator：缓冲区大小，默认 32M：buffer.memory<br>properties.put(ProducerConfig.BUFFER_MEMORY_CONFIG,33554432);</p>
</li>
</ul>
<p>&#x2F;&#x2F; compression.type：压缩，默认 none，可配置值 gzip、snappy、lz4 和 zstd<br>properties.put(ProducerConfig.COMPRESSION_TYPE_CONFIG, “snappy”);</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line"></span><br><span class="line">发送方发送消息到kafka集群，这一段路 也保证数据的可靠性</span><br><span class="line"></span><br><span class="line">## 生产经验—数据可靠性</span><br><span class="line"></span><br><span class="line">### 消息确认机制-ACK</span><br><span class="line"></span><br><span class="line">producer提供了三种消息确认的模式，通过配置acks来实现</span><br><span class="line"></span><br><span class="line">acks为0时， 表示生产者将数据发送出去就不管了，不等待任何返回。这种情况下数据传输效率最高，但是数据可靠性最低，当 server挂掉的时候就会丢数据；</span><br><span class="line"></span><br><span class="line">acks为1时（默认），表示数据发送到Kafka后，经过leader成功接收消息的的确认，才算发送成功，如果leader宕机了，就会丢失数据。</span><br><span class="line"></span><br><span class="line">acks为-1/all时，表示生产者需要等待ISR中的所有follower都确认接收到数据后才算发送完成，这样数据不会丢失，因此可靠性最高，性能最低。</span><br><span class="line"></span><br><span class="line">数据完全可靠条件 = ACK级别设置为-1 + 分区副本大于等于2 + ISR里应答的最小副本数量大于等于2</span><br><span class="line"></span><br><span class="line">![image-20220902172535966](../images/Kafka/a5c1a40450861d56bfc5cce44746a8a6.png)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">AR = ISR + ORS</span><br><span class="line"></span><br><span class="line">ISR 表示在指定时间内和leader保存数据同步的集合；</span><br><span class="line"></span><br><span class="line">ORS表示不能在指定的时间内和leader保持数据同步集合，称为OSR(Out-Sync Relipca set)。</span><br><span class="line"></span><br><span class="line">### 数据去重-幂等性</span><br><span class="line"></span><br><span class="line">1）幂等性原理</span><br><span class="line"></span><br><span class="line">在一般的MQ模型中，常有以下的消息通信概念</span><br><span class="line"></span><br><span class="line">至少一次（At Least Once）： ACK级别设置为-1 + 分区副本大于等于2 + ISR里应答的最小副本数量&gt;=2。可以保证数据不丢失，但是不能保证数据不重复。</span><br><span class="line">最多一次（At Most Once）：ACK级别设置为0 。可以保证数据不重复，但是不能保证数据不丢失。•</span><br><span class="line">精确一次（Exactly Once）：至少一次 + 幂等性 。 Kafka 0.11版本引入一项重大特性：幂等性和事务。</span><br><span class="line"> 幂等性，简单地说就是对接口的多次调用所产生的结果和调用一次是一致的。生产者在进行重试的时候有可能会重复写入消息，而使用Kafka 的幂等性功能之后就可以避免这种情况。（不产生重复数据）</span><br><span class="line"></span><br><span class="line"> 重复数据的判断标准：具有&lt;PID, Partition, SeqNumber&gt;相同主键的消息提交时，Broker只会持久化一条。其</span><br><span class="line"></span><br><span class="line">中ProducerId（pid）是Kafka每次重启都会分配一个新的；Partition 表示分区号；Sequence Number 序列化号，是单调自增的。</span><br><span class="line"></span><br><span class="line"> broker中会在内存维护一个pid+分区对应的序列号。如果收到的序列号正好比内存序列号大一，才存储消息，如果小于内存序列号，意味着消息重复，那么会丢弃消息，并应答。如果远大于内存序列号，意味着消息丢失，会抛出异常。</span><br><span class="line"></span><br><span class="line">所以幂等解决的是sender到broker间，由于网络波动可能造成的重发问题。用幂等来标识唯一消息。</span><br><span class="line"></span><br><span class="line">并且幂等性只能保证的是在单分区单会话内不重复。</span><br><span class="line"></span><br><span class="line">2）如何使用幂等性</span><br><span class="line"></span><br><span class="line"> 开启幂等性功能的方式很简单，只需要显式地将生产者客户端参数enable.idempotence设置为true即可(这个参数的默认值为true)，并且还需要确保生产者客户端的retries、acks、max.in.filght.request.per.connection参数不被配置错，默认值就是对的。</span><br><span class="line"></span><br><span class="line">### 消息事务</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">由于幂等性不能跨分区运作，为了保证同时发的多条消息，要么全成功，要么全失败。kafka引入了事务的概念。</span><br><span class="line"></span><br><span class="line">开启事务需要producer设置transactional.id的值并同时开启幂等性。</span><br><span class="line"></span><br><span class="line">通过事务协调器，来实现事务，工作流程如下：</span><br><span class="line"></span><br><span class="line">![image-20220902183826203](../images/Kafka/4d210e935a7af0d15c3caa53e08f4e9e.png)</span><br><span class="line"></span><br><span class="line">### 消息顺序</span><br><span class="line"></span><br><span class="line">kafka只能保证单分区下的消息顺序性，为了保证消息的顺序性，需要做到如下几点。</span><br><span class="line"></span><br><span class="line">如果未开启幂等性，需要 max.in.flight.requests.per.connection 设置为1。（缓冲队列最多放置1个请求）</span><br><span class="line"></span><br><span class="line">如果开启幂等性，需要 max.in.flight.requests.per.connection 设置为小于5。</span><br><span class="line"></span><br><span class="line">这是因为broker端会缓存producer主题分区下的五个request，保证最近5个request是有序的。</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"># 3、Broker</span><br><span class="line"></span><br><span class="line">## Broker设计</span><br><span class="line"></span><br><span class="line"> 我们都知道kafka能堆积非常大的数据，一台服务器，肯定是放不下的。由此出现的集群的概念，集群不仅可以让消息负载均衡，还能提高消息存取的吞吐量。kafka集群中，会有多台broker，每台broker分别在不同的机器上。为了提高吞吐量，每个topic也会都多个分区，同时为了保持可靠性，每个分区还会有多个副本。这些分区副本被均匀的散落在每个broker上，其中每个分区副本中有一个副本为leader，其他的为follower。</span><br><span class="line"></span><br><span class="line">![image-20220902195939625](../images/Kafka/37643c8b56fe0f32a3b9d7c803f85b0b.png)</span><br><span class="line"></span><br><span class="line">## Zookeeper</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line">Zookeeper在Kafka中扮演了重要的角色，kafka使用zookeeper进行元数据管理，保存broker注册信息，包括主题（Topic）、分区（Partition）信息等，选择分区leader。</span><br><span class="line"></span><br><span class="line">![image-20220902200249692](../images/Kafka/b1f0ebc535b00384be6bf81540c5f416.png)</span><br><span class="line"></span><br><span class="line">## Broker选举Leader</span><br><span class="line"></span><br><span class="line">Kafka由三个方面会涉及到选举：</span><br><span class="line"></span><br><span class="line">- broker（控制器）选leader</span><br><span class="line"></span><br><span class="line">- 分区多副本选leader</span><br><span class="line">- 消费者选Leader</span><br><span class="line"></span><br><span class="line"> 在kafka集群中由很多的broker（也叫做控制器），但是他们之间需要选举出一个leader，其他的都是follower。broker的leader有很重要的作用，诸如：创建、删除主题、增加分区并分配leader分区；集群broker管理，包括新增、关闭和故障处理；分区重分配（auto.leader.rebalance.enable=true，后面会介绍），分区leader选举。</span><br><span class="line"></span><br><span class="line"> 每个broker都有唯一的brokerId，他们在启动后会去竞争注册zookeeper上的Controller结点，谁先抢到，谁就是broker leader。而其他broker会监听该结点事件，以便后续leader下线后触发重新选举。</span><br><span class="line"></span><br><span class="line">- broker（控制器）选leader</span><br><span class="line"></span><br><span class="line">![image-20220902200901222](../images/Kafka/12b4f076e8f82c66b00ec8782433649f.png)</span><br><span class="line"></span><br><span class="line">- 分区多副本选leader![image-20220902201352868](../images/Kafka/e5c14b9c17123faf3eefa58a22ab0668-20230928225949575.png)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line">## 副本机制</span><br><span class="line"></span><br><span class="line">- replica ：副本，同一分区的不同副本保存的是相同的消息，为保证集群中的某个节点发生故障时，该节点上的 partition 数据不丢失 ，提高副本可靠性，且 kafka 仍然能够继续工作，kafka 提供了副本机制，一个 topic 的每个分区都有若干个副本，一个 leader 和若干个 follower。</span><br><span class="line"></span><br><span class="line">- Leader ：每个分区的多个副本中的&quot;主副本&quot;，生产者以及消费者只与 Leader 交互。</span><br><span class="line">- Follower ：每个分区的多个副本中的&quot;从副本&quot;，负责实时从 Leader 中同步数据，保持和 Leader 数据的同步。Leader 发生故障时，从 Follower 副本中重新选举新的 Leader 副本对外提供服务。</span><br><span class="line">- **LEO**:每个副本都有内部的LEO，代表当前队列消息的最后一条偏移量offset + 1。</span><br><span class="line">- **HW**:高水位，代表所有ISR中的LEO最低的那个offset，也是消费者可见的最大消息offset。</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line">![image-20220902201925254](../images/Kafka/1c5cd091fee1ef3c76fcc1c13dccf7de.png)</span><br><span class="line"></span><br><span class="line"> Kafka 集群中有一个 broker 的 Controller 会被选举为 Controller Leader (4.2.2) ，负责管理集群Broker 的上下线，所有 topic 的分区副本分配和 Leader 选举等工作</span><br><span class="line"></span><br><span class="line"> Broker中Controller 的信息同步工作是依赖于 Zookeeper 的 ./broker/topic 目录下的信息。</span><br><span class="line"></span><br><span class="line">## 副本故障处理</span><br><span class="line"></span><br><span class="line">### **1.follower故障流程**</span><br><span class="line"></span><br><span class="line">![image-20220902210759125](../images/Kafka/b01dad78f006b40d82e719fe71caeb78.png)</span><br><span class="line"></span><br><span class="line">### 2.leader故障流程</span><br><span class="line"></span><br><span class="line">旧Leader先被从ISR队列中踢出，然后从ISR中选出一个新的Leader来；此时为了保证多个副本之间的数据一致性，其他的follower会先将各自的log文件中高于HW的部分截取掉，然后从新的leader同步数据（由此可知这只能保证副本之间数据一致性，并不能保证数据不丢失或者不重复）。体现了设置ACK-all的重要性。</span><br><span class="line">![image-20220902210830344](../images/Kafka/1f96e55810be5ff8cbf64c04b5d37315.png)</span><br><span class="line"></span><br><span class="line">## kafka分区策略</span><br><span class="line"></span><br><span class="line">如果 kafka 服务器只有 4 个节点，那么设置 kafka 的分区数大于服务器台数，在 kafka底层如何分配存储副本呢？</span><br><span class="line"></span><br><span class="line">- 这里如果用默认的就是如下</span><br><span class="line"></span><br><span class="line">![image-20220902211334365](../images/Kafka/15514da0f22aca9e3017fa2305733ba4.png)</span><br><span class="line"></span><br><span class="line">- 也可以手动指定~~~</span><br><span class="line"></span><br></pre></td></tr></table></figure>
<p>$ vim increase-replication-factor.json<br>输入如下内容：<br>{<br>“version”:1,<br>“partitions”:[<br>{“topic”:”three”,”partition”:0,”replicas”:[0,1]},<br>{“topic”:”three”,”partition”:1,”replicas”:[0,1]},<br>{“topic”:”three”,”partition”:2,”replicas”:[1,0]},<br>{“topic”:”three”,”partition”:3,”replicas”:[1,0]}]<br>}</p>
<p>~~~</p>
<h4 id="分区自动调整"><a href="#分区自动调整" class="headerlink" title="分区自动调整"></a><strong>分区自动调整</strong></h4><p>随着一些broker故障，会慢慢出现leader集中在某台broker上的情况，造成集群负载不均衡，这时候就需要分区平衡。</p>
<p><img src="/../images/Kafka/watermark,type_d3F5LXplbmhlaQ,shadow_50,text_Q1NETiBA6Zi_5piM5Zac5qyi5ZCD6buE5qGD,size_20,color_FFFFFF,t_70,g_se,x_16.png" alt="在这里插入图片描述"></p>
<h2 id="文件存储"><a href="#文件存储" class="headerlink" title="文件存储"></a>文件存储</h2><h5 id="①文件存储机制"><a href="#①文件存储机制" class="headerlink" title="①文件存储机制"></a>①文件存储机制</h5><p><img src="/../images/Kafka/watermark,type_d3F5LXplbmhlaQ,shadow_50,text_Q1NETiBA6Zi_5piM5Zac5qyi5ZCD6buE5qGD,size_20,color_FFFFFF,t_70,g_se,x_16-20230928232748011.png" alt="在这里插入图片描述"></p>
<h5 id="②思考：Topic-数据到底存储-在什么位置？"><a href="#②思考：Topic-数据到底存储-在什么位置？" class="headerlink" title="②思考：Topic 数据到底存储 在什么位置？"></a>②思考：Topic 数据到底存储 在什么位置？</h5><p><img src="/../images/Kafka/watermark,type_d3F5LXplbmhlaQ,shadow_50,text_Q1NETiBA6Zi_5piM5Zac5qyi5ZCD6buE5qGD,size_20,color_FFFFFF,t_70,g_se,x_16-20230928232838576.png" alt="在这里插入图片描述"></p>
<h5 id="③index-文件和-log-文件详解"><a href="#③index-文件和-log-文件详解" class="headerlink" title="③index 文件和 log 文件详解"></a>③index 文件和 log 文件详解</h5><p><img src="/../images/Kafka/watermark,type_d3F5LXplbmhlaQ,shadow_50,text_Q1NETiBA6Zi_5piM5Zac5qyi5ZCD6buE5qGD,size_20,color_FFFFFF,t_70,g_se,x_16-20230928233003817.png" alt="在这里插入图片描述"></p>
<h2 id="文件清理策略"><a href="#文件清理策略" class="headerlink" title="文件清理策略"></a>文件清理策略</h2><p>Kafka将消息存储在磁盘中，为了控制磁盘占用空间的不断增加就需要对消息做一定的清理操作。Kafka 中每一个分区副本都对应一个Log，而Log又可以分为多个日志分段，这样也便于日志的清理操作。Kafka提供了两种日志清理策略。</p>
<p>日志删除(delete) :按照一定的保留策略直接删除不符合条件的日志分段。<br>日志压缩(compact) :针对每个消息的key进行整合，对于有相同key的不同value值，只保留最后一个版本。</p>
<p><img src="/../images/Kafka/watermark,type_d3F5LXplbmhlaQ,shadow_50,text_Q1NETiBA6Zi_5piM5Zac5qyi5ZCD6buE5qGD,size_20,color_FFFFFF,t_70,g_se,x_16-20230928233204011.png" alt="在这里插入图片描述"></p>
<p><img src="/../images/Kafka/watermark,type_d3F5LXplbmhlaQ,shadow_50,text_Q1NETiBA6Zi_5piM5Zac5qyi5ZCD6buE5qGD,size_20,color_FFFFFF,t_70,g_se,x_16-20230928233315113.png" alt="在这里插入图片描述"></p>
<h2 id="Kafka高效读数据"><a href="#Kafka高效读数据" class="headerlink" title="Kafka高效读数据"></a><strong>Kafka高效读数据</strong></h2><p>kafka之所以可以快速读写的原因如下：</p>
<ol>
<li>kafka是分布式集群，采用分区方式，并行操作</li>
<li>读取数据采用稀疏索引，可以快速定位消费数据</li>
<li>顺序写磁盘</li>
<li>页缓冲和零拷贝</li>
</ol>
<p><img src="/../images/Kafka/eeb8531c34ed091d57d9be10590839c5.png" alt="image-20220902214803709"></p>
<p><img src="/../images/Kafka/watermark,type_d3F5LXplbmhlaQ,shadow_50,text_Q1NETiBA6Zi_5piM5Zac5qyi5ZCD6buE5qGD,size_20,color_FFFFFF,t_70,g_se,x_16-20230928233417216.png" alt="在这里插入图片描述"></p>
<h1 id="4、kafka消费者"><a href="#4、kafka消费者" class="headerlink" title="4、kafka消费者"></a>4、kafka消费者</h1><h2 id="1、Kafka-消费方式"><a href="#1、Kafka-消费方式" class="headerlink" title="1、Kafka 消费方式"></a>1、Kafka 消费方式</h2><p>​	<img src="/../images/Kafka/watermark,type_d3F5LXplbmhlaQ,shadow_50,text_Q1NETiBA6Zi_5piM5Zac5qyi5ZCD6buE5qGD,size_20,color_FFFFFF,t_70,g_se,x_16-20230928234825729.png" alt="在这里插入图片描述"></p>
<h2 id="2、消费者工作流程"><a href="#2、消费者工作流程" class="headerlink" title="2、消费者工作流程"></a>2、消费者工作流程</h2><h5 id="①消费者总体工作流程"><a href="#①消费者总体工作流程" class="headerlink" title="①消费者总体工作流程"></a>①消费者总体工作流程</h5><p><img src="/../images/Kafka/watermark,type_d3F5LXplbmhlaQ,shadow_50,text_Q1NETiBA6Zi_5piM5Zac5qyi5ZCD6buE5qGD,size_20,color_FFFFFF,t_70,g_se,x_16-20230928234848009.png" alt="在这里插入图片描述"></p>
<h5 id="②消费者组原理"><a href="#②消费者组原理" class="headerlink" title="②消费者组原理"></a>②消费者组原理</h5><p> <img src="/../images/Kafka/watermark,type_d3F5LXplbmhlaQ,shadow_50,text_Q1NETiBA6Zi_5piM5Zac5qyi5ZCD6buE5qGD,size_20,color_FFFFFF,t_70,g_se,x_16-20230928235013969.png" alt="在这里插入图片描述"></p>
<p><img src="/../images/Kafka/watermark,type_d3F5LXplbmhlaQ,shadow_50,text_Q1NETiBA6Zi_5piM5Zac5qyi5ZCD6buE5qGD,size_20,color_FFFFFF,t_70,g_se,x_16-20230928235020544.png" alt="在这里插入图片描述"></p>
<p><strong>消费者组初始化流程</strong></p>
<p><img src="/../images/Kafka/watermark,type_d3F5LXplbmhlaQ,shadow_50,text_Q1NETiBA6Zi_5piM5Zac5qyi5ZCD6buE5qGD,size_20,color_FFFFFF,t_70,g_se,x_16-20230928235058845.png" alt="在这里插入图片描述"></p>
<p><strong>消费者组详细消费流程</strong></p>
<p><img src="/../images/Kafka/watermark,type_d3F5LXplbmhlaQ,shadow_50,text_Q1NETiBA6Zi_5piM5Zac5qyi5ZCD6buE5qGD,size_20,color_FFFFFF,t_70,g_se,x_16-20230928235306060.png" alt="在这里插入图片描述"></p>
<h2 id="3、消费者api"><a href="#3、消费者api" class="headerlink" title="3、消费者api"></a>3、消费者api</h2><h2 id="4、生产经验-——-分区的分配"><a href="#4、生产经验-——-分区的分配" class="headerlink" title="4、生产经验 —— 分区的分配"></a>4、生产经验 —— 分区的分配</h2><p><img src="/../images/Kafka/watermark,type_d3F5LXplbmhlaQ,shadow_50,text_Q1NETiBA6Zi_5piM5Zac5qyi5ZCD6buE5qGD,size_20,color_FFFFFF,t_70,g_se,x_16-20230928235523539.png" alt="在这里插入图片描述"></p>
<p><img src="/../images/Kafka/watermark,type_d3F5LXplbmhlaQ,shadow_50,text_Q1NETiBA6Zi_5piM5Zac5qyi5ZCD6buE5qGD,size_20,color_FFFFFF,t_70,g_se,x_16-20230928235554746.png" alt="在这里插入图片描述"></p>
<p><strong>Range 分区分配策略案例</strong></p>
<p> <img src="/../images/Kafka/watermark,type_d3F5LXplbmhlaQ,shadow_50,text_Q1NETiBA6Zi_5piM5Zac5qyi5ZCD6buE5qGD,size_20,color_FFFFFF,t_70,g_se,x_16-20230928235731478.png" alt="在这里插入图片描述"></p>
<p><img src="/../images/Kafka/29f6564651824fe69bba934f8e5e83b6.png" alt="在这里插入图片描述"></p>
<h5 id="Range-分区分配再平衡案例"><a href="#Range-分区分配再平衡案例" class="headerlink" title="Range 分区分配再平衡案例"></a><strong>Range 分区分配再平衡案例</strong></h5><p><img src="/../images/Kafka/watermark,type_d3F5LXplbmhlaQ,shadow_50,text_Q1NETiBA6Zi_5piM5Zac5qyi5ZCD6buE5qGD,size_20,color_FFFFFF,t_70,g_se,x_16-20230928235744058.png" alt="在这里插入图片描述"></p>
<h5 id="RoundRobin-以及再平衡原理"><a href="#RoundRobin-以及再平衡原理" class="headerlink" title="RoundRobin 以及再平衡原理"></a>RoundRobin 以及再平衡原理</h5><h5 id=""><a href="#" class="headerlink" title=""></a></h5><p><img src="/../images/Kafka/watermark,type_d3F5LXplbmhlaQ,shadow_50,text_Q1NETiBA6Zi_5piM5Zac5qyi5ZCD6buE5qGD,size_20,color_FFFFFF,t_70,g_se,x_16-20230929000334551.png" alt="在这里插入图片描述"></p>
<p><img src="/../images/Kafka/watermark,type_d3F5LXplbmhlaQ,shadow_50,text_Q1NETiBA6Zi_5piM5Zac5qyi5ZCD6buE5qGD,size_20,color_FFFFFF,t_70,g_se,x_16-20230929000415710.png" alt="在这里插入图片描述"></p>
<h5 id="Sticky-以及再平衡"><a href="#Sticky-以及再平衡" class="headerlink" title="Sticky 以及再平衡"></a>Sticky 以及再平衡</h5><p><img src="/../images/Kafka/watermark,type_d3F5LXplbmhlaQ,shadow_50,text_Q1NETiBA6Zi_5piM5Zac5qyi5ZCD6buE5qGD,size_20,color_FFFFFF,t_70,g_se,x_16-20230929000640458.png" alt="在这里插入图片描述"></p>
<p><img src="/../images/Kafka/watermark,type_d3F5LXplbmhlaQ,shadow_50,text_Q1NETiBA6Zi_5piM5Zac5qyi5ZCD6buE5qGD,size_20,color_FFFFFF,t_70,g_se,x_16-20230929000653360.png" alt="在这里插入图片描述"></p>
<p><img src="/../images/Kafka/watermark,type_d3F5LXplbmhlaQ,shadow_50,text_Q1NETiBA6Zi_5piM5Zac5qyi5ZCD6buE5qGD,size_20,color_FFFFFF,t_70,g_se,x_16-20230929000715131.png" alt="在这里插入图片描述"></p>
<p><img src="/../images/Kafka/watermark,type_d3F5LXplbmhlaQ,shadow_50,text_Q1NETiBA6Zi_5piM5Zac5qyi5ZCD6buE5qGD,size_20,color_FFFFFF,t_70,g_se,x_16-20230929000728390.png" alt="在这里插入图片描述"></p>
<h2 id="5、offset-位移"><a href="#5、offset-位移" class="headerlink" title="5、offset 位移"></a>5、offset 位移</h2><h5 id="1、offset-的默认维护"><a href="#1、offset-的默认维护" class="headerlink" title="1、offset 的默认维护"></a>1、offset 的默认维护</h5><p><img src="/../images/Kafka/watermark,type_d3F5LXplbmhlaQ,shadow_50,text_Q1NETiBA6Zi_5piM5Zac5qyi5ZCD6buE5qGD,size_20,color_FFFFFF,t_70,g_se,x_16-20230929000851750.png" alt="在这里插入图片描述"></p>
<p>__consumer_offsets 主题里面采用 key 和 value 的方式存储数据。</p>
<p>key 是group.id+topic+分区号，value 就是当前 offset 的值。</p>
<p>每隔一段时间，kafka 内部会对这个 topic 进行compact，也就是每个 group.id+topic+分区号就保留最新数据。</p>
<h5 id="①消费-offset-案例"><a href="#①消费-offset-案例" class="headerlink" title="①消费 offset 案例"></a>①消费 offset 案例</h5><p><img src="/../images/Kafka/watermark,type_d3F5LXplbmhlaQ,shadow_50,text_Q1NETiBA6Zi_5piM5Zac5qyi5ZCD6buE5qGD,size_20,color_FFFFFF,t_70,g_se,x_16-20230929000928260.png" alt="在这里插入图片描述"></p>
<h5 id="②自动提交-offset"><a href="#②自动提交-offset" class="headerlink" title="②自动提交 offset"></a>②自动提交 offset</h5><p><img src="/../images/Kafka/watermark,type_d3F5LXplbmhlaQ,shadow_50,text_Q1NETiBA6Zi_5piM5Zac5qyi5ZCD6buE5qGD,size_20,color_FFFFFF,t_70,g_se,x_16-20230929001005340.png" alt="在这里插入图片描述"></p>
<h5 id="③手动交-提交-offset"><a href="#③手动交-提交-offset" class="headerlink" title="③手动交 提交 offset"></a>③手动交 提交 offset</h5><p><img src="/../images/Kafka/watermark,type_d3F5LXplbmhlaQ,shadow_50,text_Q1NETiBA6Zi_5piM5Zac5qyi5ZCD6buE5qGD,size_20,color_FFFFFF,t_70,g_se,x_16-20230929001022624.png" alt="在这里插入图片描述"></p>
<h5 id="④指定-Offset-消费"><a href="#④指定-Offset-消费" class="headerlink" title="④指定 Offset 消费"></a>④指定 Offset 消费</h5><p><img src="/../images/Kafka/watermark,type_d3F5LXplbmhlaQ,shadow_50,text_Q1NETiBA6Zi_5piM5Zac5qyi5ZCD6buE5qGD,size_20,color_FFFFFF,t_70,g_se,x_16-20230929001046545.png" alt="在这里插入图片描述"></p>
<p><img src="/../images/Kafka/watermark,type_d3F5LXplbmhlaQ,shadow_50,text_Q1NETiBA6Zi_5piM5Zac5qyi5ZCD6buE5qGD,size_20,color_FFFFFF,t_70,g_se,x_16-20230929001143065.png" alt="在这里插入图片描述"></p>
<h5 id="⑤指定时间消费"><a href="#⑤指定时间消费" class="headerlink" title="⑤指定时间消费"></a>⑤指定时间消费</h5><p>其实就是通过时间得到offset然后指定offset</p>
<h5 id="⑥漏消费和重复消费"><a href="#⑥漏消费和重复消费" class="headerlink" title="⑥漏消费和重复消费"></a>⑥漏消费和重复消费</h5><p><strong>重复消费</strong>：已经消费了数据，但是 offset没提交。</p>
<p><strong>漏消费</strong>：先提交 offset后消费，有可能会造成数据的漏消费</p>
<p><img src="/../images/Kafka/watermark,type_d3F5LXplbmhlaQ,shadow_50,text_Q1NETiBA6Zi_5piM5Zac5qyi5ZCD6buE5qGD,size_20,color_FFFFFF,t_70,g_se,x_16-20230929001250173.png" alt="在这里插入图片描述"></p>
<p><img src="/../images/Kafka/watermark,type_d3F5LXplbmhlaQ,shadow_50,text_Q1NETiBA6Zi_5piM5Zac5qyi5ZCD6buE5qGD,size_20,color_FFFFFF,t_70,g_se,x_16-20230929001509066.png" alt="在这里插入图片描述"></p>
<h4 id="数据积压-（-消费者-如何提高吞吐量）"><a href="#数据积压-（-消费者-如何提高吞吐量）" class="headerlink" title="数据积压 （ 消费者 如何提高吞吐量）"></a>数据积压 （ 消费者 如何提高吞吐量）</h4><p><img src="/../images/Kafka/watermark,type_d3F5LXplbmhlaQ,shadow_50,text_Q1NETiBA6Zi_5piM5Zac5qyi5ZCD6buE5qGD,size_20,color_FFFFFF,t_70,g_se,x_16-20230929001531640.png" alt="在这里插入图片描述"></p>

                    
                        


                    
                    
                        <p>
                            <a
                                href="/2023/07/08/Kafka/#post-footer"
                                class="postShorten-excerpt_link link"
                                aria-label=""
                            >
                                Kommentieren und teilen
                            </a>
                        </p>
                    
                </div>
            
        </div>
        
    </article>
    
    
    <article class="postShorten postShorten--thumbnailimg-bottom">
        <div class="postShorten-wrap">
            
            <div class="postShorten-header">
                <h1 class="postShorten-title">
                    
                        <a
                            class="link-unstyled"
                            href="/2023/07/08/Mysql%E5%A4%8D%E4%B9%A0%EF%BC%88mysql%E6%8A%80%E6%9C%AF%E5%86%85%E5%B9%95%20innodb%E5%AD%98%E5%82%A8%E5%BC%95%E6%93%8E%EF%BC%89/"
                            aria-label=": Mysql复习（mysql技术内幕 innodb存储引擎）"
                        >
                            Mysql复习（mysql技术内幕 innodb存储引擎）
                        </a>
                    
                </h1>
                <div class="postShorten-meta">
    <time datetime="2023-07-08T00:00:00+08:00">
	
		    08 Jul 2023
    	
    </time>
    
        <span>in </span>
        
    <a class="category-link" href="/categories/Java/">Java</a>


    
</div>

            </div>
            
                <div class="postShorten-content">
                    <p>InnoDB最重要的点：行锁设计、MVCC、外键</p>
<p>首先来了解一下InnoDB的体系架构：</p>
<h1 id="体系架构"><a href="#体系架构" class="headerlink" title="体系架构"></a>体系架构</h1><p>![image-20231004235405057](..&#x2F;images&#x2F;Mysql复习（mysql技术内幕 innodb存储引擎）&#x2F;image-20231004235405057.png)</p>
<p>InnoDB有很多内存块，组成内存池，负责的工作：</p>
<p>维护所有线程</p>
<p>缓存磁盘的数据</p>
<p>重做日志缓冲</p>
<p>后台线程的主要作用就是：刷新内存池中的数据，保证缓冲池里的是最新的数据。把已修改的数据文件刷新到磁盘文件，</p>
<p>我们看体系架构，可以从以下几点：</p>
<h2 id="1、后台线程"><a href="#1、后台线程" class="headerlink" title="1、后台线程"></a>1、后台线程</h2><p>主要有：</p>
<p>master thread：最重要的，脏页刷新、合并insert buffer，undo 页的回收。不过后来脏页回收放到了单独的线程，也就是page thread</p>
<p>本质是一个</p>
<p>IO thread</p>
<p>purge thread</p>
<p>page thread</p>
<h3 id="1、master-thread"><a href="#1、master-thread" class="headerlink" title="1、master thread"></a>1、master thread</h3><p>本质是一个循环</p>
<p>每秒都会进行一次操作：重做日志缓冲刷新、合并insertbuffer ，脏页刷新被放到了page clean 线程</p>
<p>每十秒会进行的操作：重做日志缓冲刷新、合并insertbuffer、脏页刷新被放到了page clean 线程、删除无用的undo 页</p>
<h2 id="2、内存"><a href="#2、内存" class="headerlink" title="2、内存"></a>2、内存</h2><p>内存方面就是缓冲池、lrulist freelist flushlist、redo log buffer 三块，还有一些额外内存池</p>
<h3 id="1、缓冲池"><a href="#1、缓冲池" class="headerlink" title="1、缓冲池"></a>1、缓冲池</h3><p>本质就是一块内存，就是为了缓解cpu和磁盘的差距，缓冲池里面有数据页、索引页、undo 页、insert buffer、自适应哈希索引、锁信息、数据字典。</p>
<p>所以修改操作，基本都是现修改缓冲池里面的数据，然后按照一定频率通过checkpoint刷回磁盘。</p>
<h3 id="2、List"><a href="#2、List" class="headerlink" title="2、List"></a>2、List</h3><p>缓冲池是通过改进的LRU算法（在原本的基础上加了midpoint，新加入的页放到这里，默认5&#x2F;8）进行管理的，方法就是LRUlist、freelist flushlist。如果缓冲池不能放新的，就把lru里面末尾的释放掉。</p>
<p>改进lru的原因：有可能新页仅仅是这次查询需要用到，并不是真正的热点数据，这样反而有可能将真正的热点数据淘汰。</p>
<p>flushlist就是脏页列表，就像上面说的，用checkpoiint机制刷新</p>
<p>一页16k</p>
<p>说了这么多checkpoint，什么是checkpoint？</p>
<h4 id="1、checkpoint"><a href="#1、checkpoint" class="headerlink" title="1、checkpoint"></a>1、checkpoint</h4><p>解决问题：</p>
<ul>
<li>缩短数据库恢复时间？</li>
</ul>
<p>即使发生宕机， 因为checkpoint之前多页已经刷新回磁盘，所以只需要对checkpoint之后对进行恢复</p>
<ul>
<li>缓冲池不够时，可以将脏页刷回磁盘？</li>
</ul>
<p>缓冲池不够用的时候，根据lru找lru末尾的页，如果是脏页，就强制执行checkpoint，讲脏页刷新回磁盘</p>
<ul>
<li>重做日志不可用，刷新脏页。</li>
</ul>
<p>重做日志两个文件是循环使用，为了不让他一直无限变大，不可用是指重做日志已经不被需要了可以被覆盖。如果宕机，数据库恢复操作不需要这部分的重做日志就可以覆盖重用。如果此时重做日志还需要用，就必须强制产生checkpoint将讲缓冲池的页至少刷新到当前重做日志的位置</p>
<p>所以总归checkpoint做的事情就是把脏页刷回磁盘。那怎么刷新？什么时候刷新？</p>
<p>这里有两种checkpoint，分别是：</p>
<p>sharp checkpoint</p>
<p>fuzzy checkpoint</p>
<p>sharp checkpoint就是在关闭的时候全部刷新到磁盘</p>
<p>fuzzy checkpoint是刷新部分脏页？刷新到时机如下：</p>
<p>master thread checkpoint</p>
<p>flushlrulist checkpoint：这饿是lru列表需要有100个空闲的页，否则一处lru末尾的页，如果有脏页就checkpoint</p>
<p>async sycn flush checkpoint：这个是重做日志i文件不可用的情况，需要强制将一些刷新回磁盘  </p>
<p>dirty page too much：这个是脏页数量太多了，强制checkpoint 75%</p>
<h3 id="3、Redo-log-buffer"><a href="#3、Redo-log-buffer" class="headerlink" title="3、Redo log buffer"></a>3、Redo log buffer</h3><p>这个是innodb独有的，重做日志信息 -&gt;Redo log buffer -〉 重做日志文件，为重做日志文件服务，重做日志文件本身是为了数据库的恢复功能，但是同样的，为了环节和磁盘的差距，我们给他加一个buffer。</p>
<p>刷回时机：</p>
<p>master thread 每秒</p>
<p>每个事务提交的时候</p>
<p>重做日志缓冲 剩余空间小雨1&#x2F;2</p>
<h1 id="关键特性"><a href="#关键特性" class="headerlink" title="关键特性"></a>关键特性</h1><p>1、插入缓冲</p>
<p>2、两次写</p>
<p>3、自适应哈希</p>
<p>4、异步io</p>
<p>5、刷新邻接页</p>
<h2 id="1、插入缓冲"><a href="#1、插入缓冲" class="headerlink" title="1、插入缓冲"></a>1、插入缓冲</h2><h3 id="1、insert-buffer"><a href="#1、insert-buffer" class="headerlink" title="1、insert buffer"></a>1、insert buffer</h3><p>插入缓冲是针对辅助索引的，数据在真正存放的时候还是按照主键顺序插入的，但是这个表如果有辅助索引，那么这条记录也会插入辅助索引，但是这时候他就不是顺序插入了，而是离散的插入访问。</p>
<p>为此，InnoDB开创性的提出了Insert buffer，insertbuffer不是缓存，而是实实在在的物理页。我们在对非聚集索引的插入的时候不会实时的插入，而是先判断有没有在缓冲池里面，有的话直接插入，没有的话，先放到一个insert buffer里面。后面再以一定的频率进行insertbuffer和非聚集索页子节点的merge操作。</p>
<h3 id="2、change-buffer"><a href="#2、change-buffer" class="headerlink" title="2、change buffer"></a>2、change buffer</h3><p>insert buffer 升级为了 change buffer，对插入更新删除操作都准备了缓冲</p>
<h3 id="3、insert-buffer的内部实现"><a href="#3、insert-buffer的内部实现" class="headerlink" title="3、insert buffer的内部实现"></a>3、insert buffer的内部实现</h3><p>全局唯一的b+树的形式，负责对所有表的辅助索引进行insert buffer，存放在共享表空间，就是ibdata1。但是我们知道，我们可以有独立表ibdata，但是恢复的时候最好用共享表里面的。</p>
<p>因为是树，所以有非叶子结点和叶子结点。</p>
<p>非叶子结点放的是searchkey，所以插入非聚集索引的时候，如果不在缓冲池，那么要加入这颗唯一的insertbuffer，实现构造一个searchkey，我想通过这个searchkey找到我要插入的位置，然后再构造一个叶子结点，放进去。</p>
<h3 id="4、Merge-insert-buffer"><a href="#4、Merge-insert-buffer" class="headerlink" title="4、Merge insert buffer"></a>4、Merge insert buffer</h3><p>所以后面就是合并操作，合并的时机：</p>
<p>1、master thread</p>
<p>2、辅助索引页被读到缓冲池里去，然后这个是要执行正常的查询语句了，就去检查这个insert buffer bitmap，确认这个该辅助索引是不是在insert buffer b+书里面，如果有，就把树里面的记录查到辅助索引里面。</p>
<h2 id="2、两次写"><a href="#2、两次写" class="headerlink" title="2、两次写"></a>2、两次写</h2><p>doublewrite的目的是为了数据的可靠性。</p>
<p>具体实现的话，是依赖于两个部分，一个是内存中的doublewrite buffer，2m。另一部分是磁盘里的共享表空间里面有一个连续的128页，也是2m。然后我们对脏页进行刷新到磁盘里面，我先不直接写磁盘，我先复制到这个内存的doublewrite buffer里面，然后分两次写入，每次1m写入共享表空间的物理磁盘，然后马上调用fsync函数，同步磁盘。所以，如果写的时候崩溃了，那就把这个共享表空间里面的副本拿出来配合redo log进行恢复。</p>
<h2 id="3、自适应哈希"><a href="#3、自适应哈希" class="headerlink" title="3、自适应哈希"></a>3、自适应哈希</h2><p>InnoDB会自动为某些访问频率非常高的页建立哈希索引，而哈希索引比起b+树更快，所以也是一种提高性能手段。</p>
<p>但是有一个比较大的痛点就是他只能用于做 等值查询，如果遇到范围查到，就无能为力。</p>
<h1 id="文件"><a href="#文件" class="headerlink" title="文件"></a>文件</h1><p>文件包括mysql文件和innodb文件</p>
<p>1、参数文件</p>
<p>2、日志文件、</p>
<p>3、socket文件</p>
<p>4、pid文件</p>
<p>5、mysql表结构文件</p>
<p>6、存储引擎文件</p>
<p>我们这里只讲几个</p>
<h2 id="2、日志文件"><a href="#2、日志文件" class="headerlink" title="2、日志文件"></a>2、日志文件</h2><p>日志文件有错误日志、慢查询日志、查询日志、二进制日志，我们着重可以讲一下二进制日志</p>
<h3 id="1、二进制日志"><a href="#1、二进制日志" class="headerlink" title="1、二进制日志"></a>1、二进制日志</h3><p>事务执行过程中，先把日志写到 binlog cache（Server 层的 cache），MySQL 给每个线程分配了一片内存用于缓冲 binlog，事务提交的时候，再把 binlog cache 写到 binlog 文件中</p>
<p>他是mysql 的日志，记录了对mysql数据库更改的所有操作。不包括selectshow这类操作</p>
<p>主要用于：</p>
<p>恢复：某些数据需要二进制日志。比如数据库全备文件恢复之后，通过二进制进行point-in-time的恢复</p>
<p>复制；主从同步，那canal也是通过这种方式去监听binlog</p>
<p>审计：用户通过二进制的信息判断是否有对数据库进行注入的攻击</p>
<p>然后二进制日志它肯定要落盘，但是他不是每一次写都要落盘，他有个参数sync—binlog，如果等于n，代表每次缓冲多少次就同步到磁盘里面。如果等于1，那就代表同步写磁盘。</p>
<p>MySQL提供一个 sync_binlog 参数来控制数据库的 binlog 刷到磁盘上的频率：</p>
<ul>
<li>sync_binlog &#x3D; 0 的时候，表示每次提交事务都只 write，不 fsync，后续交由操作系统决定何时将数据持久化到磁盘；</li>
<li>sync_binlog &#x3D; 1 的时候，表示每次提交事务都会 write，然后马上执行 fsync；</li>
<li>sync_binlog &#x3D;N(N&gt;1) 的时候，表示每次提交事务都 write，但累积 N 个事务后才 fsync。</li>
</ul>
<p>还有个需要关注的点就是它落盘的形式，就是怎么记录的？</p>
<p>这个是依赖于binlog——format这个参数，他就是记录二进制的格式，有三种、statement、row、mixed。</p>
<p>statement就是最简单的sql语句，但是他有个很大的问题就是如果用到了uuid rand udf这些函数或触发器，那么回导致主从不一致，那我们可以用row的格式，row的话就是记录表的行修改情况。同样的他也有一个很大问题就是要求的容量比较大。那还有一种mixed格式就是混用，正常情况下我按照statement记录sql语句，但是在uuid rand udf这些特殊情况我用row的格式进行纪记录。</p>
<h3 id="2、表结构定义文件"><a href="#2、表结构定义文件" class="headerlink" title="2、表结构定义文件"></a>2、表结构定义文件</h3><p>这个文件的后缀是.frm，每个文件都会有这个一个frm文件，记录了该表的表结构定义</p>
<h3 id="3、Innodb存储引擎文件"><a href="#3、Innodb存储引擎文件" class="headerlink" title="3、Innodb存储引擎文件"></a>3、Innodb存储引擎文件</h3><h4 id="1、表空间文件"><a href="#1、表空间文件" class="headerlink" title="1、表空间文件"></a>1、表空间文件</h4><p>首当其冲的就是表空间文件，次情况下我们会放到ibdata那个文件里面，但是我们可以通过设置一个参数去产生一个自己表的独立表空间，然后这些独立的表空间记录该表的数据，索引，insertbuffer等信息，其余的还是放在共享表空间里面。</p>
<h4 id="2、重做日志文件"><a href="#2、重做日志文件" class="headerlink" title="2、重做日志文件"></a>2、重做日志文件</h4><p>这个ib_logfile0 ib_logile1，先写logfile0，写完之后我们再去写logfile1.然后他有一个capacity容量参数，如果超过这个值，就必须从缓冲池里面的脏页列表去刷回一部分脏页。</p>
<p>binlog他是mysql的，所以很多其他引擎的操作都会记录，而redolog就是属于innodb的，然后她的记录格式也是大不相同的，binlog是逻辑日志，而redolog则是记录每个页的更改的物理情况</p>
<p>其次刷新的时间也不同，binlog是很明显，我事务提交之前进行一次提交，而redolog在事务执行过程中就会不多的写入redolog。</p>
<h1 id="索引前的准备知识"><a href="#索引前的准备知识" class="headerlink" title="索引前的准备知识"></a>索引前的准备知识</h1><p><a target="_blank" rel="noopener" href="https://baijiahao.baidu.com/s?id=1709211669369376612&amp;wfr=spider&amp;for=pc">https://baijiahao.baidu.com/s?id=1709211669369376612&amp;wfr=spider&amp;for=pc</a></p>
<p><strong>这里我们首先要问三个重要的问题去扒一扒MySQL的InnoDB存储引擎</strong></p>
<ol>
<li><strong>MySQL的记录是怎么存储的？</strong></li>
<li><strong>页内记录到底是怎么维护的？</strong></li>
<li><strong>页内查询过程是怎样的</strong></li>
</ol>
<h3 id="穿上第一件：Page页面"><a href="#穿上第一件：Page页面" class="headerlink" title="穿上第一件：Page页面"></a>穿上第一件：Page页面</h3><p>MySQL管理数据的一个单位叫Page页面，数据都是存在页面里的<strong>。</strong>那咱们想要知道数据是怎么存，就<strong>需要了解页面长什么样子</strong>。</p>
<p>直接爆照：</p>
<p>![img](..&#x2F;images&#x2F;Mysql复习（mysql技术内幕 innodb存储引擎）&#x2F;42a98226cffc1e171d3b202cf4e9e50a728de9ae.jpeg)</p>
<p>页头（Page Header）：存一些统计信息，记录页面的控制信息，共占56字节，包括页面空间使用情况、页的左右兄弟页面指针（<strong>这个就是双向链表，把左右兄弟页面的指针给拿到了</strong>）等。</p>
<p>虚记录：分为最大虚记录与最小虚记录，<strong>它俩把这页里面存储的数据的范围框住了。</strong>那怎么比较谁大谁小？用的是主键去比较：最大虚记录比页内最大主键还大，最小虚记录比页内最小主键还小<strong>。</strong>那主键到底是怎么存的呢？InnoDB用的是聚簇索引——<strong>数据和主键存到一起、数据和索引存到一起，数据按主键顺序存储。</strong></p>
<p>记录堆：<strong>这部分就是存储记录的区域</strong>，分为有效记录和已删除记录。已被删除的记录构成一个链表，叫做自由空间链表<strong>，</strong>如图蓝色已经被删除的数据，<strong>用一个链表把它们连起来</strong>。</p>
<p>未分配空间：页面未使用的存储空间，除了用了一部分的橙色的区域和已删除的蓝色的数据，剩下的就是未分配空间了，<strong>后面有新的数据插入，往里放就行了</strong>。</p>
<p>Slog区：<strong>这一块对数据检索非常有用</strong>，卖个关子，后面详细说。</p>
<p>页尾（Page Tailer）：页面的最后部分，占8个字节，主要存储页面的校验信息。<strong>这一页如果写坏了，数据不对了，通过校验位可以检查出来。</strong></p>
<p>好了，到这里一个页面咱们了解了，了解数据大概是怎么分布的，<strong>那接下来需要考虑哪些点呢？</strong>我们接下来研究一下——页面记录是怎么维护的</p>
<h3 id="穿上第二件：聚簇索引"><a href="#穿上第二件：聚簇索引" class="headerlink" title="穿上第二件：聚簇索引"></a>穿上第二件：聚簇索引</h3><p>刚刚提到了主键顺序这个词，那这个顺序是怎么保证的？这里说的按什么顺序存储，不是说升序、降序这些，这些没有意义，实际上说的是<strong>在页里面数据是怎么组织起来的</strong>，还有就是插入数据的策略，<strong>我怎么插入数据</strong>，还有就是<strong>页内的查询是怎样的</strong>。</p>
<p>我们先来看看聚簇索引：</p>
<p>![img](..&#x2F;images&#x2F;Mysql复习（mysql技术内幕 innodb存储引擎）&#x2F;c9fcc3cec3fdfc032a5c874b6446949da5c2269b.jpeg)</p>
<p>首先，聚簇索引是一棵B+树，那什么是聚簇呢？</p>
<p>图中下面绿色的部分是咱们的数据区域，数据是基于紫色部分的主键顺序去存储的，<strong>数据和主键存到一起没毛病，主键是按照树的顺序去组织的，这个结构就叫聚簇</strong>。</p>
<p>我们再看每一个Page，刚刚说到，Page里面有最大虚记录、最小虚记录，最大、最小这数据肯定是有个范围，<strong>那这个数据在里边到底是怎么存的</strong>？换个说法——数据的顺序是怎么保证的？<strong>到底是物理有序，还是逻辑有序？</strong></p>
<p>我们再回顾一下大学的知识——<strong>物理有序写入不友好，查询友好；逻辑有序查询不友好，插入友好</strong>，两者优缺点互补。</p>
<p>再回到正题，了解了这两种不同存储方式的特性，反观页面是怎么做的。</p>
<p>先看下面这幅图，思考一下插入主键为10，9，8的数据，是按物理有序存储还是逻辑有序存储：</p>
<p>![img](..&#x2F;images&#x2F;Mysql复习（mysql技术内幕 innodb存储引擎）&#x2F;e850352ac65c103892bb2f180b68801ab27e89a2.jpeg)</p>
<p>数据插入是写入IO，数据查询是读IO，不管是写还是读，在分析存储的时候，无非是这四种：顺序写、随机写、顺序读、随机读。<strong>如果是顺序写，数据会有各种移动，写入性能肯定非常糟糕</strong>。但是没办法，<strong>优化写入的手段十分有限，不过呢我们却有很多办法优化读</strong>。</p>
<p><strong>所以想都不用想，页内数据存储的顺序就是逻辑有序</strong>。</p>
<p>重新梳理一下，Page与Page之间由双向链表连接，页内是用小的链表连起来的：</p>
<p>![img](..&#x2F;images&#x2F;Mysql复习（mysql技术内幕 innodb存储引擎）&#x2F;9825bc315c6034a8191108a4766a5a5d082376a2.jpeg)</p>
<p>我们再来重新画一下这棵树：</p>
<p>![img](..&#x2F;images&#x2F;Mysql复习（mysql技术内幕 innodb存储引擎）&#x2F;80cb39dbb6fd5266c5d8021702618422d5073647.jpeg)</p>
<p>这里要注意，每个Page的索引的每个节点，也就是树的每个节点，它也是一个Page。<strong>既然是个Page，也会有页头，也会有双向链表</strong>，如图蓝色与紫色相间那部分节点数据。</p>
<p><strong>接下来咱分析一下它的插入策略。</strong></p>
<p>蓝色部分已删除的空间（记录堆）怎么办呢？<strong>我们得想办法尽量把它们利用上</strong>，这个换谁做数据库设计都要这么设计<strong>。</strong></p>
<p>其实，插入策略就是先使用自由空间链表，再使用未使用空间，<strong>把数据库“空洞”给补上。</strong>不过呢，自由空间链表的空间也不能完全利用上，比如旧的数据占25个字节，新的数据假设都只有20个字节，<strong>那剩下这5个字节基本也利用不上，这样一来就会产生越来越多的“碎片”</strong>。经过长时间的插入删除插入删除以后，我们就得考虑给数据库做一次收缩，比如通过两次主从表的双向同步，<strong>把所有表数据重新插一遍</strong>。</p>
<p><strong>我们接下来研究一下——页内查询是怎么做的？</strong></p>
<h3 id="穿上第三件：Slot槽"><a href="#穿上第三件：Slot槽" class="headerlink" title="穿上第三件：Slot槽"></a>穿上第三件：Slot槽</h3><p><strong>页内的数据是遍历还是二分查找？</strong></p>
<p>无论数据是物理连续还是逻辑有序，都不能二分查找，都得用遍历的办法。如果我们设计一款数据库，通过索引找到数据在哪个Page里面，要是Page这一层通过遍历的方式，那效率实在是太低了，所以数据库肯定不能这样设计。</p>
<p>遍历不行，那就使用二分查找吧，提高一下效率。那MySQL是怎么做的呢？看看这张图：</p>
<p>![img](..&#x2F;images&#x2F;Mysql复习（mysql技术内幕 innodb存储引擎）&#x2F;3b87e950352ac65c1fead4dc4c8ba11892138a30.jpeg)</p>
<p>如图，最小虚记录和最大虚记录之间形成一个链表，这时候Slot区就派上用场了，每个Slot槽指向链表中的某一个位置，每个槽的大小一样，可以理解为一个指针，<strong>这样我们只需要用一个算法把每个子链表的长度拆成差不多大小就行了</strong>。</p>
<p>在查找的时候，先基于Sn、S0找到指向的最大最小虚记录，在Slot区进行二分：<strong>先找到Sn和S0的中间位置，中间找到某个Slot，然后再一步步进行比较，通过几次二分后找到具体的子链表，最后，在子链表内进行遍历找到最终的记录</strong>。这样我们借助Slot区实现了一个近似二分查找的方法。这特别像Java里面的跳表结构，一次查找跳一次，再一次查找再跳一次，效率就特别高了</p>
<h1 id="索引"><a href="#索引" class="headerlink" title="索引"></a>索引</h1><p>innodb最常见的索引就是：</p>
<p>b+树索引 （b+树只能找到数据行所在的页，然后把页读到内存里面，进行查找）</p>
<p>哈希索引（自动生成）</p>
<p>全文索引</p>
<h2 id="1、B-树索引"><a href="#1、B-树索引" class="headerlink" title="1、B+树索引"></a>1、B+树索引</h2><p>二叉查找树（左小于中小于右）-》平衡二叉树，任何结点的两个子树高度差小于等于1（性能比较高，但不是最高）（需要左旋右旋等等）</p>
<p>b+树是为了磁盘或其他直接存取辅助设备设计的一种平衡查找树</p>
<p>b+树的所有记录结点都是按照键值的大小顺序存放到同一层的叶子结点，他们之间通过叶子结点指针进行连接，中间的都是searchkey</p>
<h3 id="1、操作"><a href="#1、操作" class="headerlink" title="1、操作"></a>1、操作</h3><h4 id="1、插入"><a href="#1、插入" class="headerlink" title="1、插入"></a>1、插入</h4><p>![image-20231005201534270](..&#x2F;images&#x2F;Mysql复习（mysql技术内幕 innodb存储引擎）&#x2F;image-20231005201534270.png)</p>
<h4 id="2、旋转"><a href="#2、旋转" class="headerlink" title="2、旋转"></a>2、旋转</h4><p>旋转发生在leaf page已经满了，但是左右兄弟还没有满，这时候会把记录平移到兄弟结点上面，左兄弟优先</p>
<h4 id="3、删除"><a href="#3、删除" class="headerlink" title="3、删除"></a>3、删除</h4><p>![image-20231005202324173](..&#x2F;images&#x2F;Mysql复习（mysql技术内幕 innodb存储引擎）&#x2F;image-20231005202324173.png)</p>
<h3 id="2、分类"><a href="#2、分类" class="headerlink" title="2、分类"></a>2、分类</h3><p>b+树可以分成聚集索引、辅助索引，这两个到区别就是叶子结点放的到底是不是一行信息</p>
<h4 id="1、聚集索引"><a href="#1、聚集索引" class="headerlink" title="1、聚集索引"></a>1、聚集索引</h4><p>innodb引擎是索引组织表，按照主键顺序存放，而聚集索引就是按照主键构造的索引b+树，所以叶子结点存放的就是整张表的数据，叶子结点也叫做数据页。非叶子结点的索引页存放的仅仅是键值和指向数据页的偏移量。</p>
<h4 id="2、辅助索引"><a href="#2、辅助索引" class="headerlink" title="2、辅助索引"></a>2、辅助索引</h4><p>辅助索引的叶子结点不包含行记录的全部数据。叶子结点包含键值和书签，书签用来告诉引擎哪里能找到真正的行数据。由于innodb是索引组织表，所以辅助索引的书签就是行记录的聚集索引键。比如（文件名：页号：槽号），所以辅助索引就是包含了索引那列的值和主键的值</p>
<h3 id="3、B-树索引的管理"><a href="#3、B-树索引的管理" class="headerlink" title="3、B+树索引的管理"></a>3、B+树索引的管理</h3><h4 id="1、索引管理"><a href="#1、索引管理" class="headerlink" title="1、索引管理"></a>1、索引管理</h4><p>创建和删除可以通过两种方法。一种是alter table。另一种是create&#x2F;drop index。</p>
<p>查看：show index from XX</p>
<h4 id="2、fast-index-create"><a href="#2、fast-index-create" class="headerlink" title="2、fast index create"></a>2、fast index create</h4><p>对于一张大表进行索引的添加和删除操作，这会需要很长时间。所以就提出了这个快速创建索引的方式。只限制于辅助索引。</p>
<p>在创建索引的表加上一个S锁不需要重建表，删除索引只需要更新内部视图。</p>
<h4 id="3、Online-Schema-Change在线架构改变OSC"><a href="#3、Online-Schema-Change在线架构改变OSC" class="headerlink" title="3、Online Schema Change在线架构改变OSC"></a>3、Online Schema Change在线架构改变OSC</h4><p>在线的意思其实就是在DDL的过程中，可以有读写事务对表进行操作</p>
<h4 id="4、Online-DDL"><a href="#4、Online-DDL" class="headerlink" title="4、Online DDL"></a>4、Online DDL</h4><p>允许在辅助索引创建的同时，还允许insert update等DML操作</p>
<p>原理是：执行insert update delete这些操作的时候，先把操作日志写入一个缓存里面，然后，索引建立后重做表上面</p>
<p>新的alter table语法中，通过algorithm如果是 copy还是通过建立临时表的方式，如果是replace就是不需要临时表，如果是default，那就是根据old_alter_table判断，如果是off，那就是replace。</p>
<h4 id="5、cardinality值"><a href="#5、cardinality值" class="headerlink" title="5、cardinality值"></a>5、cardinality值</h4><p>优化器会根据这个值来判断我们用不用索引。表示索引中唯一值的数据的估计值，如果是性别这种，重复的非常多，我们叫低选择性，不适合做索引。反之高选择性就比较适合，尤其是在高选择性属性字段里面取出一小部分数据，那就更有必要了。</p>
<ul>
<li><strong>统计的方式</strong>？</li>
</ul>
<p>一张大表，每次统计的时间很长，这是不能接受的，所以我们用的是采样的方法。cardinality值的更新发生在insert和update操作，但是肯定不是每一次insertupdate都去更新，具体策略如下：</p>
<p>1、表中1&#x2F;16数据发生了变化</p>
<p>2、计数器超过20亿</p>
<ul>
<li><strong>采样的方法：</strong></li>
</ul>
<p>对八个叶子结点进行采样预估，取出平均值</p>
<h3 id="4、B-树索引的使用"><a href="#4、B-树索引的使用" class="headerlink" title="4、B+树索引的使用"></a>4、B+树索引的使用</h3><h4 id="1、联合索引"><a href="#1、联合索引" class="headerlink" title="1、联合索引"></a>1、联合索引</h4><p>本质也是一颗二叉树，之前是a,b,c,d现在是（a,b）(c,d)</p>
<p>第一个好处：对于联合查询和单列的第一列的查询都可以用联合查询</p>
<p>第二个好处：一句对第二个键值进行了排序处理，可以缩短某些情况的查询时间</p>
<h4 id="2、覆盖索引"><a href="#2、覆盖索引" class="headerlink" title="2、覆盖索引"></a>2、覆盖索引</h4><p>覆盖索引的意思是，从辅助索引中就直接可以得到想要查询的记录，不需要回表。</p>
<p>第一个好处是：辅助索引本身不包括整行记录，所以大小远小于聚集索引，减少io操作</p>
<p>第二个好处是：对于某些统计问题，存储引擎并不会通过积极索引，辅助索引远远小于聚集索引，</p>
<h4 id="3、优化器不选择索引的方式"><a href="#3、优化器不选择索引的方式" class="headerlink" title="3、优化器不选择索引的方式"></a>3、优化器不选择索引的方式</h4><p>多发生在范围查找、join链接操作</p>
<h4 id="4、MRR优化（只支持非聚集索引）（离散读变成顺序读）"><a href="#4、MRR优化（只支持非聚集索引）（离散读变成顺序读）" class="headerlink" title="4、MRR优化（只支持非聚集索引）（离散读变成顺序读）"></a>4、MRR优化（只支持非聚集索引）（离散读变成顺序读）</h4><p>工作方式：</p>
<ul>
<li>把辅助索引读出来放到一个缓存里面</li>
<li>把缓存中的键值更具rowid进行排序</li>
<li>然后根据rowid去找数据</li>
</ul>
<p>他还可以进行某些范围查找，就是把范围查找拆分成键值对的等值查找。直接就过滤了一些不符合条件的数据。</p>
<p>好处：</p>
<ul>
<li>数据访问更加顺序，</li>
<li>减少缓冲池页的替换</li>
</ul>
<h4 id="5、ICP优化（只支持非聚集索引）"><a href="#5、ICP优化（只支持非聚集索引）" class="headerlink" title="5、ICP优化（只支持非聚集索引）"></a>5、ICP优化（只支持非聚集索引）</h4><p>原本我们通过索引进行查询的时候，首先根据索引查找记录，然后根据where条件过滤记录。ICP是在取出索引的同时，判断是否可以进行where条件的过滤，也就是讲where的部分过滤操作放到了存储引擎层</p>
<p>场景：</p>
<p>假设表TB1上有索引IDX_C1_C2_C3(C1,C2,C3)，对于查询SELECT * FROM TB1 WHERE C1&#x3D;’XXX’ AND C3&#x3D;’XXX’</p>
<p>在MySQL 5.6版本以前，由于缺少C2的过滤条件，Innodb存储引擎层只能使用索引IDX_C1_C2_C3按照C1&#x3D;’XXX’条件找出所有满足条件的索引记录，再根据这些索引记录去聚集索引中查找，将找到的表数据返回给MySQL Server层，然后由MySQL Server层使用C3&#x3D;’XXX’条件进行过滤得到最终结果。</p>
<p>再MySQL 5.6版本中引入ICP特性，Innodb存储引擎层只能使用索引IDX_C1_C2_C3按照C1&#x3D;’XXX’条件去扫描所有满足条件的索引记录，再将这些索引记录按照C3&#x3D;’XXX’条件进行过滤，并按照过滤后的索引记录去去聚集索引中查找，将找到的表数据返回给MySQL Server层，得到最终结果。</p>
<p>假设满足C1&#x3D;’XXX’条件的数据行为100000条，而满足C1&#x3D;’XXX’ AND C3&#x3D;’XXX’的数据行为100条，则：</p>
<p>1、在MySQL 5.5版本中，需要对TB1的聚集索引进行100000次Index Seek操作，Innodb存储引擎层向MySQL Server层传递100000行数据。</p>
<p>2、在MySQL 5.6版本中，使用ICP仅需要对TB1的聚集索引进行100次的Index Seek操作，Innodb存储引擎层向MySQL Server层传递100行数据。</p>
<h4 id="6、自适应哈希索引"><a href="#6、自适应哈希索引" class="headerlink" title="6、自适应哈希索引"></a>6、自适应哈希索引</h4><p>InnoDB中的哈希用的字典进行查找，冲突用链表解决，哈希函数用除法散列</p>
<p>自适应哈希索引就是用的这种方法。</p>
<h4 id="7、全文检索"><a href="#7、全文检索" class="headerlink" title="7、全文检索"></a>7、全文检索</h4><p>全文检索一般使用倒排索引。</p>
<h5 id="1、倒排索引"><a href="#1、倒排索引" class="headerlink" title="1、倒排索引"></a>1、倒排索引</h5><p>它在辅助表（auxiliary table）中存储了单词与单词自身在一个或多个文档中所在位置之间的映射。这通常利用关键数组实现，其拥有两种表现形式：<br>inverted file index：其表现形式为{单词，单词所在文档的ID}<br>full inverted index：其表现形式为{单词，(单词所在文档的ID，在文档中的具体位置)}</p>
<h5 id="2、InnoDB全文检索的实现"><a href="#2、InnoDB全文检索的实现" class="headerlink" title="2、InnoDB全文检索的实现"></a>2、InnoDB全文检索的实现</h5><p><strong>InnoDB全文索引有3个非常重要的东西，一个是辅助表，一个是FTS Index Cache、一个是FTS DOUCUMENT id</strong></p>
<h6 id="1、Auxiliary-Table（辅助表）"><a href="#1、Auxiliary-Table（辅助表）" class="headerlink" title="1、Auxiliary Table（辅助表）"></a><strong>1、Auxiliary Table（辅助表）</strong></h6><p>辅助表是把文档，分词然后规范化后的白哦，</p>
<p>辅助表的话采用“full inverted index”的方式有两个列：<br>一个是word字段。在word字段上有设有索引，另一个是ilist字段，（DocumentId,Position）</p>
<h6 id="2、FTS-INDEX-Cache（全文检索缓存）"><a href="#2、FTS-INDEX-Cache（全文检索缓存）" class="headerlink" title="2、FTS INDEX Cache（全文检索缓存）"></a><strong>2、FTS INDEX Cache（全文检索缓存）</strong></h6><p>他是一个红黑树的结构：我执行插入操作，插入的数据已经更新了对应的表，但是我们的辅助表可能还没更新，这个更新还停留在FTS cache里面。如果没插一次就更新这是不合理的，那具体同步到辅助表的时机：</p>
<p>1、在我进行全文检索查询的时候，我把FTS INDEX cache里的word字段合并到辅助表，然后查询。有点类似于insert buffer</p>
<p>2、数据库关闭的时候会同步</p>
<p>3、cache满了	</p>
<p>数据库宕机时：一些FTS InDEX Cache中的数据库可能未被同步到磁盘上。那么下次重启时，当用户对表进行全文检索（查询或者插入操作）时，InnoDB会自动读取未完成的文档，然后进行分词操作，再将分词的结果放入到FTS Index Cache中</p>
<p>对于InnoDB来说，其总是在事务提交时将分词写入到FTS Index Cache。</p>
<h6 id="3、FTS-DOUCUMENT-ID"><a href="#3、FTS-DOUCUMENT-ID" class="headerlink" title="3、FTS DOUCUMENT ID"></a>3、FTS DOUCUMENT ID</h6><p>为了支持全文检索，<strong>必须有一个列与word进行映射：</strong></p>
<ul>
<li>在InnoDB中这个列<strong>被命名为FTS_DOC_ID</strong></li>
<li>其<strong>类型必须是</strong>bigint unsigned not null</li>
<li>并且InnoDB自动会在该列上加入一个<strong>名为FTS_DOC_ID_INDEX的unique index索引</strong></li>
<li><strong>用户也可以在建表时自动添加FTS_DOC_ID，以及相应的Unique Index</strong></li>
</ul>
<p>Deleted auxiliary table<br>文档中分词的插入操作是在事务提交时完成的，然而对于删除操作，其在事务提交时不删除磁盘Auxiliary Table中的记录，而只是删除FTS Index Cache中的记录。对于Auxiliary Table中被删除的记录，InnoDB会记录其FTS Document ID，并将其保存在Deleted auxiliary table中</p>
<p>由于文档的DML操作实际并不删除索引中的数据，相反还会在对应的DELETED表中插入记录，因此随着应用程序的允许，索引会变得非常大，即使索引列中的有些数据已经被删除，查询也不会使用到。为了，InnoDB存储引擎提供了一种方式，允许用户手动地将已删除的记录从索引中彻底删除，该命令就是OPTIMIZE TABLE</p>
<h1 id="锁"><a href="#锁" class="headerlink" title="锁"></a>锁</h1><p>锁机制是用于管理对共享资源的并发访问，保证数据的完整性和一致性。</p>
<h2 id="1、锁的类型"><a href="#1、锁的类型" class="headerlink" title="1、锁的类型"></a>1、锁的类型</h2><h3 id="1、全局锁"><a href="#1、全局锁" class="headerlink" title="1、全局锁"></a>1、全局锁</h3><p>典型的使用场景就是做全库的逻辑备份</p>
<ul>
<li><p>一旦加了全局锁之后，其他的DDL、 DML全部都处于阻塞状态，但是可以执行DQL语句，也就是处于只读状态</p>
</li>
<li><p>语法</p>
<figure class="highlight sql"><table><tr><td class="code"><pre><span class="line">flush tables <span class="keyword">with</span> read lock;<span class="number">1</span>、加全局锁</span><br><span class="line">mysqldump <span class="operator">-</span>uroot <span class="operator">-</span>pxxx db_name <span class="operator">-</span><span class="operator">&gt;</span> xxx.sql;<span class="number">2</span>、数据备份</span><br><span class="line">unlock tables;<span class="number">3</span>、释放锁</span><br></pre></td></tr></table></figure></li>
</ul>
<h3 id="2、表级锁"><a href="#2、表级锁" class="headerlink" title="2、表级锁"></a>2、表级锁</h3><p>表级锁，主要分为3类：</p>
<ul>
<li>表锁</li>
<li>元数据锁（meta data lock，MDL）</li>
<li>意向锁</li>
</ul>
<h4 id="1、表锁"><a href="#1、表锁" class="headerlink" title="1、表锁"></a>1、表锁</h4><p>对于表锁，又可以分为2类：</p>
<ul>
<li>表共享读锁（read lock）</li>
<li>表独占写锁（write lock）</li>
</ul>
<p>结论: 读锁不会阻塞其他客户端的读，但是会阻塞写。写锁既会阻塞其他客户端的读，又会阻塞 其他客户端的写。</p>
<h4 id="2、、元数据锁"><a href="#2、、元数据锁" class="headerlink" title="2、、元数据锁"></a>2、、元数据锁</h4><p>再来说说<strong>元数据锁</strong>（MDL）。</p>
<p>我们不需要显示的使用 MDL，因为当我们对数据库表进行操作时，会自动给这个表加上 MDL：</p>
<ul>
<li>对一张表进行 CRUD 操作时，加的是 <strong>MDL 读锁</strong>；</li>
<li>对一张表做结构变更操作的时候，加的是 <strong>MDL 写锁</strong>；</li>
</ul>
<p>MDL 是为了保证当用户对表执行 CRUD 操作时，防止其他线程对这个表结构做了变更。</p>
<blockquote>
<p>MDL 不需要显示调用，那它是在什么时候释放的?</p>
</blockquote>
<p>MDL 是在事务提交后才会释放，这意味着<strong>事务执行期间，MDL 是一直持有的</strong>。</p>
<p>MDL 加锁过程是系统自动控制，无需显式使用，在访问一张表的时候会自动加上。MDL 锁主要作用是维 护表元数据的数据一致性，在表上有活动事务的时候，不可以对元数据进行写入操作。为了避免DML与 DDL冲突，保证读写的正确性。</p>
<h4 id="3、意向锁"><a href="#3、意向锁" class="headerlink" title="3、意向锁"></a>3、意向锁</h4><p>我觉得意向锁主要还是解决行锁和表锁之间的冲突问题。</p>
<ul>
<li>在使用 InnoDB 引擎的表里对某些记录加上「共享锁」之前，需要先在表级别加上一个「意向共享锁」；</li>
<li>在使用 InnoDB 引擎的表里对某些纪录加上「独占锁」之前，需要先在表级别加上一个「意向独占锁」；</li>
</ul>
<p>也就是，当执行插入、更新、删除操作，需要先对表加上「意向独占锁」，然后对该记录加行级独占锁。</p>
<p>![img](..&#x2F;images&#x2F;Mysql复习（mysql技术内幕 innodb存储引擎）&#x2F;20e0f35589584352bd15e817668a0886.png)</p>
<p>![img](..&#x2F;images&#x2F;Mysql复习（mysql技术内幕 innodb存储引擎）&#x2F;6e6b275c2d6d4dfcbbb338be4f61bee9.png)</p>
<p>所以，<strong>意向锁的目的是为了快速判断表里是否有记录被加锁</strong>。</p>
<h4 id="4、自增锁"><a href="#4、自增锁" class="headerlink" title="4、自增锁"></a>4、自增锁</h4><p>主键设置成自增之后，在插入数据时，可以不指定主键的值，数据库会自动给主键赋值递增的值，这主要是通过 <strong>AUTO-INC 锁</strong>实现的。</p>
<p><strong>在插入数据时，会加一个表级别的 AUTO-INC 锁</strong>，<strong>不是再一个事务提交后才释放，而是再执行完插入语句后就会立即释放</strong>。</p>
<p>但是， AUTO-INC 锁再对大量数据进行插入的时候，会影响插入性能，因为另一个事务中的插入会被阻塞。</p>
<p>因此， 在 MySQL 5.1.22 版本开始，InnoDB 存储引擎提供了一种<strong>轻量级的锁</strong>来实现自增</p>
<p>InnoDB 存储引擎提供了个 innodb_autoinc_lock_mode 的系统变量，是用来控制选择用 AUTO-INC 锁，还是轻量级的锁。</p>
<ul>
<li>当 innodb_autoinc_lock_mode &#x3D; 0，就采用 AUTO-INC 锁，语句执行结束后才释放锁；</li>
<li>当 innodb_autoinc_lock_mode &#x3D; 2，就采用轻量级锁，申请自增主键后就释放锁，并不需要等语句执行后才释放。</li>
<li>当 innodb_autoinc_lock_mode &#x3D; 1：<ul>
<li>普通 insert 语句，自增锁在申请之后就马上释放；</li>
<li>类似 insert … select 这样的批量插入数据的语句，自增锁还是要等语句结束后才被释放；</li>
</ul>
</li>
</ul>
<p>![img](..&#x2F;images&#x2F;Mysql复习（mysql技术内幕 innodb存储引擎）&#x2F;innodb_autoinc_lock_mode&#x3D;2.png)</p>
<p>session A 往表 t 中插入了 4 行数据，然后创建了一个相同结构的表 t2，然后<strong>两个 session 同时执行向表 t2 中插入数据</strong>。</p>
<p>如果 innodb_autoinc_lock_mode &#x3D; 2，意味着「申请自增主键后就释放锁，不必等插入语句执行完」。那么就可能出现这样的情况：</p>
<ul>
<li>session B 先插入了两个记录，(1,1,1)、(2,2,2)；</li>
<li>然后，session A 来申请自增 id 得到 id&#x3D;3，插入了（3,5,5)；</li>
<li>之后，session B 继续执行，插入两条记录 (4,3,3)、 (5,4,4)。</li>
</ul>
<p>可以看到，<strong>session B 的 insert 语句，生成的 id 不连续</strong>。</p>
<p>当「主库」发生了这种情况，binlog 面对 t2 表的更新只会记录这两个 session 的 insert 语句，如果 binlog_format&#x3D;statement，记录的语句就是原始语句。记录的顺序要么先记 session A 的 insert 语句，要么先记 session B 的 insert 语句。</p>
<p>但不论是哪一种，这个 binlog 拿去「从库」执行，这时从库是按「顺序」执行语句的，只有当执行完一条 SQL 语句后，才会执行下一条 SQL。因此，在<strong>从库上「不会」发生像主库那样两个 session 「同时」执行向表 t2 中插入数据的场景。所以，在备库上执行了 session B 的 insert 语句，生成的结果里面，id 都是连续的。这时，主从库就发生了数据不一致</strong>。</p>
<p>要解决这问题，binlog 日志格式要设置为 row，这样在 binlog 里面记录的是主库分配的自增值，到备库执行的时候，主库的自增值是什么，从库的自增值就是什么。</p>
<p>所以，<strong>当 innodb_autoinc_lock_mode &#x3D; 2 时，并且 binlog_format &#x3D; row，既能提升并发性，又不会出现数据一致性问题</strong>。</p>
<h3 id="3、行锁"><a href="#3、行锁" class="headerlink" title="3、行锁"></a>3、行锁</h3><p>InnoDB实现了以下两种类型的行锁：</p>
<ul>
<li>共享锁（S）：允许一个事务去读一行，阻止其他事务获得相同数据集的排它锁。</li>
<li>排他锁（X）：允许获取排他锁的事务更新数据，阻止其他事务获得相同数据集的共享锁和排他 锁</li>
</ul>
<p>![image-20230805221422216](..&#x2F;images&#x2F;Mysql复习（mysql技术内幕 innodb存储引擎）&#x2F;image-20230805221422216.png)</p>
<h2 id="2、一致性非锁定读（快照读）"><a href="#2、一致性非锁定读（快照读）" class="headerlink" title="2、一致性非锁定读（快照读）"></a>2、一致性非锁定读（快照读）</h2><p>一致性非锁定读是指InnoDb通过多版本控制（MVCC）的方式读取当前执行时间里面数据库的数据。如果读取的那一行正在做一些dml操作，但是我不会去等，我会直接去读一个快照数据。不需要等待X锁的释放，那这个数据是哪里来的呢？这个快照数据是指该行之前版本的数据，他的实现是通过undo页完成的，而一个行记录它对应的可能不只有一个快照数据，所以我们把对于这些快照数据的管理，叫做多版本控制MVCC。当然这里提一嘴就是,读已提交和可重复读这两种级别是可以用一致性非锁定读，但是对于快照数据的定义不一样，读已提交总是读区被锁定行的最新的一份快照，可重复读总是读事务开始时候的数据版本，</p>
<h2 id="3、一致性锁定读（当前读）"><a href="#3、一致性锁定读（当前读）" class="headerlink" title="3、一致性锁定读（当前读）"></a>3、一致性锁定读（当前读）</h2><p>有时候用户需要些显式的对读操作进行加锁保证一致性。</p>
<h2 id="4、锁的算法"><a href="#4、锁的算法" class="headerlink" title="4、锁的算法"></a>4、锁的算法</h2><p>InnoDB有三种行锁的算法：</p>
<p>Record Lock：单个行记录的锁</p>
<p>Gap Lock：间隙锁，锁定一个范围，但不包括记录本身</p>
<p>Next-Key Lock：Record Lock + Gap Lock</p>
<p>InnoDB就是用Next-Key去解决幻想问题（同一事务下，连续执行两次相同的sql语句可能导致不同的结果，第二次sql可能会返回之前不存在的行）</p>
<p>查询的索引如果是唯一性质，那么降级为Record Lock</p>
<h2 id="5、锁问题"><a href="#5、锁问题" class="headerlink" title="5、锁问题"></a>5、锁问题</h2><h3 id="1、脏读"><a href="#1、脏读" class="headerlink" title="1、脏读"></a>1、脏读</h3><p>读到了其他事务没有提交的数据，违反了隔离性。但是脏读发生的隔离级别最少也得是read uncommitted，而我们的数据库默认是可重复读，所以一般在生产环境中，发生的并不多。</p>
<h3 id="2、不可重复读"><a href="#2、不可重复读" class="headerlink" title="2、不可重复读"></a>2、不可重复读</h3><p>就是一个事务读两次，另一个事务在两次读之间作出修改，因为读是mvcc，不加锁，所以会出现不可重复读。innoDB的解决方法：</p>
<ul>
<li>针对<strong>快照读</strong>（普通 select 语句），是<strong>通过 MVCC 方式解决了幻读</strong>，因为可重复读隔离级别下，事务执行过程中看到的数据，一直跟这个事务启动时看到的数据是一致的，即使中途有其他事务插入了一条数据，是查询不出来这条数据的，所以就很好了避免幻读问题。</li>
<li>针对<strong>当前读</strong>（select … for update 等语句），是<strong>通过 next-key lock（记录锁+间隙锁）方式解决了幻读</strong>，因为当执行 select … for update 语句的时候，会加上 next-key lock，如果有其他事务在 next-key lock 锁范围内插入了一条记录，那么这个插入语句就会被阻塞，无法成功插入，所以就很好了避免幻读问题。</li>
</ul>
<h3 id="3、丢失更新"><a href="#3、丢失更新" class="headerlink" title="3、丢失更新"></a>3、丢失更新</h3><p>是指一个事务的操作被另一个事务的操作覆盖了，但是当前数据库的任何隔离级别都对行或者粗粒度的对象加锁，所以还是比较难发生。</p>
<h2 id=""><a href="#" class="headerlink" title=""></a></h2><p>事务级别</p>
<p><strong>类型一：RU（READ-UNCOMMITTED 表示读未提交）</strong></p>
<p>可以读取到事务未提交的数据，隔离性差，会出现脏读（当前内存读），不可重复读，幻读问题;</p>
<p><strong>类型二：RC（READ-COMMITTED 表示读已提交）</strong>可用</p>
<p>可以读取到事务已提交的数据，隔离性一般，不会出现脏读问题，但是会出现不可重复读，幻读问题；</p>
<p><strong>类型三：RR（REPEATABLE-READ 表示可重复读）</strong><code>默认</code></p>
<p>可以防止脏读（当前内存读），防止不可重复读问题，防止会出现的幻读问题，但是并发能力较差；</p>
<p>会使用next lock锁进制，来防止幻读问题，但是引入锁进制后，锁的代价会比较高，比较耗费CPU资源，占用系统性能；</p>
<p><strong>类型四：SR（SERIALIZABLE 可串行化）</strong></p>
<p>隔离性比较高，可以实现串行化读取数据，但是事务的并发度就没有了；</p>
<p>这是事务的最高级别，在每条读的数据上，加上锁，使之不可能相互冲突</p>
<h2 id="6、死锁"><a href="#6、死锁" class="headerlink" title="6、死锁"></a>6、死锁</h2><p>死锁是指两个或以上的事务争夺资源造成的一种互相等待的现象</p>
<p>解决方法：</p>
<p>1、设置超时的阈值，回滚一个事务</p>
<p>2、wait-for-graph 等待图。检测是否有回路。通常用深度优先。1.2版本开始就变成非递归</p>
<p>如果有死锁，那就回归undo量最少的</p>
<h2 id="7、锁升级"><a href="#7、锁升级" class="headerlink" title="7、锁升级"></a>7、锁升级</h2><p>InnoDB中不存在锁升级的问题，因为InnoDB不是更具每个记录来产生锁的，相反，其根据每个事务访问的每个页对锁进行管理，采用的是位图的方式。所以不管你锁住的是页中的一个记录或者多个记录，开销一样</p>
<p>![image-20231006204601132](..&#x2F;images&#x2F;Mysql复习（mysql技术内幕 innodb存储引擎）&#x2F;image-20231006204601132.png)</p>
<h1 id="事务"><a href="#事务" class="headerlink" title="事务"></a>事务</h1><h2 id="1、认识事务"><a href="#1、认识事务" class="headerlink" title="1、认识事务"></a>1、认识事务</h2><h3 id="1、四个特性：acid。"><a href="#1、四个特性：acid。" class="headerlink" title="1、四个特性：acid。"></a>1、四个特性：acid。</h3><p>原子性：要么成功要么失败</p>
<p>一致性：讲数据库从一种状态转变为下一种一致的专题。</p>
<p>isolation：一个事务提交之前对其他事物不可见</p>
<p>durability：一旦提交，那么结果是永久性的</p>
<h3 id="2、分类-1"><a href="#2、分类-1" class="headerlink" title="2、分类"></a>2、分类</h3><p>扁平事务</p>
<p>带有保存点的扁平事务</p>
<p>链事务</p>
<p>嵌套事务</p>
<p>分布式事务</p>
<h2 id="2、事务的实现"><a href="#2、事务的实现" class="headerlink" title="2、事务的实现"></a>2、事务的实现</h2><p>事务的隔离性由锁机制来实现。</p>
<p>原子性、一致性、持久性通过redo log和undo log完成</p>
<p>redo log保证持久性</p>
<p>undo log保证事务的原子性，一致性</p>
<p>redolog恢复提交事务修改的页操作</p>
<p>undo回滚行记录道某个特定版本，事务</p>
<h3 id="1、redo"><a href="#1、redo" class="headerlink" title="1、redo"></a>1、redo</h3><p>有两部分组成：redo log buffer缓冲，redo log file</p>
<p>事务提交的时候必须把事务的所有日志写入重做日志文件进行持久化。这个的所有日志包括redo log 和undo log</p>
<p>为了防止断电导致数据丢失的问题，当有一条记录需要更新的时候，InnoDB 引擎就会先更新内存（同时标记为脏页），然后将本次对这个页的修改以 redo log 的形式记录下来，<strong>这个时候更新就算完成了</strong>。</p>
<p>后续，InnoDB 引擎会在适当的时候，由后台线程将缓存在 Buffer Pool 的脏页刷新到磁盘里，这就是 <strong>WAL （Write-Ahead Logging）技术</strong>。</p>
<p><strong>WAL 技术指的是， MySQL 的写操作并不是立刻写到磁盘上，而是先写日志，然后在合适的时间再写到磁盘上</strong>。</p>
<p>![image-20231007131604938](..&#x2F;images&#x2F;Mysql复习（mysql技术内幕 innodb存储引擎）&#x2F;image-20231007131604938.png)</p>
<p>![image-20231007131752781](..&#x2F;images&#x2F;Mysql复习（mysql技术内幕 innodb存储引擎）&#x2F;image-20231007131752781.png)</p>
<p>![image-20231007131726290](..&#x2F;images&#x2F;Mysql复习（mysql技术内幕 innodb存储引擎）&#x2F;image-20231007131726290.png)</p>
<blockquote>
<p>产生的 redo log 是直接写入磁盘的吗？</p>
</blockquote>
<p>不是的。</p>
<p>实际上， 执行一个事务的过程中，产生的 redo log 也不是直接写入磁盘的，因为这样会产生大量的 I&#x2F;O 操作，而且磁盘的运行速度远慢于内存。</p>
<p>所以，redo log 也有自己的缓存—— <strong>redo log buffer</strong>，每当产生一条 redo log 时，会先写入到 redo log buffer，后续在持久化到磁盘如下图：</p>
<p>![image-20231007131921540](..&#x2F;images&#x2F;Mysql复习（mysql技术内幕 innodb存储引擎）&#x2F;image-20231007131921540.png)</p>
<h3 id="redo-log-什么时候刷盘？"><a href="#redo-log-什么时候刷盘？" class="headerlink" title="redo log 什么时候刷盘？"></a>redo log 什么时候刷盘？</h3><p>缓存在 redo log buffer 里的 redo log 还是在内存中，它什么时候刷新到磁盘？</p>
<p>主要有下面几个时机：</p>
<ul>
<li>MySQL 正常关闭时；</li>
<li>当 redo log buffer 中记录的写入量大于 redo log buffer 内存空间的一半时，会触发落盘；</li>
<li>InnoDB 的后台线程每隔 1 秒，将 redo log buffer 持久化到磁盘。</li>
<li>每次事务提交时都将缓存在 redo log buffer 里的 redo log 直接持久化到磁盘（这个策略可由 innodb_flush_log_at_trx_commit 参数控制，下面会说）。</li>
</ul>
<p>由参数 <code>innodb_flush_log_at_trx_commit</code> 参数控制，可取的值有：0、1、2，默认值为 1，这三个值分别代表的策略如下：</p>
<ul>
<li>当设置该<strong>参数为 0 时</strong>，表示每次事务提交时 ，还是<strong>将 redo log 留在 redo log buffer 中</strong> ，该模式下在事务提交时不会主动触发写入磁盘的操作。</li>
<li>当设置该<strong>参数为 1 时</strong>，表示每次事务提交时，都<strong>将缓存在 redo log buffer 里的 redo log 直接持久化到磁盘</strong>，这样可以保证 MySQL 异常重启之后数据不会丢失。</li>
<li>当设置该<strong>参数为 2 时</strong>，表示每次事务提交时，都只是缓存在 redo log buffer 里的 redo log <strong>写到 redo log 文件，注意写入到「 redo log 文件」并不意味着写入到了磁盘</strong>，因为操作系统的文件系统中有个 Page Cache（如果你想了解 Page Cache，可以看<a target="_blank" rel="noopener" href="https://xiaolincoding.com/os/6_file_system/pagecache.html">这篇 (opens new window)</a>），Page Cache 是专门用来缓存文件数据的，所以写入「 redo log文件」意味着写入到了操作系统的文件缓存。</li>
</ul>
<h3 id="2、undo-log"><a href="#2、undo-log" class="headerlink" title="2、undo log"></a>2、undo log</h3><p>undo log最主要的作用有两点：一个是事务回滚，保证原子性；还有一个是支持mvcc</p>
<p>那我们先讲第一个，就是事务提交之前，如果发生意外，这时候你用redolog是没有办法恢复的，所以我们可以使用undolog，他的做法是，假如我们去修改一个数据，上锁之后，我们把该行数据拷贝到 <code>undo log</code>作为旧版本。copy之后，那进行真正的修改操作，同时修改trxid 和roll_pointer。</p>
<p>另外一个大的作用是mvcc，mvcc他是基于undo log版本链和ReadView实现</p>
<p>然后每一行数据其实都有两个隐藏列，一个是trxid一个是rollpointer，trxid 表示修最新修改事务的id，rollpointer表示指向旧版本log</p>
<p>ReadView，里面有四个比较关键的东西：</p>
<p>一个是m_ids，这个就是说事务开启那一刻有哪些事务在Mysql里面执行还没有提交的；</p>
<p>一个是min_trx_id，就是m_ids里最小的事务id的值；</p>
<p>一个是max_trx_id，就是此刻mysql下一个要生成的事务id，就是最大事务id；</p>
<p>一个是creator_trx_id，就是你这个事务的id。</p>
<p>那我们只要对比mintexid，如果说比他小，说明已经事务已经提交了，我们可以看得见。</p>
<p>比如一条记录旧版本里面有三条记录：10，20，30。然后我们的事务id是15，m_ids里面有20，30。这里的min_trx_id就是20，我们的15比她小，说明还没有提交。因为隔离性所以肯定是看不到的，然后再去找更前面版本，我们就找到了10，发现10可以，所以我们这次读到的数据就是事务id为10的那一个版本。</p>
<p>rr：事务启动的时候创建readview</p>
<p>rc：每次查询都会创建一个readview</p>

                    
                        


                    
                    
                        <p>
                            <a
                                href="/2023/07/08/Mysql%E5%A4%8D%E4%B9%A0%EF%BC%88mysql%E6%8A%80%E6%9C%AF%E5%86%85%E5%B9%95%20innodb%E5%AD%98%E5%82%A8%E5%BC%95%E6%93%8E%EF%BC%89/#post-footer"
                                class="postShorten-excerpt_link link"
                                aria-label=""
                            >
                                Kommentieren und teilen
                            </a>
                        </p>
                    
                </div>
            
        </div>
        
    </article>
    
    <div class="pagination-bar">
    <ul class="pagination">
        
        
        <li class="pagination-number">Seite 1 von 1</li>
    </ul>
</div>

</section>



                <footer id="footer" class="main-content-wrap">
    <span class="copyrights">
        Copyrights &copy; 2023 CSEN. All Rights Reserved.
    </span>
</footer>

            </div>
            
        </div>
        


    
        
    

<div id="about">
    <div id="about-card">
        <div id="about-btn-close">
            <i class="fa fa-times"></i>
        </div>
        
            <img id="about-card-picture" src="/assets/images/head.jpg" alt="Bild des Autors"/>
        
            <h4 id="about-card-name">CSEN</h4>
        
            <div id="about-card-bio"><p>author.bio</p>
</div>
        
        
            <div id="about-card-job">
                <i class="fa fa-briefcase"></i>
                <br/>
                <p>author.job</p>

            </div>
        
        
            <div id="about-card-location">
                <i class="fa fa-map-marker-alt"></i>
                <br/>
                浙江温州
            </div>
        
    </div>
</div>

        
        
<div id="cover" style="background-image:url('/assets/images/cover.jpg');"></div>
        <!--SCRIPTS-->

<script src="/assets/js/script-39paoi2hupf5wmw7ojejrxpco6edftjriz5ezbtp4grymrdceksftgan2adp.min.js"></script>

<!--SCRIPTS END-->





    </body>
</html>
