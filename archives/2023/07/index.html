
<!DOCTYPE html>
<html lang="zh-CH">
    
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1">
    <meta name="generator" content="森">
    <title>Archiv: 2023/7 - 森</title>
    <meta name="author" content="CSEN">
    
    
    
    <script type="application/ld+json">{}</script>
    <meta name="description" content="潮起潮落，云卷云舒">
<meta property="og:type" content="blog">
<meta property="og:title" content="森">
<meta property="og:url" content="http://example.com/archives/2023/07/index.html">
<meta property="og:site_name" content="森">
<meta property="og:description" content="潮起潮落，云卷云舒">
<meta property="og:locale" content="zh_CH">
<meta property="article:author" content="CSEN">
<meta name="twitter:card" content="summary">
    
    
        
    
    
        <meta property="og:image" content="http://example.com/assets/images/head.jpg"/>
    
    
    
    
    <!--STYLES-->
    
<link rel="stylesheet" href="/assets/css/style-w816scvuzwavitjylabixcb3ofuoklqul47j3rgwu1r0mxrxvbdehvp2jk5s.min.css">

    <!--STYLES END-->
    

    

    
</head>

    <body>
        <div id="blog">
            <!-- Define author's picture -->


    
        
            
        
    

<header id="header" data-behavior="1">
    <i id="btn-open-sidebar" class="fa fa-lg fa-bars"></i>
    <div class="header-title">
        <a
            class="header-title-link"
            href="/"
            aria-label=""
        >
            森
        </a>
    </div>
    
        
            <a
                class="header-right-picture "
                href="#about"
                aria-label="Öffne den Link: /#about"
            >
        
        
            <img class="header-picture" src="/assets/images/head.jpg" alt="Bild des Autors"/>
        
        </a>
    
</header>

            <!-- Define author's picture -->



        
    

<nav id="sidebar" data-behavior="1">
    <div class="sidebar-container">
        
            <div class="sidebar-profile">
                <a
                    href="/#about"
                    aria-label="Lesen Sie mehr über den Autor"
                >
                    <img class="sidebar-profile-picture" src="/assets/images/head.jpg" alt="Bild des Autors"/>
                </a>
                <h4 class="sidebar-profile-name">CSEN</h4>
                
                    <h5 class="sidebar-profile-bio"><p>author.bio</p>
</h5>
                
            </div>
        
        
            <ul class="sidebar-buttons">
            
                <li class="sidebar-button">
                    
                        <a
                            class="sidebar-button-link "
                            href="/"
                            
                            rel="noopener"
                            title="首页"
                        >
                        <i class="sidebar-button-icon fa fa-home" aria-hidden="true"></i>
                        <span class="sidebar-button-desc">首页</span>
                    </a>
            </li>
            
                <li class="sidebar-button">
                    
                        <a
                            class="sidebar-button-link "
                            href="/all-categories"
                            
                            rel="noopener"
                            title="分类"
                        >
                        <i class="sidebar-button-icon fa fa-bookmark" aria-hidden="true"></i>
                        <span class="sidebar-button-desc">分类</span>
                    </a>
            </li>
            
                <li class="sidebar-button">
                    
                        <a
                            class="sidebar-button-link "
                            href="/all-tags"
                            
                            rel="noopener"
                            title="标签"
                        >
                        <i class="sidebar-button-icon fa fa-tags" aria-hidden="true"></i>
                        <span class="sidebar-button-desc">标签</span>
                    </a>
            </li>
            
                <li class="sidebar-button">
                    
                        <a
                            class="sidebar-button-link "
                            href="/all-archives"
                            
                            rel="noopener"
                            title="档案"
                        >
                        <i class="sidebar-button-icon fa fa-archive" aria-hidden="true"></i>
                        <span class="sidebar-button-desc">档案</span>
                    </a>
            </li>
            
                <li class="sidebar-button">
                    
                        <a
                            class="sidebar-button-link open-algolia-search"
                            href="#search"
                            
                            rel="noopener"
                            title="搜索"
                        >
                        <i class="sidebar-button-icon fa fa-search" aria-hidden="true"></i>
                        <span class="sidebar-button-desc">搜索</span>
                    </a>
            </li>
            
                <li class="sidebar-button">
                    
                        <a
                            class="sidebar-button-link "
                            href="#about"
                            
                            rel="noopener"
                            title="关于"
                        >
                        <i class="sidebar-button-icon fa fa-question" aria-hidden="true"></i>
                        <span class="sidebar-button-desc">关于</span>
                    </a>
            </li>
            
        </ul>
        
            <ul class="sidebar-buttons">
            
                <li class="sidebar-button">
                    
                        <a
                            class="sidebar-button-link "
                            href="https://github.com/Caosen0819"
                            
                                target="_blank"
                            
                            rel="noopener"
                            title=".github"
                        >
                        <i class="sidebar-button-icon fab fa-github" aria-hidden="true"></i>
                        <span class="sidebar-button-desc">.github</span>
                    </a>
            </li>
            
        </ul>
        
    </div>
</nav>

            
            <div id="main" data-behavior="1"
                 class="
                        hasCoverMetaIn
                        ">
                
    <section class="postShorten-group main-content-wrap">
    
    
    <article class="postShorten postShorten--thumbnailimg-bottom">
        <div class="postShorten-wrap">
            
            <div class="postShorten-header">
                <h1 class="postShorten-title">
                    
                        <a
                            class="link-unstyled"
                            href="/2023/07/08/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C%E5%A4%8D%E4%B9%A01/"
                            aria-label=": 计算机网络复习1"
                        >
                            计算机网络复习1
                        </a>
                    
                </h1>
                <div class="postShorten-meta">
    <time datetime="2023-07-08T00:00:00+08:00">
	
		    08 Jul 2023
    	
    </time>
    
        <span>in </span>
        
    <a class="category-link" href="/categories/Java/">Java</a>


    
</div>

            </div>
            
                <div class="postShorten-content">
                    <p>计算机网络整体的学习可以按照tcpip网络模型进行学习。我们的总结也是这样的</p>
<p>Tcp&#x2F;ip网络模型分别是应用层、传输层、网络层、数据链路层</p>
<p>这里面前三层比较重要，数据链路层复杂的方面涉及实际的物理知识所以我们只对逻辑思想上做一个学习，</p>
<p>那每一层分别学的是什么呢？</p>
<p>应用层：HTTP  HTTPs TLS</p>
<p>传输层：tcp udp </p>
<p>网络层：ipv4 v6</p>
<p>基本上就是这样子</p>
<p>TCP 连接传输协议，这是传输层的，很多应用层的协议在传输层都是使用这个的，比如HTTP</p>
<p>那tcp和udp的差距是，tcp相比udp多了很多为了可靠的连接所增加的特性，比如流量控制，超时重传，拥塞控制，就是为了数据能可靠的传到对方，但是过程中究竟是请求-应答模式还是什么模式，那就是后面的不同版本做出的更新。</p>
<p>udp他不在乎这个数据究竟有没有到对面，只负责发送，所以实时性好，效率高。但是他并不是不能做到可靠传输，因为udp只是传输层，我们还可以在应用层做出一定的限制来保证传输是可靠的，比如quic协议，当然这是困难的。</p>
<p>除此之外，还有一个很大的不同就是tcp是会分片的，但是udp是不会分片。在这里我们还要知道的一点是在网络层，也就是ip协议中还是会分片的，大小是MTU。但是对于tcp来说因为你要是在ip层才分片，我为了保证可靠，我假设12345 丢了一个2，那我就要12345全部重新发，这样不好，所以我们就在tcp层也分片，大小是MSS。而udp不用可靠，所以他不用分片。</p>
<p>网络层，主要的作用其实就是路由和寻址，加上ip头，规定好源ip，目的ip等信息，</p>
<p>网络接口层，是提供链路级别的传输服务，因为源ip和目的ip知道了，但是在以太网中实际上是不行的，IP会变，我们需要一个确切的信息，这个就是mac地址，</p>
<h1 id="那我们这里用输入网址到显示，来串联一下整体的流程："><a href="#那我们这里用输入网址到显示，来串联一下整体的流程：" class="headerlink" title="那我们这里用输入网址到显示，来串联一下整体的流程："></a>那我们这里用输入网址到显示，来串联一下整体的流程：</h1><h4 id="1、解析url"><a href="#1、解析url" class="headerlink" title="1、解析url"></a>1、解析url</h4><p>解析之后得到三个信息，一个协议，一个是web服务器域名，一个是请求文件的路径（可选）</p>
<p>那对于我们前两个是最重要的，</p>
<p>这时候我们客户端生产自己的HTTP请求报文，格式如下，方法get，url没有默认index什么的，版本HTTP1.1，字段名就很多，然后是数据，这个数据也是后面一种包装的根数据。</p>
<p><img src="/../images/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C%E5%A4%8D%E4%B9%A01/image-20230728193306158.png" alt="image-20230728193306158">	</p>
<p>如图所示，一个是请求一个是响应报文</p>
<p>到这里消息成功生产，那我们生产出一个消息之后就要开始发送？那应该怎么发？往哪里发？</p>
<p>这就需要下面的知识。</p>
<h2 id="地址查询-——-DNS"><a href="#地址查询-——-DNS" class="headerlink" title="地址查询 —— DNS"></a>地址查询 —— DNS</h2><p>基于我们已经拿到的web服务器域名，我们可以先去浏览器缓存里面找有没有，如果有，就直接返回，如果没有那就问操作系统的缓存再去看hosts文件，如果都没有，那就看走下面</p>
<p>客户端首先会发出一个 DNS 请求，问 <a target="_blank" rel="noopener" href="http://www.xx.com/">www.xx.com</a> 的 IP 是啥，发给本地 DNS 服务器（也就是客户端的 TCP&#x2F;IP 设置中填写的 DNS 服务器地址）。</p>
<p>本地域名服务器收到客户端的请求后，如果缓存里的表格能找到 <a target="_blank" rel="noopener" href="http://www.xx.com,则它直接返回/">www.xx.com，则它直接返回</a> IP 地址。如果没有，本地 DNS 会去问它的根域名服务器：“老大， 能告诉我 <a target="_blank" rel="noopener" href="http://www.xx.com/">www.xx.com</a> 的 IP 地址吗？” 根域名服务器是最高层次的，它不直接用于域名解析，但能指明一条道路。</p>
<p>根 DNS 收到来自本地 DNS 的请求后，发现后置是 .com，说：“<a target="_blank" rel="noopener" href="http://www.xx.com/">www.xx.com</a> 这个域名归 .com 区域管理”，我给你 .com 顶级域名服务器地址给你，你去问问它吧。”</p>
<p>本地 DNS 收到顶级域名服务器的地址后，发起请求问“老二， 你能告诉我 <a target="_blank" rel="noopener" href="http://www.xx.com/">www.xx.com</a> 的 IP 地址吗？”</p>
<p>顶级域名服务器说：“我给你负责 <a target="_blank" rel="noopener" href="http://www.xx.com/">www.xx.com</a> 区域的权威 DNS 服务器的地址，你去问它应该能问到”。</p>
<p>本地 DNS 于是转向问权威 DNS 服务器：“老三，<a href="http://www.xx.com对应的IP是啥呀？”">www.xx.com对应的IP是啥呀？”</a> server.com 的权威 DNS 服务器，它是域名解析结果的原出处。为啥叫权威呢？就是我的域名我做主。</p>
<p>权威 DNS 服务器查询后将对应的 IP 地址 X.X.X.X 告诉本地 DNS。</p>
<p>本地 DNS 再将 IP 地址返回客户端，客户端和目标建立连接</p>
<p><img src="/../images/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C%E5%A4%8D%E4%B9%A01/image-20230728193808617.png" alt="image-20230728193808617"></p>
<p>通过dns或者缓存获取到ip地址之后，我们就要为发送做一些准备，首先浏览器通过调用 Socket 库，来委托协议栈工作。</p>
<p><img src="/../images/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C%E5%A4%8D%E4%B9%A01/image-20230728193955912.png" alt="image-20230728193955912"></p>
<p>说是协议栈，其实就是中间tcp udp ip这些协议。那下面我们就来仔细的看看</p>
<h2 id="TCP"><a href="#TCP" class="headerlink" title="TCP"></a>TCP</h2><p>tcp段的头如下所示：</p>
<p><img src="/../images/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C%E5%A4%8D%E4%B9%A01/image-20230728194108402.png" alt="image-20230728194108402"></p>
<p>TCP 传输数据之前，要先三次握手建立连接</p>
<p>前提：客户端 为closed状态，服务端变成listen状态</p>
<p>连接：</p>
<p>1、客户端向服务端发送连接syn，之后客户端处于syn-sent状态；</p>
<p>2、服务端接收到这个消息之后，会返回一个syn+ack，之后服务端处于syn-rcvd状态</p>
<p>3、客户端收到这个之后，再给服务端发送一个对syn的ack，之后客户端处于establish状态</p>
<p>服务端收到ack也变成了establish状态</p>
<p>所以三次握手目的是<strong>保证双方都有发送和接收的能力</strong>。</p>
<p>假设我们已经建立了连接，我们要发送消息，但是消息要遵循tcp协议，他的消息大小是有限制的，不是每一次都可以发送全部消息。具体要求如下：</p>
<p><img src="/../images/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C%E5%A4%8D%E4%B9%A01/image-20230728195857751.png" alt="image-20230728195857751"></p>
<ul>
<li><code>MTU</code>：一个网络包的最大长度，以太网中一般为 <code>1500</code> 字节。</li>
<li><code>MSS</code>：除去 IP 和 TCP 头部之后，一个网络包所能容纳的 TCP 数据的最大长度</li>
</ul>
<p>所以如果HTTP请求消息超过mss，那么就要分段发送。</p>
<p>到这里我们得到了一个tcp的报文段或者说包，下面我们就要把这个包发送给网络层，因为在传输层我们就是服务应用层，然后对好端口，确定好协议，之后的事情就不归传输层管控了。</p>
<p>到这里，我们的数据包的格式如下所示：</p>
<p><img src="/../images/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C%E5%A4%8D%E4%B9%A01/image-20230728200405680.png" alt="image-20230728200405680"></p>
<h2 id="定位IP"><a href="#定位IP" class="headerlink" title="定位IP"></a>定位IP</h2><p>ip协议的最重要的功能就是寻址和路由，他要做到这两点就需要你遵循ip协议，那么遵循的要求就是你加一个ip头<img src="/../images/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C%E5%A4%8D%E4%B9%A01/image-20230728200452235.png" alt="image-20230728200452235"></p>
<p>加上ip头之后我们就知道了我们的源ip和目的ip地址，那么起点站和终点站就已经知道了</p>
<p>可以现在又有一个小问题，那就是路径怎么规划呢？这时候就需要用到Mac地址</p>
<h2 id="mac地址"><a href="#mac地址" class="headerlink" title="mac地址"></a>mac地址</h2><p><img src="/../images/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C%E5%A4%8D%E4%B9%A01/image-20230728202408619.png" alt="image-20230728202408619"></p>
<ul>
<li>先查询 ARP 缓存，如果其中已经保存了对方的 MAC 地址，就不需要发送 ARP 查询，直接使用 ARP 缓存中的地址。</li>
<li>而当 ARP 缓存中不存在对方 MAC 地址时，则发送 ARP 广播查询</li>
</ul>
<p>也就是说到了网络接口层，要发了，结果不知道往哪里发，这时候就按照上面两步得到mac地址</p>
<p>因为上面已经得到了ip地址，所以直接喊话：这个 IP 地址是谁的？请把你的 MAC 地址告诉我，就得到mac地址了。</p>
<p>到这里数据包还差最后一层包装</p>
<h2 id="出口–网卡"><a href="#出口–网卡" class="headerlink" title="出口–网卡"></a>出口–网卡</h2><p><img src="/../images/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C%E5%A4%8D%E4%B9%A01/image-20230728204942674.png" alt="image-20230728204942674"></p>
<p>最后一层包装就是上面图片提到的报头和起始帧分界符和fcs帧校验序列</p>
<p>网卡驱动获取网络包之后，会将其<strong>复制</strong>到网卡内的缓存区中，接着会在其<strong>开头加上报头和起始帧分界符，在末尾加上用于检测错误的帧校验序列</strong>。</p>
<p>到这里数据包就真正的包装结束了，最后网卡会将包转为电信号，通过网线发送出去。！！</p>
<h2 id="送别者—交换机"><a href="#送别者—交换机" class="headerlink" title="送别者—交换机"></a>送别者—交换机</h2><p>交换机的设计是将网络包<strong>原样</strong>转发到目的地。交换机工作在 MAC 层，也称为<strong>二层网络设备</strong>。</p>
<p>一般在网线接口啊这些地方，其实路由器也可以作为交换机。</p>
<h3 id="交换机的包接收操作"><a href="#交换机的包接收操作" class="headerlink" title="交换机的包接收操作"></a>交换机的包接收操作</h3><p>交换机里的模块将电信号转换为数字信号。</p>
<p>然后通过包末尾的fcs校验错误，没问题就放到缓存区，这部分操作基本和计算机的网卡相同，但交换机的工作方式和网卡不同。</p>
<p>计算机的网卡本身具有 MAC 地址，并通过核对收到的包的接收方 MAC 地址判断是不是发给自己的，如果不是发给自己的则丢弃；相对地，交换机的端口不核对接收方 MAC 地址，而是直接接收所有的包并存放到缓冲区中。因此，和网卡不同，<strong>交换机的端口不具有 MAC 地址</strong>。</p>
<h3 id="查询MAC-地址表"><a href="#查询MAC-地址表" class="headerlink" title="查询MAC 地址表"></a>查询<strong>MAC 地址表</strong></h3><p>如果找到，就发送到相应的端口，如果找不到，那说明该mac地址的设备还没有向我们交换机发送过包，那这时候我们主动的向除了源端口的所有端口都发送一遍，因为后面的设备他自己都有检测功能，所以不需要担心</p>
<p>这时候要么就发送到位，要么就可能离开子网了，离开子网需要用到路由器</p>
<h2 id="出境大门–路由器"><a href="#出境大门–路由器" class="headerlink" title="出境大门–路由器"></a>出境大门–路由器</h2><h3 id="路由器的包接收操作"><a href="#路由器的包接收操作" class="headerlink" title="路由器的包接收操作"></a>路由器的包接收操作</h3><blockquote>
<p>1、首先，电信号到达网线接口部分，路由器中的模块会将电信号转成数字信号，然后通过包末尾的 <code>FCS</code> 进行错误校验。</p>
<p>2、检查 MAC 头部中的<strong>接收方 MAC 地址</strong>，看看是不是发给自己的包，如果是就放到接收缓冲区中，否则就丢弃这个包。</p>
<p>3、路由器就会<strong>去掉</strong>包开头的 MAC 头部。</p>
</blockquote>
<h3 id="路由器的发送操作"><a href="#路由器的发送操作" class="headerlink" title="路由器的发送操作"></a>路由器的发送操作</h3><p><font color='red'><u><em>*<em><strong>匹配路由表确定输出端口并判断转发目标</strong>。</em>*而路由器则会忽略主机号部分，只匹配网络号部分 这里用的是最长匹配，</em><em>如果匹配上了，我们就看下他的网关列，如果网关是一个 IP 地址，那就是我们的转发目标，如果为空，那就是终点了。下面通过通过 ARP协议根据 IP 地址查询 MAC 地址，路由器也有 ARP 缓存，因此首先会在 ARP 缓存中查询，如果找不到则发送 ARP 查询请求。</em>**</u></font></p>
<p><img src="/../images/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C%E5%A4%8D%E4%B9%A01/image-20231025123050860.png" alt="image-20231025123050860"></p>
<p>接下来是发送方 MAC 地址字段，这里填写输出端口的 MAC 地址。还有一个以太类型字段，填写 <code>0800</code> （十六进制）表示 IP 协议。</p>
<p>网络包完成后，接下来会将其转换成电信号并通过端口发送出去。这一步的工作过程和计算机也是相同的。</p>
<p>发送出去的网络包会通过<strong>交换机</strong>到达下一个路由器。由于接收方 MAC 地址就是下一个路由器的地址，所以交换机会根据这一地址将包传输到下一个路由器。</p>
<h1 id="例子"><a href="#例子" class="headerlink" title="例子"></a>例子</h1><p>这边举个例子<img src="/../images/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C%E5%A4%8D%E4%B9%A01/image-20230729000740012.png" alt="image-20230729000740012"></p>
<p>子网1某个设备想要发送数据给子网2的某个设备</p>
<p>首先源ip和目的ip是知道的，如果只是简单的arp群发这个ip问是谁的ip地址，其实是找不到的，所以判断是否为同一子网，如果不是，就把目的mac改成网关的mac，然后数据发送到网关，这时候官网一查mac地址，发现属于子网2的设备，这时候修改源mac为自己的mac，修改目的mac为设备的地址，从子网2的网卡发出。</p>
<p>大多数情况下一个子网的默认网关就是一个，就基本代表着出口。复杂情况就需要某种选择算法了</p>
<h2 id="HTTP"><a href="#HTTP" class="headerlink" title="HTTP"></a>HTTP</h2><p>超文本传输协议，就是两点之间超越普通文本范畴的文本（包括文本视频图片等等）的一种协议</p>
<h4 id="HTTP常见状态码"><a href="#HTTP常见状态码" class="headerlink" title="HTTP常见状态码"></a>HTTP常见状态码</h4><blockquote>
<p>1XX 代表提示信息，表示这是处理的中间状体，后续还有操作</p>
<p>2XX 这个就是成功的状态吗</p>
<p>​	200 普通的正常的成功</p>
<p>​	204 没有body的成功，就是响应头里面没有body数据的意思</p>
<p>​	206 用于分快下载，断点续传，</p>
<p>3XX 代表重定向</p>
<p>​	 301 永久重定向</p>
<p>​	302 临时重定向</p>
<p>​	304缓存重定向，也就是配合协商缓存那一块</p>
<p>4XX 代表客户端的报文错误</p>
<p>​	400 比较笼统的</p>
<p>​	403 禁止范围</p>
<p>​	404 没找到</p>
<p>5XX 代表服务器端端报文错误</p>
<p>​	500 同样比较笼统</p>
<p>​	501 目前不支持</p>
<p>​	502 自身服务器没问题，后续转发的服务器有问题</p>
<p>​	503 请稍后再访问</p>
</blockquote>
<h4 id="常见的字段"><a href="#常见的字段" class="headerlink" title="常见的字段"></a>常见的字段</h4><blockquote>
<p>host</p>
<p>content-length</p>
<p>content-type</p>
<p>connection </p>
<p>content-encodeing</p>
</blockquote>
<h4 id="HTTP缓存"><a href="#HTTP缓存" class="headerlink" title="HTTP缓存"></a>HTTP缓存</h4><p>包括强制缓存和协商缓存</p>
<p>强制缓存就是浏览器判断缓存没有过期，那我就直接使用浏览器的缓存</p>
<p>实现可以用两个响应头部的字段表示Cache-control和Expires，前者相对时间，后者绝对时间，前者优先级更高，更加精细</p>
<p>协商缓存也是有两种方法</p>
<p>1、请求头部里面的if modified since 和响应头部last- modified</p>
<p>先问浏览器缓存，如果没过期那就是强制缓存，如果过期了，响应信息的头部会有last modified，然后我们会带这个ifmodifiedsince：时间，去访问服务器，服务器看到之后，就拿自己的Last modified去对比 如果没改，返回304，如果改了，返回200</p>
<p>2、Etag 唯一标识</p>
<p>流程一样，但是etag优先级更高，因为 if modified since还是基于时间，而时间本身可能有一些限制。</p>
<p>1、有可能没有修改文件，但是文件的最后修改时间会变化</p>
<p>2、秒级以内的操作也许不能充分做出响应</p>
<h4 id="HTTP优缺点"><a href="#HTTP优缺点" class="headerlink" title="HTTP优缺点"></a>HTTP优缺点</h4><p><strong>优点：</strong></p>
<blockquote>
<p>简单，灵活易扩充，应用广泛跨平台</p>
</blockquote>
<p><strong>缺点：</strong></p>
<blockquote>
<p>1、HTTP无状态的，所以导致一系列相联的操作可能每一次都要反问数据库，那就非常的繁琐</p>
<p>在此基础上出现了cookie技术，他就是通过在请求和响应报文里面增加cookie信息，来控制客户端的状态</p>
<p>2、明文传输。毫无隐私</p>
<p>3、不安全 也是最重要的原因</p>
<blockquote>
<p>账号信息不安全</p>
<p>不验证对方的身份</p>
<p>无法证明报文的完整性</p>
</blockquote>
</blockquote>
<p><strong>HTTP1.1改进</strong></p>
<blockquote>
<p>1、HTTP1.1在HTTP1.0的基础上提出了长连接，之前是《请求-应答》模式就是你发完应答完，关闭连接，想要进行下一次通信，那就得重新建立连接，现在可以建立一次连接之后，就可以 发收发收发收 只要一方没有明确提出断开连接，那么就一直连着</p>
<p>2、管道通信，HTTP1.1支持管道，就是所有请求都处于管道内部，我们可以发发发，而不需要等他先回复再发第二个，你可以发发发，减少了时间</p>
<p>但是这里有一个问题，HTTP是基于tcp的所以服务端会按照顺序接收请求。</p>
<p>所以说，HTTP1.1可以解决发送端的对头阻塞，但是无法解决接受端的对头阻塞</p>
<p>然而！然而！HTTP1.1默认不开启管道，</p>
</blockquote>
<h2 id="HTTPS"><a href="#HTTPS" class="headerlink" title="HTTPS"></a>HTTPS</h2><p>但是安全性的那三个缺点依旧无法得到改善，所以提出了HTTPs &#x3D; HTTP + TLS</p>
<p>我们可以知道TLS他其实做了三件事情：信息加密，校验机制，身份证书</p>
<h3 id="TLS"><a href="#TLS" class="headerlink" title="TLS"></a>TLS</h3><h4 id="1、信息加密"><a href="#1、信息加密" class="headerlink" title="1、信息加密"></a>1、信息加密</h4><p>使用的是混合加密，采用对称加密和非对称加密的结合体，混合加密，就是两种都用到了，非对称加密是在TLS握手的时候，对称加密是在传输数据的时候。</p>
<p>非对成加密安全，非对称加密速度更快。</p>
<h4 id="2、校验机制，身份证书，这两个可以一起讲"><a href="#2、校验机制，身份证书，这两个可以一起讲" class="headerlink" title="2、校验机制，身份证书，这两个可以一起讲"></a>2、校验机制，身份证书，这两个可以一起讲</h4><p>对内容先哈希算法，然后用私钥加密哈希结果得到的结果叫数字签名，把数字签名和原本的内容和在一起就相当于认证了</p>
<p>然后现在还是缺一个身份验证的问题，就是这个私钥到底对不对？</p>
<p>这时候需要一个权威机关，就叫CA</p>
<p>整体流程：服务器发送公钥和数字签名发到CA里面，CA用自己的私钥加密服务器的公钥和数字签名，这个就是证书！然后客户端发来请求的时候，服务器就把自己的证书发过去，客户端收到证书，用CA的公钥解密，得到了服务器的公钥和服务器的数字证签名，这个签名我们上面讲了一个是原始内容一个是私钥对于哈希值的加密，那我们怎么验证呢？就是用公钥去解密加密项得到一个哈希值，再对原始内容做同样的哈希操作，判断两个哈希值到底一不一样，一样代表认证成功，否则，认证失败。</p>
<h4 id="3、TLS的秘钥交换算法"><a href="#3、TLS的秘钥交换算法" class="headerlink" title="3、TLS的秘钥交换算法"></a>3、TLS的秘钥交换算法</h4><p>TLS的密钥交换算法不同，那么连接步骤也不同，我们会介绍两种</p>
<h5 id="RSA"><a href="#RSA" class="headerlink" title="RSA"></a>RSA</h5><p><strong>1、客户端 &gt; 服务端。</strong></p>
<blockquote>
<p>Client Hello：client 随机数 + TLS版本号+密码套件，密码套件可以说是一组配置的整合信息罢了</p>
</blockquote>
<p><strong>2、客户端 &lt; 服务端。</strong></p>
<blockquote>
<p>Server Hello:server随机数+确认版本号+确认密码套件</p>
<p>Certificate: 证书</p>
<p>Server Hello Done：</p>
</blockquote>
<p>当然这里收到之后，先校验，校验流程如下：</p>
<p>首先我们知道了数字签名有原始内容和对于哈希值加密的数字签名，我们对原始内容加密（签名算法），对数字签名解密（CA公钥）</p>
<p>当然，其中有一个问题就是证书的信任问题？为什么？</p>
<p>因为我们得到的证书不一定是CA签发的，假如是中间机构签发的百度证书，那么我们就不能用内置的本地CA证书中的公钥去认证，所以我们先找签发机构，发现是一个中间机构，我们向中间机构请求证书，收到证书后发现这个机构的签发者是CA，那么我们可以用CA去认证中间的这个证书，这个证书被认证了 ，那么百度的也没认证了。</p>
<p><strong>3、客户端 &gt; 服务端 使用服务器的公钥加密pre-master随机数发给服务端</strong></p>
<blockquote>
<p>Client Key Exchange: 用第二步解密得到的公钥加密pre-master</p>
<p>Change Cipher spec：改用会话秘钥加密通信，</p>
<p>Finished：所有握手数据的摘要，再用会话密钥（master secret）加密一下，让服务器做个验证</p>
</blockquote>
<p><strong>4、客户端 &lt; 服务端 服务端发送 加密算法改变通知，和握手结束通知</strong></p>
<blockquote>
<p>Change Cipher spec：改用会话秘钥加密通信</p>
<p>Finished: 所有握手数据的摘要，再用会话密钥（master secret）加密一下，让服务器做个验证</p>
</blockquote>
<p>上面这个就是RSA的基本流程，但是基于RSA的HTTPS依旧存在《前向安全》的问题，客户端发送给服务端的随机数要用服务端的公钥加密，如果服务端私钥泄密，那么所有的TLS通讯就将被破解</p>
<h5 id="ECDHE"><a href="#ECDHE" class="headerlink" title="ECDHE"></a>ECDHE</h5><p>讲过程之前，可以先说一下这个算法。先讲一下前身DH算法。这个算法依赖的就是对数运算的基础上加了「模运算」。我们对数算法知道对数得到真数很简单，但是从真数得到对数是很难的。</p>
<p><strong>1、客户端 &gt; 服务端。</strong></p>
<blockquote>
<p>Client Hello：client 随机数 + TLS版本号+密码套件，密码套件可以说是一组配置的整合信息罢了</p>
</blockquote>
<p><strong>2、客户端 &lt; 服务端。</strong></p>
<blockquote>
<p>Server Hello:server随机数+确认版本号+确认密码套件</p>
<p>Certificate: 证书</p>
<p><strong>Server Key Exchange</strong>：选择椭圆曲线，随机数作为私钥，根据椭圆曲线的基点和私钥算出公钥，发给客户端</p>
<p>Server Hello Done：</p>
</blockquote>
<p><strong>3、客户端 &gt; 服务端 使用服务器的公钥加密pre-master随机数发给服务端</strong></p>
<blockquote>
<p>Client Key Exchange: 生成一个随机数作为客户端的私钥，根据前面信息生成<strong>客户端的公钥</strong>，发给服务端。<font color='red'><u><em><strong>至此，双方都有对方的椭圆曲线公钥、自己的椭圆曲线私钥、椭圆曲线基点 G。所以能算出x，两个随机数+x就是最后的秘钥</strong></em></u></font></p>
<p>Change Cipher spec：改用会话秘钥加密通信，</p>
<p><strong>Encrypted Handshake Message</strong>：所有握手数据的摘要，再用会话密钥加密一下，让服务器做个验证</p>
</blockquote>
<p><strong>4、客户端 &lt; 服务端 服务端发送 加密算法改变通知，和握手结束通知</strong></p>
<blockquote>
<p>Change Cipher spec：改用会话秘钥加密通信</p>
<p>Encrypted Handshake Message: 所有握手数据的摘要，再用会话密钥（master secret）加密一下，让服务器做个验证</p>
</blockquote>
<p>RSA和ECDHE的区别</p>
<ul>
<li>RSA 密钥协商算法「不支持」前向保密，ECDHE 密钥协商算法「支持」前向保密；</li>
<li>使用了 RSA 密钥协商算法，TLS 完成四次握手后，才能进行应用数据传输，而对于 ECDHE 算法，客户端可以不用等服务端的最后一次 TLS 握手，就可以提前发出加密的 HTTP 数据，节省了一个消息的往返时间（这个是 RFC 文档规定的，具体原因文档没有说明，所以这点我也不太明白）；</li>
<li>使用 ECDHE， 在 TLS 第 2 次握手中，会出现服务器端发出的「Server Key Exchange」消息，而 RSA 握手过程没有该消息</li>
</ul>
<h4 id="HTTPS怎么实现数据的完整性？"><a href="#HTTPS怎么实现数据的完整性？" class="headerlink" title="HTTPS怎么实现数据的完整性？"></a>HTTPS怎么实现数据的完整性？</h4><p>刚才我们提到了TLS可以解决三个问题，包括完整性，</p>
<p>其实TLS在实现上包括了握手协议和记录协议</p>
<p>​	握手协议就是四次握手+后续加密来保护应用程序</p>
<p>​	记录协议负责保护数据的完整性和来源</p>
<p>所以我们来看记录协议：，他的实现就是负责对消息（HTTP数据）的压缩，加密和数据认证<img src="/../images/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C%E5%A4%8D%E4%B9%A01/image-20230802185945107.png" alt="	"></p>
<p>这里还是应用层，消息被分割后进行压缩，加上消息验证码，加密，加密后加上一个报头，后面就是交给tcp层，传输层</p>
<h4 id="HTTPS一定安全吗"><a href="#HTTPS一定安全吗" class="headerlink" title="HTTPS一定安全吗"></a>HTTPS一定安全吗</h4><p>理论上这个协议是安全的，HTTPS其实就是加了个TLS协议，那就是问这个TLS是不是安全的</p>
<p>而TLS就是按四次握手</p>
<p>1、第一种方法：返回的证书，他大概率是伪造的，但是我们如果叫接受了，那就不一样了，你接受了服务器的证书，相当于信任了，那后面的通信就会被监听</p>
<p>2、直接植入根证书也会导致这种情况</p>
<p>所以关键就是对于证书的认证</p>
<h3 id="HTTP1-1-gt-HTTP-2-gt-HTTP3"><a href="#HTTP1-1-gt-HTTP-2-gt-HTTP3" class="headerlink" title="HTTP1.1  -&gt; HTTP 2 -&gt; HTTP3"></a>HTTP1.1  -&gt; HTTP 2 -&gt; HTTP3</h3><p><strong>HTTP1.1在HTTP1.0的基础上增了长连接和管道，解决了发送方的对头阻塞</strong></p>
<p>缺点：header是没有压缩的，只压缩了body部分，接收方会有对头阻塞，服务端智能被动响应</p>
<p><strong>HTTP2在是基于HTTPS的，所以安全性肯定有保障</strong></p>
<p>1、头部压缩</p>
<p>HTTP2会压缩头部，会帮你压缩消除重复的部分，用的是HPACK算法</p>
<p>这就是HPACK算法，HPACK包括三个部分（静态字典、动态字典、huffman编码）</p>
<blockquote>
<p><strong>静态表</strong></p>
<p>表中的参数都是提前定义好的，只有固定的 61个值。如果头部字段在静态表里面，第一个字节是01+静态表的Index，第二个字节代表是否使用Huffman编码+长度。后面就是内容。</p>
<p><strong>动态表</strong></p>
<p>重复的字段会被放到动态表里面，编码什么的和静态表一样</p>
</blockquote>
<p>2、二进制格式</p>
<p>HTTP2不像是HTTP1是纯文本的报文，而是全部改成了二进制，头部和数据题都是二进制，统称帧</p>
<p>3、并发传输，引入了流的机制</p>
<p>一条tcp连接有多个流，每个流可以包含一个或者多个message，这个message就是请求或者响应，message里面有一个或者多个frame帧，不同的HTTP请求有独一无二的帧，所以可以乱序发送，后面会按照streamid组装，<strong>同一 Stream 内部的帧必须是严格有序的</strong></p>
<p>4、服务器主动推送</p>
<p>缺点：</p>
<p>他是基于tcp协议的，tcp是字节流，所以必须保证收到的数据是完整连续的，才会把数据交给应用，如果有一个数据卡住了，那么后面的流都要卡住，那就会触发超时重传，一个tcp连接的HTTP请求都要等待的这个重传成功。</p>
<p><strong>HTTP3，把tcp换成了udp，但是为了可靠，推出了QUIC</strong></p>
<blockquote>
<p>1、没有对头阻塞</p>
<blockquote>
<p>借鉴了HTTP2的流，但是各个流之间是相互独立的，一个流阻塞了，另外的流不会阻塞，这样就保证了没有对头阻塞</p>
</blockquote>
<p>2、更快连接</p>
<blockquote>
<p>因为HTTP2里面tcp和TLS是分层的先三次握手然后四次握手，这样需要3个rtt。然而quic内部携带了TLS，而且TLS1.3只需要一个rtt就可以完成密钥的协商。就是说，第一次发送的时候就已经把签名算法、随机数都发给服务端了，甚至在第二次可以达到0rtt</p>
</blockquote>
<p>3、连接迁移</p>
<blockquote>
<p>tcp是四元组，而quic是基于dcp的，他是考连接id来标记通信，所以ip换了也没事</p>
</blockquote>
<p>4、头部压缩变成了QPACK</p>
<blockquote>
<p>静态表变成91项，动态编码方式换了</p>
</blockquote>
</blockquote>
<h4 id="HTTP1-1请求怎么优化"><a href="#HTTP1-1请求怎么优化" class="headerlink" title="HTTP1.1请求怎么优化"></a>HTTP1.1请求怎么优化</h4><p>一方面是HTTP发送的问题，一方面是他本身数据的问题</p>
<p>1、首先肯定是避免HTTP请求：缓存技术</p>
<p>2、减少重定向，这个就是把重定向请求交给代理服务器</p>
<p>3、合并请求，就是把多个访问小文件的请求合并成一个大的</p>
<p>4、延迟发送，只访问看得到的资源</p>
<p>5、无损压缩，accept- encoding：gzip br </p>
<p>6、有损压缩，webP png</p>
<h4 id="HTTPS怎么优化"><a href="#HTTPS怎么优化" class="headerlink" title="HTTPS怎么优化"></a>HTTPS怎么优化</h4><p>HTTPs对于HTTP多了一个TLS，关键就是通过非对成加密握手得到对成加密的会话密钥</p>
<ul>
<li>提高cpu</li>
<li>升级linux </li>
<li>对密钥交换过程进行优化</li>
<li>RSA要四次握手，慢，安全性不高，我们可以缓存eche密钥交换算法，曲线选择x25519，对成加密算法，也可以换aes128</li>
<li>TLS升级1.3，升级的地方在于hello和公钥交换两个消息合并成一个消息</li>
<li>证书优化，分为传输优化和验证优化。</li>
</ul>
<p>传输：服务器证书选择椭圆曲线</p>
<p>验证：验证的过程中不仅需要ca还需要是否被ca吊销；crl是吊销列表，ca定期更新，但是实时性不好，ocsp，向ca fan song请求，返回状态，这个增加了请求开销，万一网络不好或者ca繁忙就会出现延迟；oscp stapling，服务器向ca定期查证书状态，然后在握手阶段就直接发给客户端，这样客户端就不用再去请求了。</p>
<ul>
<li>会话复用：session id 和session ticket</li>
</ul>
<p>session id：首次连接后，在内存缓存会话密钥，用session id标识，再次连接的时候，会在hello消息中带上这个，服务器收到这个就从缓存里面找，直接回复会话状态，跳过中间流程</p>
<p>缺点是，内存压力大</p>
<p>session ticket：类似于cookie，把缓存的工作交给客户端，首次连接，会加密这个发给客户端缓存起来，第二次连接，客户端会发送ticket，服务器解密后验证日期是否有效，没问题就恢复会话。</p>

                    
                        


                    
                    
                        <p>
                            <a
                                href="/2023/07/08/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C%E5%A4%8D%E4%B9%A01/#post-footer"
                                class="postShorten-excerpt_link link"
                                aria-label=""
                            >
                                Kommentieren und teilen
                            </a>
                        </p>
                    
                </div>
            
        </div>
        
    </article>
    
    
    <article class="postShorten postShorten--thumbnailimg-bottom">
        <div class="postShorten-wrap">
            
            <div class="postShorten-header">
                <h1 class="postShorten-title">
                    
                        <a
                            class="link-unstyled"
                            href="/2023/07/08/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C%E5%A4%8D%E4%B9%A03/"
                            aria-label=": 计算机网络复习3"
                        >
                            计算机网络复习3
                        </a>
                    
                </h1>
                <div class="postShorten-meta">
    <time datetime="2023-07-08T00:00:00+08:00">
	
		    08 Jul 2023
    	
    </time>
    
        <span>in </span>
        
    <a class="category-link" href="/categories/Java/">Java</a>


    
</div>

            </div>
            
                <div class="postShorten-content">
                    <h3 id="这一章节就来学习IP协议"><a href="#这一章节就来学习IP协议" class="headerlink" title="这一章节就来学习IP协议"></a>这一章节就来学习IP协议</h3><p>我们知道两个不相连的网络之间的传输其实靠的是ip地址，两个直连的设备之间的用的协议MAC头，</p>
<p>ipv4是32位</p>
<p>我们把这些分成了5类，包括a类，b类，c类，d类，e类</p>
<p>a类是0开头，b类是10开头，c类是11开头，d类是1110开头，然后e类是1111开头</p>
<p>d类用于多播，多播是可以穿透网段的，e类用于留存</p>
<p>然后每个网络号对应的主机号的数量其实是2的主机号次幂-2，因为，主机号全为0指定某个网络，主机号全为1指代某个网络下的所有主机，用于广播</p>
<p>广播是用于对链路中相互连接的主机发送消息</p>
<p>在本网络中的广播叫做本地广播，不同网络之间的叫直接广播、</p>
<p>这种分类方式的好处就是简单，清晰</p>
<p>但是有缺点：</p>
<p>首先同一层次下，没有分类</p>
<p>第二，不能和现实网络很好的适配</p>
<p>所以提出了无分类地址cidr</p>
<p><img src="/../images/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C%E5%A4%8D%E4%B9%A03/image-20230804145043580.png" alt="image-20230804145043580"></p>
<p>我们知道可以通过子网掩码划分出网络号和主机号，那实际上子网掩码还有一个作用，那就是<strong>划分子网</strong>。</p>
<p><strong>子网划分实际上是将主机地址分为两个部分：子网网络地址和子网主机地址</strong></p>
<p>其实就是在a类b类上再分而已</p>
<p>dhcp</p>
<p>先说明一点，DHCP 客户端进程监听的是 68 端口号，DHCP 服务端进程监听的是 67 端口号。</p>
<p>这 4 个步骤：</p>
<ul>
<li>客户端首先发起 <strong>DHCP 发现报文（DHCP DISCOVER）</strong> 的 IP 数据报，由于客户端没有 IP 地址，也不知道 DHCP 服务器的地址，所以使用的是 UDP <strong>广播</strong>通信，其使用的广播目的地址是 255.255.255.255（端口 67） 并且使用 0.0.0.0（端口 68） 作为源 IP 地址。DHCP 客户端将该 IP 数据报传递给链路层，链路层然后将帧广播到所有的网络中设备。</li>
<li>DHCP 服务器收到 DHCP 发现报文时，用 <strong>DHCP 提供报文（DHCP OFFER）</strong> 向客户端做出响应。该报文仍然使用 IP 广播地址 255.255.255.255，该报文信息携带服务器提供可租约的 IP 地址、子网掩码、默认网关、DNS 服务器以及 <strong>IP 地址租用期</strong>。</li>
<li>客户端收到一个或多个服务器的 DHCP 提供报文后，从中选择一个服务器，并向选中的服务器发送 <strong>DHCP 请求报文（DHCP REQUEST</strong>进行响应，回显配置的参数。</li>
<li>最后，服务端用 <strong>DHCP ACK 报文</strong>对 DHCP 请求报文进行响应，应答所要求的参数。</li>
</ul>
<p>一旦客户端收到 DHCP ACK 后，交互便完成了，并且客户端能够在租用期内使用 DHCP 服务器分配的 IP 地址。</p>

                    
                        


                    
                    
                        <p>
                            <a
                                href="/2023/07/08/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C%E5%A4%8D%E4%B9%A03/#post-footer"
                                class="postShorten-excerpt_link link"
                                aria-label=""
                            >
                                Kommentieren und teilen
                            </a>
                        </p>
                    
                </div>
            
        </div>
        
    </article>
    
    
    <article class="postShorten postShorten--thumbnailimg-bottom">
        <div class="postShorten-wrap">
            
            <div class="postShorten-header">
                <h1 class="postShorten-title">
                    
                        <a
                            class="link-unstyled"
                            href="/2023/07/08/%E8%BE%93%E5%85%A5%E7%BD%91%E7%BB%9C%EF%BC%8C%E6%9C%9F%E9%97%B4%E5%8F%91%E7%94%9F%E4%BA%86%E4%BB%80%E4%B9%88/"
                            aria-label=": 输入网络，期间发生了什么？"
                        >
                            输入网络，期间发生了什么？
                        </a>
                    
                </h1>
                <div class="postShorten-meta">
    <time datetime="2023-07-08T00:00:00+08:00">
	
		    08 Jul 2023
    	
    </time>
    
        <span>in </span>
        
    <a class="category-link" href="/categories/Java/">Java</a>


    
</div>

            </div>
            
                <div class="postShorten-content">
                    <h1 id="输入网络，期间发生了什么，或者说两个设备之间是怎么传输的？"><a href="#输入网络，期间发生了什么，或者说两个设备之间是怎么传输的？" class="headerlink" title="输入网络，期间发生了什么，或者说两个设备之间是怎么传输的？"></a>输入网络，期间发生了什么，或者说两个设备之间是怎么传输的？</h1><h2 id="1、解析url"><a href="#1、解析url" class="headerlink" title="1、解析url"></a>1、解析url</h2><p>首先，就是对我们输入的url进行解析，一般可以得到三个信息：协议，web服务器，文件的路径</p>
<p>拿到这三个信息之后我们就可以包装成一个http请求信息</p>
<p>![image-20230728193306158](&#x2F;Users&#x2F;csen&#x2F;Library&#x2F;Application Support&#x2F;typora-user-images&#x2F;image-20230728193306158.png)</p>
<p>如图所示，一个是请求一个是响应报文</p>
<p>那我们生产出一个消息之后就要开始发送？那应该怎么发？往哪里发？</p>
<p>这就需要下面的知识。</p>
<h2 id="地址查询-——-DNS"><a href="#地址查询-——-DNS" class="headerlink" title="地址查询 —— DNS"></a>地址查询 —— DNS</h2><p>基于我们已经拿到的web服务器域名，我们可以先去浏览器缓存里面找有没有，如果有，就直接返回，如果没有那就问操作系统的缓存再去看hosts文件，如果都没有，那就看走下面</p>
<p>客户端首先会发出一个 DNS 请求，问 <a target="_blank" rel="noopener" href="http://www.xx.com/">www.xx.com</a> 的 IP 是啥，并发给本地 DNS 服务器（也就是客户端的 TCP&#x2F;IP 设置中填写的 DNS 服务器地址）。</p>
<p>本地域名服务器收到客户端的请求后，如果缓存里的表格能找到 <a target="_blank" rel="noopener" href="http://www.xx.com,则它直接返回/">www.xx.com，则它直接返回</a> IP 地址。如果没有，本地 DNS 会去问它的根域名服务器：“老大， 能告诉我 <a target="_blank" rel="noopener" href="http://www.xx.com/">www.xx.com</a> 的 IP 地址吗？” 根域名服务器是最高层次的，它不直接用于域名解析，但能指明一条道路。</p>
<p>根 DNS 收到来自本地 DNS 的请求后，发现后置是 .com，说：“<a target="_blank" rel="noopener" href="http://www.xx.com/">www.xx.com</a> 这个域名归 .com 区域管理”，我给你 .com 顶级域名服务器地址给你，你去问问它吧。”</p>
<p>本地 DNS 收到顶级域名服务器的地址后，发起请求问“老二， 你能告诉我 <a target="_blank" rel="noopener" href="http://www.xx.com/">www.xx.com</a> 的 IP 地址吗？”</p>
<p>顶级域名服务器说：“我给你负责 <a target="_blank" rel="noopener" href="http://www.xx.com/">www.xx.com</a> 区域的权威 DNS 服务器的地址，你去问它应该能问到”。</p>
<p>本地 DNS 于是转向问权威 DNS 服务器：“老三，<a href="http://www.xx.com对应的IP是啥呀？”">www.xx.com对应的IP是啥呀？”</a> server.com 的权威 DNS 服务器，它是域名解析结果的原出处。为啥叫权威呢？就是我的域名我做主。</p>
<p>权威 DNS 服务器查询后将对应的 IP 地址 X.X.X.X 告诉本地 DNS。</p>
<p>本地 DNS 再将 IP 地址返回客户端，客户端和目标建立连接</p>
<p>![image-20230728193808617](&#x2F;Users&#x2F;csen&#x2F;Library&#x2F;Application Support&#x2F;typora-user-images&#x2F;image-20230728193808617.png)</p>
<p>通过dns或者缓存获取到ip地址之后，我们就要为发送做一些准备，首先浏览器通过调用 Socket 库，来委托协议栈工作。</p>
<p>![image-20230728193955912](&#x2F;Users&#x2F;csen&#x2F;Library&#x2F;Application Support&#x2F;typora-user-images&#x2F;image-20230728193955912.png)</p>
<p>说是协议栈，其实就是中间tcp udp ip这些协议。那下面我们就来仔细的看看</p>
<h2 id="TCP"><a href="#TCP" class="headerlink" title="TCP"></a>TCP</h2><p>tcp段的头如下所示：</p>
<p>![image-20230728194108402](&#x2F;Users&#x2F;csen&#x2F;Library&#x2F;Application Support&#x2F;typora-user-images&#x2F;image-20230728194108402.png)</p>
<p>TCP 传输数据之前，要先三次握手建立连接</p>
<p>前提：客户端 为closed状态，服务端变成listen状态</p>
<p>连接：</p>
<p>1、客户端向服务端发送连接syn，之后客户端处于syn-sent状态；</p>
<p>2、服务端接收到这个消息之后，会返回一个syn+ack，之后服务端处于syn-rcvd状态</p>
<p>3、客户端收到这个之后，再给服务端发送一个对syn的ack，之后客户端处于establish状态</p>
<p>服务端收到ack也变成了establish状态</p>
<p>所以三次握手目的是<strong>保证双方都有发送和接收的能力</strong>。</p>
<p>假设我们已经建立了连接，我们要发送消息，但是消息要遵循tcp协议，他的消息大小是有限制的，不是每一次都可以发送全部消息。具体要求如下：</p>
<p>![image-20230728195857751](&#x2F;Users&#x2F;csen&#x2F;Library&#x2F;Application Support&#x2F;typora-user-images&#x2F;image-20230728195857751.png)</p>
<ul>
<li><code>MTU</code>：一个网络包的最大长度，以太网中一般为 <code>1500</code> 字节。</li>
<li><code>MSS</code>：除去 IP 和 TCP 头部之后，一个网络包所能容纳的 TCP 数据的最大长度</li>
</ul>
<p>所以如果http请求消息超过mss，那么就要分段发送。</p>
<p>到这里我们得到了一个tcp的报文段或者说包，下面我们就要把这个包发送给网络层，因为在传输层我们就是服务应用层，然后对好端口，确定好协议，之后的事情就不归传输层管控了。</p>
<p>到这里，我们的数据包的格式如下所示：</p>
<p>![image-20230728200405680](&#x2F;Users&#x2F;csen&#x2F;Library&#x2F;Application Support&#x2F;typora-user-images&#x2F;image-20230728200405680.png)</p>
<h2 id="定位IP"><a href="#定位IP" class="headerlink" title="定位IP"></a>定位IP</h2><p>ip协议的最重要的功能就是寻址和路由，他要做到这两点就需要你遵循ip协议，那么遵循的要求就是你加一个ip头![image-20230728200452235](&#x2F;Users&#x2F;csen&#x2F;Library&#x2F;Application Support&#x2F;typora-user-images&#x2F;image-20230728200452235.png)</p>
<p>加上ip头之后我们就知道了我们的源ip和目的ip地址，那么起点站和终点站就已经知道了</p>
<p>可以现在又有一个小问题，那就是路径怎么规划呢？这时候就需要用到Mac地址</p>
<h2 id="mac地址"><a href="#mac地址" class="headerlink" title="mac地址"></a>mac地址</h2><p>![image-20230728202408619](&#x2F;Users&#x2F;csen&#x2F;Library&#x2F;Application Support&#x2F;typora-user-images&#x2F;image-20230728202408619.png)</p>
<ul>
<li>先查询 ARP 缓存，如果其中已经保存了对方的 MAC 地址，就不需要发送 ARP 查询，直接使用 ARP 缓存中的地址。</li>
<li>而当 ARP 缓存中不存在对方 MAC 地址时，则发送 ARP 广播查询</li>
</ul>
<p>也就是说到了网络接口层，要发了，结果不知道往哪里发，这时候就按照上面两步得到mac地址</p>
<p>因为上面已经得到了ip地址，所以直接喊话：这个 IP 地址是谁的？请把你的 MAC 地址告诉我，就得到mac地址了。</p>
<p>到这里数据包还差最后一层包装</p>
<h2 id="出口–网卡"><a href="#出口–网卡" class="headerlink" title="出口–网卡"></a>出口–网卡</h2><p>![image-20230728204942674](&#x2F;Users&#x2F;csen&#x2F;Library&#x2F;Application Support&#x2F;typora-user-images&#x2F;image-20230728204942674.png)</p>
<p>最后一层包装就是上面图片提到的报头和起始帧分界符和fcs帧校验序列</p>
<p>网卡驱动获取网络包之后，会将其<strong>复制</strong>到网卡内的缓存区中，接着会在其<strong>开头加上报头和起始帧分界符，在末尾加上用于检测错误的帧校验序列</strong>。</p>
<p>到这里数据包就真正的包装结束了，最后网卡会将包转为电信号，通过网线发送出去。！！</p>
<h2 id="送别者—交换机"><a href="#送别者—交换机" class="headerlink" title="送别者—交换机"></a>送别者—交换机</h2><p>交换机的设计是将网络包<strong>原样</strong>转发到目的地。交换机工作在 MAC 层，也称为<strong>二层网络设备</strong>。</p>
<p>一般在网线接口啊这些地方，其实路由器也可以作为交换机。</p>
<h3 id="交换机的包接收操作"><a href="#交换机的包接收操作" class="headerlink" title="交换机的包接收操作"></a>交换机的包接收操作</h3><p>交换机里的模块将电信号转换为数字信号。</p>
<p>然后通过包末尾的fcs校验错误，没问题就放到缓存区，这部分操作基本和计算机的网卡相同，但交换机的工作方式和网卡不同。</p>
<p>计算机的网卡本身具有 MAC 地址，并通过核对收到的包的接收方 MAC 地址判断是不是发给自己的，如果不是发给自己的则丢弃；相对地，交换机的端口不核对接收方 MAC 地址，而是直接接收所有的包并存放到缓冲区中。因此，和网卡不同，<strong>交换机的端口不具有 MAC 地址</strong>。</p>
<h3 id="查询MAC-地址表"><a href="#查询MAC-地址表" class="headerlink" title="查询MAC 地址表"></a>查询<strong>MAC 地址表</strong></h3><p>如果找到，就发送到相应的端口，如果找不到，那说明该mac地址的设备还没有向我们交换机发送过包，那这时候我们主动的向除了源端口的所有端口都发送一遍，因为后面的设备他自己都有检测功能，所以不需要担心</p>
<p>这时候要么就发送到位，要么就可能离开子网了，离开子网需要用到路由器</p>
<h2 id="出境大门–路由器"><a href="#出境大门–路由器" class="headerlink" title="出境大门–路由器"></a>出境大门–路由器</h2><h3 id="路由器的包接收操作"><a href="#路由器的包接收操作" class="headerlink" title="路由器的包接收操作"></a>路由器的包接收操作</h3><p>首先，电信号到达网线接口部分，路由器中的模块会将电信号转成数字信号，然后通过包末尾的 <code>FCS</code> 进行错误校验。</p>
<p>如果没问题则检查 MAC 头部中的<strong>接收方 MAC 地址</strong>，看看是不是发给自己的包，如果是就放到接收缓冲区中，否则就丢弃这个包。</p>
<p>完成包接收操作之后，路由器就会<strong>去掉</strong>包开头的 MAC 头部。</p>
<p><strong>MAC 头部的作用就是将包送达路由器</strong>，其中的接收方 MAC 地址就是路由器端口的 MAC 地址。因此，当包到达路由器之后，MAC 头部的任务就完成了，于是 MAC 头部就会<strong>被丢弃</strong>。</p>
<p>接下来，路由器会根据 MAC 头部后方的 <code>IP</code> 头部中的内容进行包的转发操作。</p>
<h3 id="路由器的发送操作"><a href="#路由器的发送操作" class="headerlink" title="路由器的发送操作"></a>路由器的发送操作</h3><p>首先，我们需要根据<strong>路由表的网关列</strong>判断对方的地址。</p>
<ul>
<li>如果网关是一个 IP 地址，则这个IP 地址就是我们要转发到的目标地址，<strong>还未抵达终点</strong>，还需继续需要路由器转发。</li>
<li>如果网关为空，则 IP 头部中的接收方 IP 地址就是要转发到的目标地址，也是就终于找到 IP 包头里的目标地址了，说明<strong>已抵达终点</strong>。</li>
</ul>
<p>反正我们从路由表知道了ip地址，那么我们同样用这个地址去查mac地址</p>
<p>接下来是发送方 MAC 地址字段，这里填写输出端口的 MAC 地址。还有一个以太类型字段，填写 <code>0800</code> （十六进制）表示 IP 协议。</p>
<p>网络包完成后，接下来会将其转换成电信号并通过端口发送出去。这一步的工作过程和计算机也是相同的。</p>
<p>发送出去的网络包会通过<strong>交换机</strong>到达下一个路由器。由于接收方 MAC 地址就是下一个路由器的地址，所以交换机会根据这一地址将包传输到下一个路由器。</p>
<h1 id="例子"><a href="#例子" class="headerlink" title="例子"></a>例子</h1><p>这边举个例子![image-20230729000740012](&#x2F;Users&#x2F;csen&#x2F;Library&#x2F;Application Support&#x2F;typora-user-images&#x2F;image-20230729000740012.png)</p>
<p>子网1某个设备想要发送数据给子网2的某个设备</p>
<p>首先源ip和目的ip是知道的，如果只是简单的arp群发这个ip问是谁的ip地址，其实是找不到的，所以判断是否为同一子网，如果不是，就把目的mac改成网关的mac，然后数据发送到网关，这时候官网一查mac地址，发现属于子网2的设备，这时候修改源mac为自己的mac，修改目的mac为设备的地址，从子网2的网卡发出。</p>
<p>大多数情况下一个子网的默认网关就是一个，就基本代表着出口。复杂情况就需要某种选择算法了</p>

                    
                        


                    
                    
                        <p>
                            <a
                                href="/2023/07/08/%E8%BE%93%E5%85%A5%E7%BD%91%E7%BB%9C%EF%BC%8C%E6%9C%9F%E9%97%B4%E5%8F%91%E7%94%9F%E4%BA%86%E4%BB%80%E4%B9%88/#post-footer"
                                class="postShorten-excerpt_link link"
                                aria-label=""
                            >
                                Kommentieren und teilen
                            </a>
                        </p>
                    
                </div>
            
        </div>
        
    </article>
    
    
    <article class="postShorten postShorten--thumbnailimg-bottom">
        <div class="postShorten-wrap">
            
            <div class="postShorten-header">
                <h1 class="postShorten-title">
                    
                        <a
                            class="link-unstyled"
                            href="/2023/07/08/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C%E5%A4%8D%E4%B9%A02/"
                            aria-label=": 计算机网络复习2"
                        >
                            计算机网络复习2
                        </a>
                    
                </h1>
                <div class="postShorten-meta">
    <time datetime="2023-07-08T00:00:00+08:00">
	
		    08 Jul 2023
    	
    </time>
    
        <span>in </span>
        
    <a class="category-link" href="/categories/Java/">Java</a>


    
</div>

            </div>
            
                <div class="postShorten-content">
                    <h2 id="TCP"><a href="#TCP" class="headerlink" title="TCP"></a>TCP</h2><h3 id="1、TCP和UDP"><a href="#1、TCP和UDP" class="headerlink" title="1、TCP和UDP"></a>1、<strong>TCP和UDP</strong></h3><p><strong>tcp头的格式</strong></p>
<blockquote>
<p>源端口目的端口</p>
<p>序列号</p>
<p>确认应答号（也是希望你在一个发送的号）</p>
<p>首部长度 保留 六个控制位 窗口大小（用于流量控制那边的）</p>
<p>校验和 紧急指针</p>
<p>选项</p>
<p>数据</p>
<p>一个tcp连接是由四元组确定的</p>
<p>最大的tcp连接数&#x3D;客户端ip*客户端端口 </p>
</blockquote>
<p><strong>UDP只有64位</strong></p>
<blockquote>
<p>区别：</p>
<p>tcp	udp</p>
<p>一个需要连接 不需要连接</p>
<p>点对点 一对多&#x2F;多对多&#x2F;一对一</p>
<p>tcp有拥塞控制流量控制	udp没有无所谓</p>
<p>首部长	首部短</p>
<p>流式传输无边界	包传输有边界</p>
<p>分片msstcp	ucp在ip分片</p>
</blockquote>
<p><strong>UDP和TCP可以共用一个端口，因为是完全独立的两个软件模块</strong></p>
<h3 id="2、为什么不能两次握手或者四次握手？"><a href="#2、为什么不能两次握手或者四次握手？" class="headerlink" title="2、为什么不能两次握手或者四次握手？"></a>2、为什么不能两次握手或者四次握手？</h3><blockquote>
<p>两次握手：在两次握手的时候，服务端没有中间状态给客户端来阻止历史连接，也就是服务端会多建立一个历史连接浪费资源，因为收到syn就变成established。这里靠序列号同步就知道了</p>
<p>四次握手：四次握手无非就是，你给我发我返回同意，我给你发你返回同意，但是第二和第三部完全可以合并，所以三次就ok了。</p>
</blockquote>
<h3 id="3、为什么，每次建立连接序列号都要求不一样？"><a href="#3、为什么，每次建立连接序列号都要求不一样？" class="headerlink" title="3、为什么，每次建立连接序列号都要求不一样？"></a>3、为什么，每次建立连接序列号都要求不一样？</h3><p>1、防止历史报文被下一个连接接受，如果每次都从特定的值开始，那历史报文就可能被下一个连接接受。</p>
<p>2、防止黑客伪造的相同序列号被接受</p>
<h3 id="4、那这个序列号是怎么随机产生的？"><a href="#4、那这个序列号是怎么随机产生的？" class="headerlink" title="4、那这个序列号是怎么随机产生的？"></a>4、那这个序列号是怎么随机产生的？</h3><p>rfc提高了序列号ISN随机生成算法：ISN &#x3D; M + F</p>
<p>m是计时器，四微秒+1</p>
<p>F是哈希算法根据四元组推出来的</p>
<h3 id="5、为什么ip层会分片，TCP还分片，"><a href="#5、为什么ip层会分片，TCP还分片，" class="headerlink" title="5、为什么ip层会分片，TCP还分片，"></a>5、为什么ip层会分片，TCP还分片，</h3><p>因为ip不能超时重传，所以只能靠tcp，而万一ip层丢了一部分，那么ip层就不能组装成一个完整的tcp报文，也就不可能发给接收方tcp层，所以发送方的tcp层就会重发整个tcp报文，所以我们最好就是自己分片，然后缺什么发什么，直接以MSS为单位就可以了</p>
<h3 id="6、TCP三次握手过程丢失问题"><a href="#6、TCP三次握手过程丢失问题" class="headerlink" title="6、TCP三次握手过程丢失问题"></a>6、TCP三次握手过程丢失问题</h3><blockquote>
<p>第一次握手丢失，会发生什么？</p>
<p>触发超时重传，每次重传次数是上一次两倍，报文最大重传次数由 <code>tcp_syn_retries</code></p>
<p>第二次握手丢失，会发生什么？</p>
<p>客户端和服务端都会重传，重传次数分别有tcp_syn_retries和tcp_synack_retries决定</p>
<p>第三次握手丢失了，会发生什么？</p>
<p>这里有一点很关键，就是ack报文是不会重传的，所以服务端会认为自己的syn+ack没发到，触发重传机制，服务端重传，次数由tcp_synack_retries决定</p>
</blockquote>
<h3 id="7、半连接状态和全连接状态"><a href="#7、半连接状态和全连接状态" class="headerlink" title="7、半连接状态和全连接状态"></a>7、半连接状态和全连接状态</h3><ul>
<li>半连接队列，也称 SYN 队列；</li>
<li>全连接队列，也称 accept 队列；</li>
</ul>
<p>正常流程：</p>
<ul>
<li>当服务端接收到客户端的 SYN 报文时，会创建一个半连接的对象，然后将其加入到内核的「 SYN 队列」；</li>
<li>接着发送 SYN + ACK 给客户端，等待客户端回应 ACK 报文；</li>
<li>服务端接收到 ACK 报文后，从「 SYN 队列」取出一个半连接对象，然后创建一个新的连接对象放入到「 Accept 队列」；</li>
<li>应用通过调用 <code>accpet()</code> socket 接口，从「 Accept 队列」取出连接对象。</li>
</ul>
<p>所以这样子就出会先一些问题</p>
<p>受到SYN攻击怎么办？就是说半连接状态很多怎么办？</p>
<ul>
<li>调大 netdev_max_backlog；缓冲队列</li>
<li>增大 TCP 半连接队列；</li>
<li>开启 tcp_syncookies；不用建立半连接</li>
<li>减少 SYN+ACK 重传次数</li>
</ul>
<h3 id="8、TCP四次挥手"><a href="#8、TCP四次挥手" class="headerlink" title="8、TCP四次挥手"></a>8、TCP四次挥手</h3><p><img src="/../images/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C%E5%A4%8D%E4%B9%A02/image-20230803130523828.png" alt="image-20230803130523828"></p>
<p>为什么4次？关键是客户端给服务端发fin报文，说我已经没有数据要发个服务端了，但是这时候服务端可能还有数据要发给客户端，所以需要先处理自己的最后流程，然后给客户端发送一个fin报文，也就是说，第二次握手和第三次握手大概率是不同步的。</p>
<p>特定情况下，可以变成三次，刚刚好没有数据。</p>
<blockquote>
<p>第一次挥手丢失，会发生什么？</p>
<p>客户端收不到来自服务端的ack报文，那么就会触发超时重传，这个次数是由tcp_orphan_retries决定的</p>
<p>第二次挥手丢失，会发生什么？</p>
<p>CK 报文是不会重传的,所以首先客户端还是会触发超时重传，这个次数是由tcp_orphan_retries决定的</p>
<p>第三次丢失，会发生什么？</p>
<p>相当于服务端一直收不到来自客户端的ack，那么服务端会触发超时重传,次数达到后还没收到，断开连接。而客户端已经进入了fin_wait2状态，一直等，如果超过设定的时间tcp_fin_timeout ，断开连接。</p>
<p>第四次丢失，会发生什么？</p>
<p>服务端一直收不到，那么触发超时重传，这时候因为客户端已经是timewait状态，所以每一次重传都会重置2msl定时器，超过时间就close，而服务端同样的重传几次之后close</p>
<p>msl是报文最大生存时间，ip头有一个ttl字段，这个字段代表可以经历的最大路由数</p>
<p>msl大于等于ttl消耗为0的时间，默认60</p>
</blockquote>
<blockquote>
<p><strong>为什么需要这个timewait状态</strong></p>
<p>1、也是为了防止接收历史连接中的第三次挥手这个时间<strong>足以让两个方向上的数据包都被丢弃，使得原来连接的数据包在网络中都自然消失。</strong></p>
<p>2、也就是说，TIME-WAIT 作用是<strong>等待足够的时间以确保最后的 ACK 能让被动关闭方接收，从而帮助其正常关闭。</strong></p>
<p><strong>出现大量超连接的原因</strong></p>
<p>没有用长链接</p>
<p>长连接超时（keepalive）</p>
<p><strong>如果建立了连接，结果客户端故障了，不发送消息，但是服务端一直establish</strong></p>
<p>tcp搞了个保活机制，隔一段时间发送探测报文，没有得到相应则认为tcp死亡，</p>
<p>但是，这个保活机制时间太长了，我们自己在应用层实现一个心跳机制，一般web服务软件都会提供keepalive-timeout状态</p>
<p><strong>如果服务器的进程崩溃了，那发生什么</strong></p>
<p>其实连接信息是由内核维护的，所以服务端的内核还是会发送fin报文进行四次挥手</p>
</blockquote>
<h3 id="9、可靠性保证方法"><a href="#9、可靠性保证方法" class="headerlink" title="9、可靠性保证方法"></a>9、可靠性保证方法</h3><blockquote>
<h3 id="重传机制"><a href="#重传机制" class="headerlink" title="重传机制"></a>重传机制</h3><p>超时重传：超过时间进行重传，时间RTO</p>
<p>快速重传：收到三个相同的 ACK 报文时，会在定时器过期之前，重传丢失的报文段。这里的问题在于传一个还是传所有，这里引入了SACK机制</p>
<p>SACK：服务端把已经收到的数据信息驾到tcp头部的选项里面，告诉发送发我收到了哪些</p>
<p>后面又出现了D-SACK：这是用来告诉发送方哪些被重复接受了了</p>
<h3 id="滑动窗口"><a href="#滑动窗口" class="headerlink" title="滑动窗口"></a>滑动窗口</h3><p>操作系统开辟的一个缓存空间，发送方在收到应答返回之前，在缓冲区中保留已发送的数据。如果按期收到确认应答，此时数据就可以从缓存区清除</p>
<p>TCP头部里面既有一个字段叫窗口大小，就是用来告诉发送端自己还有多少缓冲区可以使用，所以窗口大小一般由接收方决定</p>
<h3 id="流量控制"><a href="#流量控制" class="headerlink" title="流量控制"></a>流量控制</h3><p>避免发送方的数据填满接收方</p>
<h3 id="拥塞控制"><a href="#拥塞控制" class="headerlink" title="拥塞控制"></a>拥塞控制</h3><p>网络发生拥塞，那么tcp就会降低自己的发送量，防止网络负担加重</p>
<p>慢启动 一开始是1，就是可以传1个mss，然后收到应答变成2，4，8，16…..</p>
<p>拥塞避免 触碰到慢启动门限就是用拥塞避免，变成线性的，收到一个ack cwnd增加1&#x2F;cwnd</p>
<p>超时重传，慢启动门限变成cwnd&#x2F;2，cwnd&#x3D;1重新开始慢启动</p>
<p>快速恢复，，cwnd &#x3D; cwnd&#x2F;2，慢启动门限&#x3D; cwnd</p>
<p>cwnd &#x3D; ssthresh + 3</p>
<p>收到重复的数据包 cwnd++</p>
<p>收到新的数据包说明重传成功，cwnd &#x3D; 慢启动门限，进入拥塞避免</p>
<p>如果优化tcp？</p>
<p>从三个方向，三次握手，四次挥手，还有中途的数据传输</p>
</blockquote>
<p><img src="/../images/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C%E5%A4%8D%E4%B9%A02/image-20230803161404210.png" alt="image-20230803161404210"></p>
<p><img src="/../images/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C%E5%A4%8D%E4%B9%A02/image-20230803163142196.png" alt="image-20230803163142196"></p>
<p><img src="/../images/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C%E5%A4%8D%E4%B9%A02/image-20230803163236556.png" alt="image-20230803163236556"></p>
<blockquote>
<h4 id="如何理解字节流"><a href="#如何理解字节流" class="headerlink" title="如何理解字节流"></a>如何理解字节流</h4><p>udp操作系统不会对齐拆分，所以每一个udp就是一个消息的边界.然而tcp是会分片的，这时候，接收方如果不知道消息的长度或者边界，是无法读取消息的，<strong>不能认为一个用户消息对应一个TCP报文，正因为这样，TCP是面向字节流的协议。</strong></p>
<p><strong>没有accept，能建立tcp连接吗</strong></p>
<p>可以</p>
<p><strong>已经建立的tcp，收到syn会发生什么</strong></p>
<p>新的syn首先看看端口是不是一样，如果不一样的话，就建立新的连接，老的那个如果一直不发消息就会触发tcp保活机制</p>
<p>如果相同（可能就是宕机重传），其实会返回一个challenge ack，携带正确的序列号的确认号的ack报文，这时候客户端确认号收到这个，发现不是自己期望收到的，就会返回rst，这样，服务器就释放了连接</p>
<h4 id="如果四次挥手过程中，fin包先比数据包到了主动关闭方，那这个数据还会接受吗"><a href="#如果四次挥手过程中，fin包先比数据包到了主动关闭方，那这个数据还会接受吗" class="headerlink" title="如果四次挥手过程中，fin包先比数据包到了主动关闭方，那这个数据还会接受吗"></a>如果四次挥手过程中，fin包先比数据包到了主动关闭方，那这个数据还会接受吗</h4><p>先到的fin包其实是乱序的，所以会进入乱序队列，等数据真正的到了，才会回头检查这个fin，然后给服务端发这个。</p>
<h4 id="如果timewait状态收到syn？会怎么样？"><a href="#如果timewait状态收到syn？会怎么样？" class="headerlink" title="如果timewait状态收到syn？会怎么样？"></a>如果timewait状态收到syn？会怎么样？</h4><p>还是先看序列号时间戳吧，如果确实合法，那应该会重新进入三次握手阶段，</p>
<p>如果不合法，就会返回一个和第四次挥手一样的ack，这时候服务端收到发现不是自己的，就回复一个rst报文</p>
<h4 id="服务端没有-listen，客户端发起连接建立，会发生什么？"><a href="#服务端没有-listen，客户端发起连接建立，会发生什么？" class="headerlink" title="服务端没有 listen，客户端发起连接建立，会发生什么？"></a>服务端没有 listen，客户端发起连接建立，会发生什么？</h4><p><strong>服务端如果只 bind 了 IP 地址和端口，而没有调用 listen 的话，然后客户端对服务端发起了连接建立，服务端会回 RST 报文</strong></p>
<h4 id="Tcp连接，断电和进程崩溃有什么区别？没有保活机制"><a href="#Tcp连接，断电和进程崩溃有什么区别？没有保活机制" class="headerlink" title="Tcp连接，断电和进程崩溃有什么区别？没有保活机制"></a>Tcp连接，断电和进程崩溃有什么区别？没有保活机制</h4><p>客户端主机崩溃，没有保活机制，那就无法感知到，一直处于establish</p>
<p>进程崩溃，内核还是会发送fin完成4次挥手</p>
<h4 id="客户端主机宕机，又迅速重启"><a href="#客户端主机宕机，又迅速重启" class="headerlink" title="客户端主机宕机，又迅速重启"></a>客户端主机宕机，又迅速重启</h4><p>在客户端主机宕机后，服务端向客户端发送的报文会得不到任何的响应，在一定时长后，服务端就会触发<strong>超时重传</strong>机制，重传未得到响应的报文。</p>
<p>服务端重传报文的过程中，客户端主机重启完成后，客户端的内核就会接收重传的报文，然后根据报文的信息传递给对应的进程：</p>
<ul>
<li>如果客户端主机上<strong>没有</strong>进程绑定该 TCP 报文的目标端口号，那么客户端内核就会<strong>回复 RST 报文，重置该 TCP 连接</strong>；</li>
<li>如果客户端主机上<strong>有</strong>进程绑定该 TCP 报文的目标端口号，由于客户端主机重启后，之前的 TCP 连接的数据结构已经丢失了，客户端内核里协议栈会发现找不到该 TCP 连接的 socket 结构体，于是就会<strong>回复 RST 报文，重置该 TCP 连接</strong>。</li>
</ul>
<p>所以，<strong>只要有一方重启完成后，收到之前 TCP 连接的报文，都会回复 RST 报文，以断开连接</strong></p>
<h4 id="拔掉网线tcp连接还在吗"><a href="#拔掉网线tcp连接还在吗" class="headerlink" title="拔掉网线tcp连接还在吗"></a>拔掉网线tcp连接还在吗</h4><p>在的，tcp连接信息是存储于内核的一个结构体，网线断了，但是结构体不会改变</p>
<ul>
<li>拔掉网线后，有数据传输；</li>
<li>如果在重传前网线插回去了，那我觉得应该什么事情都没发生</li>
<li>如果没插回去，那么就超时重传几次之后，认为此连接死亡，就断开连接，即使后面插回来了，客户端向服务端发送请求，也不是连接的状态，那么服务端就会返回rst</li>
<li>拔掉网线后，没有数据传输</li>
<li>如果开启了保活机制，那就探测几次，如果有工作就重制保活时间，如果客户端没有正常工作，就断开连接</li>
<li>如果没有开启保活机制，就一直连着</li>
</ul>
</blockquote>
<h4 id="HTTPS-中-TLS-和-TCP-能同时握手吗？"><a href="#HTTPS-中-TLS-和-TCP-能同时握手吗？" class="headerlink" title="HTTPS 中 TLS 和 TCP 能同时握手吗？"></a>HTTPS 中 TLS 和 TCP 能同时握手吗？</h4><p>可能，但是有条件</p>
<ul>
<li><strong>客户端和服务端都开启了 TCP Fast Open 功能，且 TLS 版本是 1.3；</strong></li>
<li><strong>客户端和服务端已经完成过一次通信。</strong></li>
</ul>
<p><img src="/../images/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C%E5%A4%8D%E4%B9%A02/image-20230803205908513.png" alt="image-20230803205908513"></p>
<p>TCP Fast Open定义<br>TCP Fast Open（TFO）是用来加速连续TCP连接的数据交互的TCP协议扩展，原理如下：在TCP三次握手的过程中，当用户首次访问Server时，发送SYN包，Server根据用户IP生成Cookie（已加密），并与SYN-ACK一同发回Client；当Client随后重连时，在SYN包携带TCP Cookie；如果Server校验合法，则在用户回复ACK前就可以直接发送数据；否则按照正常三次握手进行<br><img src="/../images/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C%E5%A4%8D%E4%B9%A02/image-20230803210533146.png" alt="image-20230803210533146"></p>
<p>所以就是在第二次以后的通信过程中，tcp open fast在ack发回来之前直接进行tls1.3</p>
<h4 id="quic怎么实现可靠传输"><a href="#quic怎么实现可靠传输" class="headerlink" title="quic怎么实现可靠传输"></a>quic怎么实现可靠传输</h4><p>总的来说，<strong>QUIC 通过单向递增的 Packet Number，配合 Stream ID 与 Offset 字段信息，可以支持乱序确认而不影响数据包的正确组装</strong>，摆脱了TCP 必须按顺序确认应答 ACK 的限制，解决了 TCP 因某个数据包重传而阻塞后续所有待发送数据包的问题。</p>
<p>Packet Number 是严格递增，即使重传报文的 Packet Number 也是递增的，既然重传数据包的 Packet N+M 与丢失数据包的 Packet N 编号并不一致，我们怎么确定这两个数据包的内容一样呢？</p>
<p>所以引入 Frame Header 这一层，<strong>通过 Stream ID + Offset 字段信息实现数据的有序性</strong>，通过比较两个数据包的 Stream ID 与 Stream Offset ，如果都是一致，就说明这两个数据包的内容一致。</p>
<p><img src="/../images/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C%E5%A4%8D%E4%B9%A02/image-20230803212833705.png"></p>
<p><img src="/../images/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C%E5%A4%8D%E4%B9%A02/image-20230803213009597.png" alt="image-20230803213009597"></p>
<h3 id="QUIC怎么解决对头阻塞"><a href="#QUIC怎么解决对头阻塞" class="headerlink" title="QUIC怎么解决对头阻塞"></a>QUIC怎么解决对头阻塞</h3><p><strong>QUIC 给每一个 Stream 都分配了一个独立的滑动窗口，都是相互独立的，各自控制的滑动窗口</strong>。</p>
<h3 id="QUIC-是如何做流量控制的？"><a href="#QUIC-是如何做流量控制的？" class="headerlink" title="QUIC 是如何做流量控制的？"></a>QUIC 是如何做流量控制的？</h3><p>QUIC 实现流量控制的方式：</p>
<ul>
<li>通过 window_update 帧告诉对端自己可以接收的字节数，这样发送方就不会发送超过这个数量的数据。 如果消耗数据的长度大于了最大接收窗口的一半发送</li>
<li>通过 BlockFrame 告诉对端由于流量控制被阻塞了，无法发送数据。</li>
</ul>

                    
                        


                    
                    
                        <p>
                            <a
                                href="/2023/07/08/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C%E5%A4%8D%E4%B9%A02/#post-footer"
                                class="postShorten-excerpt_link link"
                                aria-label=""
                            >
                                Kommentieren und teilen
                            </a>
                        </p>
                    
                </div>
            
        </div>
        
    </article>
    
    
    <article class="postShorten postShorten--thumbnailimg-bottom">
        <div class="postShorten-wrap">
            
            <div class="postShorten-header">
                <h1 class="postShorten-title">
                    
                        <a
                            class="link-unstyled"
                            href="/2023/07/08/Kafka/"
                            aria-label=": Kafka知识"
                        >
                            Kafka知识
                        </a>
                    
                </h1>
                <div class="postShorten-meta">
    <time datetime="2023-07-08T00:00:00+08:00">
	
		    08 Jul 2023
    	
    </time>
    
        <span>in </span>
        
    <a class="category-link" href="/categories/Java/">Java</a>


    
</div>

            </div>
            
                <div class="postShorten-content">
                    <h1 id="1、定义"><a href="#1、定义" class="headerlink" title="1、定义"></a>1、定义</h1><p>分布式的基于发布订阅模式的消息队列</p>
<p>主要应用场景包括：<strong>缓存消峰</strong>、<strong>解耦</strong>和<strong>异步通信。</strong></p>
<p>消息队列有两种模式：</p>
<ul>
<li>点对点模式：一个消费者消费一个主题，数据被消费后会删除</li>
<li>发布订阅模式：多个消费者消费多个主题，数据被消费不会删除</li>
</ul>
<p><strong>基础架构</strong>：</p>
<p><img src="/../images/Kafka/708e86e70504f41234b05cb3cc30dea7.png" alt="image-20220902125656203"></p>
<p>1）Producer：消息生产者，就是向 Kafka broker 发消息的客户端。</p>
<p>（2）Consumer：消息消费者，向 Kafka broker 取消息的客户端。</p>
<p>（3）Consumer Group（CG）：消费者组，由多个 consumer 组成。消费者组内每个消费者负责消费不同分区的数据，一个分区只能由一个组内消费者消费；消费者组之间互不影响。所有的消费者都属于某个消费者组，即消费者组是逻辑上的一个订阅者。</p>
<p>（4）Broker：一台 Kafka 服务器就是一个 broker。一个集群由多个 broker 组成。一个broker 可以容纳多个 topic。</p>
<p>（5）Topic：可以理解为一个队列，生产者和消费者面向的都是一个 topic。</p>
<p>（6）Partition：为了实现扩展性，一个非常大的 topic 可以分布到多个 broker（即服务器）上，一个 topic 可以分为多个 partition，每个 partition 是一个有序的队列。</p>
<p>（7）Replica：副本。一个 topic 的每个分区都有若干个副本，一个 Leader 和若干个Follower。</p>
<p>（8）Leader：每个分区多个副本的“主”，生产者发送数据的对象，以及消费者消费数据的对象都是 Leader。</p>
<p>（9）Follower：每个分区多个副本中的“从”，实时从 Leader 中同步数据，保持和Leader 数据的同步。Leader 发生故障时，某个 Follower 会成为新的 Leader。</p>
<p>其实总的流程就是生产者发送数据到kafka，然后消费者从kafka拉取数据。所以架构中最主要的就是生产者、kafka集群和消费者这三个，其他的很多知识都是为了这三个服务的。</p>
<h1 id="2、生产者"><a href="#2、生产者" class="headerlink" title="2、生产者"></a>2、生产者</h1><p> 在消息发送的过程中，涉及到两个线程，<font color='red'><u><em><strong>main线程和sender线程。</strong></em></u></font></p>
<p>main线程的流程就是<strong>producer</strong>（就是生产者）、然后拦截器（相当于留了一个供我们修改的接口）、<strong>序列化器</strong>（消息发送总要有一种形式，什么json啊）、分区器（我们事先其实是分好了区，但是发送消息的时候发送到那一个区？<strong>分区器</strong>，他有一个默认的分区器DefaultPartitioner，支持三种分区策略 1) 指定分区； 2）指定key，计算hash得分区； 3）指定随机粘性分区；（4）还可以自定义分区器（见代码）（下图））<img src="/../images/Kafka/18a0b6ba56db8e5b16b3d6fac9ba7fb7.png" alt="image-20220902163808502"></p>
<p>但是，并不是来一条消息就发一次，他是把消息加入到一个叫消息累加器里面，然后进行批量发送，一次是16k，32M大小的内存。 我看了下代码，就是 累加器的存储形式为ConcurrentMap&lt;TopicPartition, Deque<ProducerBatch>&gt;，一个分区对应一个双端队列</p>
<p>真正的发送要靠sender线程。发送的时机是：当双端队列中的DQueue满足 batch.size 或者 linger.ms 条件时触发sender线程。 同时Sender线程默认每个分区容纳5个未确认的消息，消息发送失败后会进行重试。</p>
<p><img src="/../images/Kafka/cd41370a872e70b75435f35692925370.png" alt="image-20220902155220662"></p>
<hr>
<p>消息发送就会涉及到可靠性和幂等性的问题。</p>
<p><font color='red'><u><em><strong>可靠性用的是ACK消息确认机制</strong></em></u></font></p>
<blockquote>
<p>producer提供了<strong>三种</strong>消息确认的模式，通过配置acks来实现</p>
<p>acks为0时， 表示生产者将数据发送出去就不管了，不等待任何返回。这种情况下数据传输效率最高，但是数据可靠性最低，当 server挂掉的时候就会丢数据；</p>
<p>acks为1时（默认），表示数据发送到Kafka后，经过leader成功接收消息的的确认，才算发送成功，如果leader宕机了，就会丢失数据。</p>
<p>acks为-1&#x2F;all时，表示生产者需要等待ISR中的所有follower都确认接收到数据后才算发送完成，这样数据不会丢失，因此可靠性最高，性能最低。</p>
</blockquote>
<p><img src="/../images/Kafka/a5c1a40450861d56bfc5cce44746a8a6.png" alt="image-20220902172535966"></p>
<blockquote>
<p>AR &#x3D; ISR + ORS</p>
<p>ISR 表示在指定时间内和leader保存数据同步的集合；</p>
<p>OSR 表示不能在指定的时间内和leader保持数据同步集合，称为OSR(Out-Sync Relipca set)。</p>
</blockquote>
<p><strong>数据完全可靠条件 &#x3D; ACK级别设置为-1 + 分区副本大于等于2 + ISR里应答的最小副本数量大于等于2</strong></p>
<hr>
<p><font color='red'><u><em><strong>到这里可以保证数据可靠性，但是不能保证数据不重复，kafka的解决方法是 保证幂等性  + 事务，kafka</strong></em></u></font></p>
<p><img src="/../images/Kafka/image-20231024141535944.png" alt="image-20231024141535944"></p>
<blockquote>
<p><font color='red'><u><em><strong>保证幂等性怎么保证？</strong></em></u></font></p>
<p>生产者发送消息给broker的时候会携带PID和sequence number，一个是生产者的id，一个是消息的序列号。</p>
<p>broker中会在内存维护一个pid+分区对应的序列号。如果收到的序列号正好比内存序列号大一，才存储消息，如果小于内存序列号，意味着消息重复，那么会丢弃消息，并应答。如果远大于内存序列号，意味着消息丢失，会抛出异常。</p>
<p>了解：</p>
<p>至少一次（At Least Once）： ACK级别设置为-1 + 分区副本大于等于2 + ISR里应答的最小副本数量&gt;&#x3D;2。可以保证数据不丢失，但是不能保证数据不重复。<br>最多一次（At Most Once）：ACK级别设置为0 。可以保证数据不重复，但是不能保证数据不丢失。<br>精确一次（Exactly Once）：至少一次 + 幂等性 。 Kafka 0.11版本引入一项重大特性：幂等性和事务。</p>
</blockquote>
<blockquote>
<p>幂等性只能保证的是在单分区单会话内不重复。如果设计到跨区，为了保证同时发的多条消息，要么全成功，要么全失败。kafka引入了事务</p>
<p>开启事务需要producer设置transactional.id的值并同时开启幂等性。</p>
<h2 id="定位事务协调器"><a href="#定位事务协调器" class="headerlink" title="定位事务协调器"></a>定位事务协调器</h2><p>其本质也是一个后端的broker，只是这个broker起到了针对当前事务的协调作用，它是在transaction_state特殊主题里面根据transcationid%50在一个特殊主题里面选出对应节点。</p>
<p>事务初始化</p>
<p>事务启动，消息发送</p>
<p>事务提交</p>
</blockquote>
<p>通过事务协调器，来实现事务，工作流程如下：</p>
<p><img src="/../images/Kafka/4d210e935a7af0d15c3caa53e08f4e9e.png" alt="image-20220902183826203"></p>
<p>消息顺序</p>
<p>kafka只能保证单分区下的消息顺序性，为了保证消息的顺序性，需要做到如下几点。</p>
<p>如果未开启幂等性，需要 max.in.flight.requests.per.connection 设置为1。（缓冲队列最多放置1个请求）</p>
<p>如果开启幂等性，需要 max.in.flight.requests.per.connection 设置为小于5。</p>
<p>这是因为broker端会缓存producer主题分区下的五个request，保证最近5个request是有序的。</p>
<h1 id="3、Broker"><a href="#3、Broker" class="headerlink" title="3、Broker"></a>3、Broker</h1><h2 id="Broker架构"><a href="#Broker架构" class="headerlink" title="Broker架构"></a>Broker架构</h2><p>一台机器一个broker</p>
<p><img src="/../images/Kafka/image-20231024150746020.png" alt="image-20231024150746020"></p>
<p><strong>Zookeeper</strong>的作用</p>
<p>Zookeeper在Kafka中扮演了重要的角色，kafka使用zookeeper进行<font color='red'><u><em><strong>元数据管理，保存broker注册信息，包括主题（Topic）、分区（Partition）信息等，选择分区leader。</strong></em></u></font></p>
<p><img src="/../images/Kafka/b1f0ebc535b00384be6bf81540c5f416.png" alt="image-20220902200249692"></p>
<h2 id="Broker选举Leader"><a href="#Broker选举Leader" class="headerlink" title="Broker选举Leader"></a>Broker选举Leader</h2><p>Kafka由三个方面会涉及到选举：</p>
<ul>
<li>broker（控制器）选leader</li>
</ul>
<blockquote>
<p>集群中由很多的broker选出一个leader，其他事follower。负责主题创建删除，管理broker，分区重分配，分区leader选举等等</p>
<p>方法简单粗暴：</p>
<p>每个broker都有唯一的brokerId，启动后会去竞争注册zookeeper上的Controller结点，谁先抢到，谁就是broker leader。一般第一个broker都是controller。而其他broker会监听该结点事件，以便后续leader下线后触发重新选举。</p>
<p><img src="/../images/Kafka/12b4f076e8f82c66b00ec8782433649f.png" alt="image-20220902200901222"></p>
</blockquote>
<ul>
<li>分区多副本选leader<ul>
<li>有controller节点空值，决策是：排在ar列表前面的优先，同时必须在isr里面。</li>
</ul>
</li>
</ul>
<blockquote>
<p><img src="/../images/Kafka/e5c14b9c17123faf3eefa58a22ab0668-20230928225949575.png" alt="image-20220902201352868"></p>
</blockquote>
<ul>
<li>消费者选Leader</li>
</ul>
<p> 在kafka，但是他们之间需要选举出一个leader，其他的都是follower。broker的leader有很重要的作用，诸如：创建、删除主题、增加分区并分配leader分区；集群broker管理，包括新增、关闭和故障处理；分区重分配（auto.leader.rebalance.enable&#x3D;true，后面会介绍），分区leader选举。</p>
<h2 id="副本故障处理"><a href="#副本故障处理" class="headerlink" title="副本故障处理"></a>副本故障处理</h2><h3 id="1-follower故障流程"><a href="#1-follower故障流程" class="headerlink" title="1.follower故障流程"></a><strong>1.follower故障流程</strong></h3><p><img src="/../images/Kafka/b01dad78f006b40d82e719fe71caeb78.png" alt="image-20220902210759125"></p>
<h3 id="2-leader故障流程"><a href="#2-leader故障流程" class="headerlink" title="2.leader故障流程"></a>2.leader故障流程</h3><p><img src="/../images/Kafka/1f96e55810be5ff8cbf64c04b5d37315.png" alt="image-20220902210830344"></p>
<h2 id="kafka分区策略"><a href="#kafka分区策略" class="headerlink" title="kafka分区策略"></a>kafka分区策略</h2><p>如果 kafka 服务器只有 4 个节点，那么设置 kafka 的分区数大于服务器台数，在 kafka底层如何分配存储副本呢？</p>
<ul>
<li>这里如果用默认的就是如下</li>
</ul>
<p><img src="/../images/Kafka/15514da0f22aca9e3017fa2305733ba4.png" alt="image-20220902211334365"></p>
<ul>
<li>也可以手动指定</li>
</ul>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">$ vim increase-replication-factor.json</span><br><span class="line">输入如下内容：</span><br><span class="line">&#123;</span><br><span class="line">&quot;version&quot;:1,</span><br><span class="line">&quot;partitions&quot;:[</span><br><span class="line">&#123;&quot;topic&quot;:&quot;three&quot;,&quot;partition&quot;:0,&quot;replicas&quot;:[0,1]&#125;,</span><br><span class="line">&#123;&quot;topic&quot;:&quot;three&quot;,&quot;partition&quot;:1,&quot;replicas&quot;:[0,1]&#125;,</span><br><span class="line">&#123;&quot;topic&quot;:&quot;three&quot;,&quot;partition&quot;:2,&quot;replicas&quot;:[1,0]&#125;,</span><br><span class="line">&#123;&quot;topic&quot;:&quot;three&quot;,&quot;partition&quot;:3,&quot;replicas&quot;:[1,0]&#125;]</span><br><span class="line">&#125;</span><br><span class="line"></span><br></pre></td></tr></table></figure>

<h3 id="1、分区自动调整"><a href="#1、分区自动调整" class="headerlink" title="1、分区自动调整"></a><strong>1、分区自动调整</strong></h3><p>随着一些broker故障，会慢慢出现leader集中在某台broker上的情况，造成集群负载不均衡，这时候就需要分区平衡。</p>
<p><img src="/../images/Kafka/watermark,type_d3F5LXplbmhlaQ,shadow_50,text_Q1NETiBA6Zi_5piM5Zac5qyi5ZCD6buE5qGD,size_20,color_FFFFFF,t_70,g_se,x_16.png" alt="在这里插入图片描述"></p>
<h2 id="文件存储和清理"><a href="#文件存储和清理" class="headerlink" title="文件存储和清理"></a>文件存储和清理</h2><p>一个partition对应多个segment，一个segment里面有log index timeindex。producer的数据会追加到log里面，每次往log里面写4k数据，就会到index文件写一条索引。</p>
<p><img src="/../images/Kafka/watermark,type_d3F5LXplbmhlaQ,shadow_50,text_Q1NETiBA6Zi_5piM5Zac5qyi5ZCD6buE5qGD,size_20,color_FFFFFF,t_70,g_se,x_16-20230928232748011.png" alt="在这里插入图片描述"></p>
<h3 id="1、存储"><a href="#1、存储" class="headerlink" title="1、存储"></a>1、存储</h3><p><img src="/../images/Kafka/watermark,type_d3F5LXplbmhlaQ,shadow_50,text_Q1NETiBA6Zi_5piM5Zac5qyi5ZCD6buE5qGD,size_20,color_FFFFFF,t_70,g_se,x_16-20230928233003817.png" alt="在这里插入图片描述"></p>
<h3 id="2、清理"><a href="#2、清理" class="headerlink" title="2、清理"></a>2、清理</h3><p>Kafka将消息存储在磁盘中，为了控制磁盘占用空间的不断增加就需要对消息做一定的清理操作。Kafka 中每一个分区副本都对应一个Log，而Log又可以分为多个日志分段，这样也便于日志的清理操作。Kafka提供了两种日志清理策略。</p>
<p>日志删除(delete) :按照一定的保留策略直接删除不符合条件的日志分段。默认七天<br>日志压缩(compact) :针对每个消息的key进行整合，对于有相同key的不同value值，只保留最后一个版本。</p>
<p><img src="/../images/Kafka/watermark,type_d3F5LXplbmhlaQ,shadow_50,text_Q1NETiBA6Zi_5piM5Zac5qyi5ZCD6buE5qGD,size_20,color_FFFFFF,t_70,g_se,x_16-20230928233204011.png" alt="在这里插入图片描述"></p>
<p><img src="/../images/Kafka/watermark,type_d3F5LXplbmhlaQ,shadow_50,text_Q1NETiBA6Zi_5piM5Zac5qyi5ZCD6buE5qGD,size_20,color_FFFFFF,t_70,g_se,x_16-20230928233315113.png" alt="在这里插入图片描述"></p>
<h2 id="Kafka高效读写数据"><a href="#Kafka高效读写数据" class="headerlink" title="Kafka高效读写数据"></a><strong>Kafka高效读写数据</strong></h2><p>kafka之所以可以快速读写的原因如下：</p>
<p>读的话：<font color='red'><u><em><strong>1）分区可以并行操作。2）稀疏索引快速定位。3）零拷贝</strong></em></u></font></p>
<p>写的话：首先kafka是顺序写，这个本身比较快，但是即使这样，速度也追不上内存。所以他引入了 MMF（Memory Mapped File）。</p>
<h4 id="Memory-Mapped-Files"><a href="#Memory-Mapped-Files" class="headerlink" title="Memory Mapped Files"></a><strong>Memory Mapped Files</strong></h4><p>内存映射文件MMF它的工作原理是直接利用操作系统的 Page 来实现文件到物理内存的直接映射。</p>
<h4 id="零拷贝："><a href="#零拷贝：" class="headerlink" title="零拷贝："></a>零拷贝：</h4><p>传统的io，先读取、再发送，实际经过 1~4 四次 copy。</p>
<p>分别是：</p>
<ol>
<li>第一次：将磁盘文件，读取到操作系统内核缓冲区；</li>
<li>第二次：将内核缓冲区的数据，copy 到 application 应用程序的 buffer；</li>
<li>第三步：将 application 应用程序 buffer 中的数据，copy 到 socket 网络发送缓冲区(属于操作系统内核的缓冲区)；</li>
<li>第四次：将 socket buffer 的数据，copy 到网卡，由网卡进行网络传输。</li>
</ol>
<p>但是broker不关心数据，也不对这个数据做什么操作。</p>
<ul>
<li>Sendfile 系统调用，文件数据被 Copy 至内核缓冲区。</li>
<li>再从内核缓冲区 Copy 至内核中 Socket 相关的缓冲区。</li>
<li>最后走网卡</li>
</ul>
<p><img src="/../images/Kafka/eeb8531c34ed091d57d9be10590839c5.png" alt="image-20220902214803709"></p>
<p><img src="/../images/Kafka/watermark,type_d3F5LXplbmhlaQ,shadow_50,text_Q1NETiBA6Zi_5piM5Zac5qyi5ZCD6buE5qGD,size_20,color_FFFFFF,t_70,g_se,x_16-20230928233417216.png" alt="在这里插入图片描述"></p>
<h1 id="4、kafka消费者"><a href="#4、kafka消费者" class="headerlink" title="4、kafka消费者"></a>4、kafka消费者</h1><h2 id="1、Kafka-消费方式"><a href="#1、Kafka-消费方式" class="headerlink" title="1、Kafka 消费方式"></a>1、Kafka 消费方式</h2><p>​	<img src="/../images/Kafka/watermark,type_d3F5LXplbmhlaQ,shadow_50,text_Q1NETiBA6Zi_5piM5Zac5qyi5ZCD6buE5qGD,size_20,color_FFFFFF,t_70,g_se,x_16-20230928234825729.png" alt="在这里插入图片描述"></p>
<h2 id="2、消费者工作流程"><a href="#2、消费者工作流程" class="headerlink" title="2、消费者工作流程"></a>2、消费者工作流程</h2><h5 id="①消费者总体工作流程"><a href="#①消费者总体工作流程" class="headerlink" title="①消费者总体工作流程"></a>①消费者总体工作流程</h5><p><img src="/../images/Kafka/watermark,type_d3F5LXplbmhlaQ,shadow_50,text_Q1NETiBA6Zi_5piM5Zac5qyi5ZCD6buE5qGD,size_20,color_FFFFFF,t_70,g_se,x_16-20230928234848009.png" alt="在这里插入图片描述"></p>
<h5 id="②消费者组原理"><a href="#②消费者组原理" class="headerlink" title="②消费者组原理"></a>②消费者组原理</h5><p> <img src="/../images/Kafka/watermark,type_d3F5LXplbmhlaQ,shadow_50,text_Q1NETiBA6Zi_5piM5Zac5qyi5ZCD6buE5qGD,size_20,color_FFFFFF,t_70,g_se,x_16-20230928235013969.png" alt="在这里插入图片描述"></p>
<p><img src="/../images/Kafka/watermark,type_d3F5LXplbmhlaQ,shadow_50,text_Q1NETiBA6Zi_5piM5Zac5qyi5ZCD6buE5qGD,size_20,color_FFFFFF,t_70,g_se,x_16-20230928235020544.png" alt="在这里插入图片描述"></p>
<p><strong>消费者组初始化流程</strong></p>
<p><a target="_blank" rel="noopener" href="https://baijiahao.baidu.com/s?id=1767477534734641183&amp;wfr=spider&amp;for=pc">https://baijiahao.baidu.com/s?id=1767477534734641183&amp;wfr=spider&amp;for=pc</a></p>
<p>多个消费者像协调器发送JoinGroup请求，然后协调器选一个消费者leader，消费者leader指定消费方案，并发送给协调器，协调器把这个方案通知到每一个消费者。</p>
<p><img src="/../images/Kafka/watermark,type_d3F5LXplbmhlaQ,shadow_50,text_Q1NETiBA6Zi_5piM5Zac5qyi5ZCD6buE5qGD,size_20,color_FFFFFF,t_70,g_se,x_16-20230928235058845.png" alt="在这里插入图片描述"></p>
<p><strong>消费者组详细消费流程</strong></p>
<p><img src="/../images/Kafka/watermark,type_d3F5LXplbmhlaQ,shadow_50,text_Q1NETiBA6Zi_5piM5Zac5qyi5ZCD6buE5qGD,size_20,color_FFFFFF,t_70,g_se,x_16-20230928235306060.png" alt="在这里插入图片描述"></p>
<h2 id="3、消费者api"><a href="#3、消费者api" class="headerlink" title="3、消费者api"></a>3、消费者api</h2><h2 id="4、生产经验-——-分区的分配"><a href="#4、生产经验-——-分区的分配" class="headerlink" title="4、生产经验 —— 分区的分配"></a>4、生产经验 —— 分区的分配</h2><p><img src="/../images/Kafka/watermark,type_d3F5LXplbmhlaQ,shadow_50,text_Q1NETiBA6Zi_5piM5Zac5qyi5ZCD6buE5qGD,size_20,color_FFFFFF,t_70,g_se,x_16-20230928235523539.png" alt="在这里插入图片描述"></p>
<p><img src="/../images/Kafka/watermark,type_d3F5LXplbmhlaQ,shadow_50,text_Q1NETiBA6Zi_5piM5Zac5qyi5ZCD6buE5qGD,size_20,color_FFFFFF,t_70,g_se,x_16-20230928235554746.png" alt="在这里插入图片描述"></p>
<p><strong>Range 分区分配策略案例</strong></p>
<p> <img src="/../images/Kafka/watermark,type_d3F5LXplbmhlaQ,shadow_50,text_Q1NETiBA6Zi_5piM5Zac5qyi5ZCD6buE5qGD,size_20,color_FFFFFF,t_70,g_se,x_16-20230928235731478.png" alt="在这里插入图片描述"></p>
<p><img src="/../images/Kafka/29f6564651824fe69bba934f8e5e83b6.png" alt="在这里插入图片描述"></p>
<h5 id="Range-分区分配再平衡案例"><a href="#Range-分区分配再平衡案例" class="headerlink" title="Range 分区分配再平衡案例"></a><strong>Range 分区分配再平衡案例</strong></h5><p><img src="/../images/Kafka/watermark,type_d3F5LXplbmhlaQ,shadow_50,text_Q1NETiBA6Zi_5piM5Zac5qyi5ZCD6buE5qGD,size_20,color_FFFFFF,t_70,g_se,x_16-20230928235744058.png" alt="在这里插入图片描述"></p>
<h5 id="RoundRobin-以及再平衡原理"><a href="#RoundRobin-以及再平衡原理" class="headerlink" title="RoundRobin 以及再平衡原理"></a>RoundRobin 以及再平衡原理</h5><h5 id=""><a href="#" class="headerlink" title=""></a></h5><p><img src="/../images/Kafka/watermark,type_d3F5LXplbmhlaQ,shadow_50,text_Q1NETiBA6Zi_5piM5Zac5qyi5ZCD6buE5qGD,size_20,color_FFFFFF,t_70,g_se,x_16-20230929000334551.png" alt="在这里插入图片描述"></p>
<p><img src="/../images/Kafka/watermark,type_d3F5LXplbmhlaQ,shadow_50,text_Q1NETiBA6Zi_5piM5Zac5qyi5ZCD6buE5qGD,size_20,color_FFFFFF,t_70,g_se,x_16-20230929000415710.png" alt="在这里插入图片描述"></p>
<h5 id="Sticky-以及再平衡"><a href="#Sticky-以及再平衡" class="headerlink" title="Sticky 以及再平衡"></a>Sticky 以及再平衡</h5><p><img src="/../images/Kafka/watermark,type_d3F5LXplbmhlaQ,shadow_50,text_Q1NETiBA6Zi_5piM5Zac5qyi5ZCD6buE5qGD,size_20,color_FFFFFF,t_70,g_se,x_16-20230929000640458.png" alt="在这里插入图片描述"></p>
<p><img src="/../images/Kafka/watermark,type_d3F5LXplbmhlaQ,shadow_50,text_Q1NETiBA6Zi_5piM5Zac5qyi5ZCD6buE5qGD,size_20,color_FFFFFF,t_70,g_se,x_16-20230929000653360.png" alt="在这里插入图片描述"></p>
<p><img src="/../images/Kafka/watermark,type_d3F5LXplbmhlaQ,shadow_50,text_Q1NETiBA6Zi_5piM5Zac5qyi5ZCD6buE5qGD,size_20,color_FFFFFF,t_70,g_se,x_16-20230929000715131.png" alt="在这里插入图片描述"></p>
<p><img src="/../images/Kafka/watermark,type_d3F5LXplbmhlaQ,shadow_50,text_Q1NETiBA6Zi_5piM5Zac5qyi5ZCD6buE5qGD,size_20,color_FFFFFF,t_70,g_se,x_16-20230929000728390.png" alt="在这里插入图片描述"></p>
<h2 id="5、offset-位移"><a href="#5、offset-位移" class="headerlink" title="5、offset 位移"></a>5、offset 位移</h2><h5 id="1、offset-的默认维护"><a href="#1、offset-的默认维护" class="headerlink" title="1、offset 的默认维护"></a>1、offset 的默认维护</h5><p><img src="/../images/Kafka/watermark,type_d3F5LXplbmhlaQ,shadow_50,text_Q1NETiBA6Zi_5piM5Zac5qyi5ZCD6buE5qGD,size_20,color_FFFFFF,t_70,g_se,x_16-20230929000851750.png" alt="在这里插入图片描述"></p>
<p>__consumer_offsets 主题里面采用 key 和 value 的方式存储数据。</p>
<p>key 是group.id+topic+分区号，value 就是当前 offset 的值。</p>
<p>offset是消费者提交的，分为自动提交和手动提交。</p>
<p>自动提交会出现重复消费的问题。默认5s提交一次</p>
<p>手动提交会出现漏消费的问题，因为消费完数据后，如果来不及调用哪个sync函数，消费者宕机，就会丢失数据。</p>
<p><img src="/../images/Kafka/watermark,type_d3F5LXplbmhlaQ,shadow_50,text_Q1NETiBA6Zi_5piM5Zac5qyi5ZCD6buE5qGD,size_20,color_FFFFFF,t_70,g_se,x_16-20230929001250173.png" alt="在这里插入图片描述"></p>
<h5 id="③手动交-提交-offset"><a href="#③手动交-提交-offset" class="headerlink" title="③手动交 提交 offset"></a>③手动交 提交 offset</h5><p><img src="/../images/Kafka/watermark,type_d3F5LXplbmhlaQ,shadow_50,text_Q1NETiBA6Zi_5piM5Zac5qyi5ZCD6buE5qGD,size_20,color_FFFFFF,t_70,g_se,x_16-20230929001022624.png" alt="在这里插入图片描述"></p>
<p><img src="/../images/Kafka/watermark,type_d3F5LXplbmhlaQ,shadow_50,text_Q1NETiBA6Zi_5piM5Zac5qyi5ZCD6buE5qGD,size_20,color_FFFFFF,t_70,g_se,x_16-20230929001509066.png" alt="在这里插入图片描述"></p>
<h4 id="数据积压-（-消费者-如何提高吞吐量）"><a href="#数据积压-（-消费者-如何提高吞吐量）" class="headerlink" title="数据积压 （ 消费者 如何提高吞吐量）"></a>数据积压 （ 消费者 如何提高吞吐量）</h4><p>1、增加分区数和消费者数量</p>
<p>2、提高消费者每次拉取的数量</p>
<p><img src="/../images/Kafka/watermark,type_d3F5LXplbmhlaQ,shadow_50,text_Q1NETiBA6Zi_5piM5Zac5qyi5ZCD6buE5qGD,size_20,color_FFFFFF,t_70,g_se,x_16-20230929001531640.png" alt="在这里插入图片描述"></p>

                    
                        


                    
                    
                        <p>
                            <a
                                href="/2023/07/08/Kafka/#post-footer"
                                class="postShorten-excerpt_link link"
                                aria-label=""
                            >
                                Kommentieren und teilen
                            </a>
                        </p>
                    
                </div>
            
        </div>
        
    </article>
    
    
    <article class="postShorten postShorten--thumbnailimg-bottom">
        <div class="postShorten-wrap">
            
            <div class="postShorten-header">
                <h1 class="postShorten-title">
                    
                        <a
                            class="link-unstyled"
                            href="/2023/07/08/MySQL%E5%A4%8D%E4%B9%A0%EF%BC%88mysql%E6%8A%80%E6%9C%AF%E5%86%85%E5%B9%95%20innodb%E5%AD%98%E5%82%A8%E5%BC%95%E6%93%8E%EF%BC%89/"
                            aria-label=": Mysql复习（mysql技术内幕 innodb存储引擎）"
                        >
                            Mysql复习（mysql技术内幕 innodb存储引擎）
                        </a>
                    
                </h1>
                <div class="postShorten-meta">
    <time datetime="2023-07-08T00:00:00+08:00">
	
		    08 Jul 2023
    	
    </time>
    
        <span>in </span>
        
    <a class="category-link" href="/categories/Java/">Java</a>


    
</div>

            </div>
            
                <div class="postShorten-content">
                    <p>InnoDB最重要的点：行锁设计、MVCC、外键</p>
<p>首先来了解一下InnoDB的体系架构：</p>
<h1 id="体系架构"><a href="#体系架构" class="headerlink" title="体系架构"></a>体系架构</h1><p>![image-20231004235405057](..&#x2F;images&#x2F;Mysql复习（mysql技术内幕 innodb存储引擎）&#x2F;image-20231004235405057.png)</p>
<p>InnoDB有很多内存块，组成内存池，负责的工作：</p>
<blockquote>
<p>维护所有线程</p>
<p>缓存磁盘的数据</p>
<p>重做日志缓冲</p>
</blockquote>
<p>后台线程的主要作用就是：刷新内存池中的数据，保证缓冲池里的是最新的数据。把已修改的数据文件刷新到磁盘文件，</p>
<p>我们看体系架构，可以从以下几点：</p>
<h2 id="1、后台线程"><a href="#1、后台线程" class="headerlink" title="1、后台线程"></a>1、后台线程</h2><blockquote>
<p>主要有：</p>
<p><font color='red'><u><em><strong>master thread</strong></em></u></font>：最重要的，脏页刷新、合并insert buffer，undo 页的回收，redolog。不过后来脏页回收放到了单独的线程，也就是page thread</p>
<p>IO thread</p>
<p>purge thread</p>
<p>page thread</p>
</blockquote>
<h3 id="1、master-thread"><a href="#1、master-thread" class="headerlink" title="1、master thread"></a>1、master thread</h3><p>本质是一个循环</p>
<p>每秒都会进行一次操作：重做日志缓冲刷新、合并insertbuffer，脏页刷新被放到了page clean 线程</p>
<p>每十秒会进行的操作：重做日志缓冲刷新、合并insertbuffer、脏页刷新被放到了page clean 线程、删除无用的undo 页</p>
<h2 id="2、内存"><a href="#2、内存" class="headerlink" title="2、内存"></a>2、内存</h2><p>内存方面就是缓冲池、lrulist freelist flushlist、redo log buffer 三块，还有一些额外内存池（为了数据结构的内存申请服务）</p>
<h3 id="1、缓冲池"><a href="#1、缓冲池" class="headerlink" title="1、缓冲池"></a>1、缓冲池</h3><p><font color='red'><u><em><strong>本质就是一块内存，缓冲池里面有数据页、索引页、undo 页、insert buffer、自适应哈希索引、锁信息、数据字典。</strong></em></u></font></p>
<p>所以修改操作，基本都现修改缓冲池里面的数据，然后按照一定刷回机制磁盘。</p>
<h3 id="2、List"><a href="#2、List" class="headerlink" title="2、List"></a>2、List</h3><p>缓冲池是通过改进的LRU算法（在原本的基础上加了midpoint，新加入的页放到这里，默认<font color='red'><u><em><strong>5&#x2F;8</strong></em></u></font>）进行管理的，方法就是LRUlist、freelist flushlist。如果缓冲池不能放新的，就把lru里面末尾的释放掉。</p>
<p>改进lru的原因：有可能新页仅仅是这次查询需要用到，并不是真正的热点数据，这样反而有可能将真正的热点数据淘汰。</p>
<p>flushlist就是脏页列表，就像上面说的，用checkpoint机制刷新</p>
<p>一页16k</p>
<p>说了这么多checkpoint，什么是checkpoint？（当前要刷回的位置）</p>
<h4 id="1、checkpoint"><a href="#1、checkpoint" class="headerlink" title="1、checkpoint"></a>1、checkpoint</h4><p>解决问题：</p>
<ul>
<li>缩短数据库恢复时间？</li>
</ul>
<p>即使发生宕机， 因为checkpoint之前多页已经刷新回磁盘，所以只需要对checkpoint之后对进行恢复</p>
<ul>
<li>缓冲池不够时，可以将脏页刷回磁盘？</li>
</ul>
<p>缓冲池不够用的时候，根据lru找lru末尾的页，如果是脏页，就强制执行checkpoint，讲脏页刷新回磁盘</p>
<ul>
<li>重做日志不可用，刷新脏页。</li>
</ul>
<p>重做日志两个文件是循环使用，为了不让他一直无限变大，不可用是指重做日志已经不被需要了可以被覆盖。如果宕机，数据库恢复操作不需要这部分的重做日志就可以覆盖重用。如果此时重做日志还需要用，就必须强制产生checkpoint将讲缓冲池的页至少刷新到当前重做日志的位置</p>
<p>所以总归checkpoint做的事情就是把脏页刷回磁盘。<font color='red'><u><em><strong>（脏页刷时机）？</strong></em></u></font></p>
<blockquote>
<p><font color='red'><u><strong>1. redo log 写满。会造成mysql不接受更新。</strong></u></font><br><font color='red'><u><strong>2. 内存不足。</strong></u></font><br><font color='red'><u><em><strong>3. 空闲时间，认为目前压力不大。（主流）</strong></em></u></font><br><font color='red'><u><em><strong>4. Mysql关闭时。</strong></em></u></font></p>
<p><font color='red'><u><em><strong>5、脏页数量太多</strong></em></u></font></p>
<p>一个是脏页比例，一个是 redo log 写盘速度去计算刷盘的速度。</p>
</blockquote>
<p>这里有两种checkpoint，分别是：</p>
<blockquote>
<p>sharp checkpoint</p>
<p>fuzzy checkpoint</p>
<p>sharp checkpoint就是在<font color='red'><u><em><strong>数据库关闭的时候全部刷新到磁盘</strong></em></u></font></p>
<p>fuzzy checkpoint是刷新部分脏页？刷新到时机如下：</p>
<p>master thread checkpoint（空闲）</p>
<p>flushlrulist checkpoint：这饿是lru列表需要有100个空闲的页，否则移除lru末尾的页，如果有脏页就checkpoint（内存不足）</p>
<p>async sycn flush checkpoint：这个是<font color='red'><u>***重做日志文件不可用的情况，需要强制将一些刷新回磁盘  ***</u></font>（redo）</p>
<p>dirty page too much：这个是脏页数量太多了，强制checkpoint ，脏页的比例达到75%</p>
</blockquote>
<h3 id="3、Redo-log-buffer"><a href="#3、Redo-log-buffer" class="headerlink" title="3、Redo log buffer"></a>3、Redo log buffer</h3><p>这个是innodb独有的，重做日志信息 -&gt;Redo log buffer -〉 重做日志文件，为重做日志文件服务，重做日志文件本身是为了数据库的恢复功能，但是同样的，为了缓解和磁盘的差距，我们给他加一个buffer。</p>
<p>刷回时机：</p>
<blockquote>
<p><font color='red'><u><em><strong>master thread 每秒</strong></em></u></font></p>
<p><font color='red'><u><em><strong>每个事务提交的时候，有个参数，1代表完全同步，0代表不写磁盘，2表示写到page cache里面，具体刷回靠操作系统</strong></em></u></font></p>
<p><font color='red'><u><em><strong>重做日志缓冲 剩余空间小于1&#x2F;2</strong></em></u></font></p>
<p><font color='red'><u><em><strong>正常关闭</strong></em></u></font></p>
</blockquote>
<h1 id="关键特性"><a href="#关键特性" class="headerlink" title="关键特性"></a>关键特性</h1><p>前三个最重要：</p>
<blockquote>
<p>1、插入缓冲</p>
<p>2、两次写</p>
<p>3、自适应哈希</p>
<p>4、异步io</p>
<p>5、刷新邻接页</p>
</blockquote>
<h2 id="1、插入缓冲"><a href="#1、插入缓冲" class="headerlink" title="1、插入缓冲"></a>1、插入缓冲</h2><h3 id="1、insert-buffer"><a href="#1、insert-buffer" class="headerlink" title="1、insert buffer"></a>1、insert buffer</h3><blockquote>
<p>数据插入的时候还是按照主键的位置存放的，但是这个表如果有辅助索引，那么这条记录也会插入辅助索引，但是这时候他就不是顺序插入了，而是离散的插入访问。我们在对非聚集索引的插入的时候不会实时的插入，而是先判断有没有在缓冲池里面，有的话直接插入，没有的话，先放到一个insert buffer里面。后面再以一定的频率进行insertbuffer和非聚集索页子节点的merge操作。</p>
<p><strong>changebuffer的存在让普通索引优于唯一索引。</strong>普通索引和唯一索引的查询效率差不多，对于已经在内存的数据更新也差不多。但是对于没有在内存的数据更新操作差很多，因为唯一索引为了保证唯一性，会把数据从磁盘读到内存，这一步是数据库成本最高的操作之一。</p>
<p>insert buffer 升级为了 change buffer，对插入更新删除操作都准备了缓冲</p>
<h3 id="2、insert-buffer的内部实现"><a href="#2、insert-buffer的内部实现" class="headerlink" title="2、insert buffer的内部实现"></a>2、insert buffer的内部实现</h3><p>全局唯一的b+树的形式，负责对<font color='red'><u><em><strong>所有表</strong></em></u></font>的辅助索引进行insert buffer，存放在共享表空间，就是ibdata1。但是我们知道，我们可以有独立表ibdata，但是恢复的时候最好用共享表里面的。</p>
<p>因为是树，所以有非叶子结点和叶子结点。</p>
<p>非叶子结点放的是searchkey，所以插入非聚集索引的时候，如果不在缓冲池，那么要加入这颗唯一的insertbuffer，实现构造一个searchkey，我想通过这个searchkey找到我要插入的位置，然后再构造一个叶子结点，放进去。</p>
<h3 id="3、Merge-insert-buffer"><a href="#3、Merge-insert-buffer" class="headerlink" title="3、Merge insert buffer"></a>3、Merge insert buffer</h3><p>所以后面就是合并操作，合并的时机：</p>
<p><font color='red'><u><em><strong>1、master thread</strong></em></u></font></p>
<p><font color='red'><u><em><strong>2、辅助索引页被读到缓冲池里去</strong></em></u></font>，然后这个是要执行正常的查询语句了，就去检查这个insert buffer bitmap，确认这个该辅助索引是不是在insert buffer b+书里面，如果有，就把树里面的记录查到辅助索引里面。</p>
</blockquote>
<h2 id="2、两次写"><a href="#2、两次写" class="headerlink" title="2、两次写"></a>2、两次写</h2><p><font color='red'><u><em><strong>doublewrite的目的是为了数据的可靠性。</strong></em></u></font></p>
<blockquote>
<p>具体实现的话，是依赖于两个部分，一个是<font color='red'><u><em><strong>内存中的doublewrite buffer</strong></em></u></font>，2m。另一部分是磁盘里的<font color='red'><u><em><strong>共享表空间里面有一个连续的128页</strong></em></u></font>，也是2m。</p>
<p>流程分三步。</p>
<p><font color='red'><u><em><strong>1、我先不直接写磁盘，我先复制到这个内存的doublewrite buffer里面</strong></em></u></font></p>
<p><font color='red'><u><em><strong>2、然后分两次写入，每次1m写入共享表空间的物理磁盘，</strong></em></u></font></p>
<p><font color='red'><u><em><strong>3、然后马上调用fsync函数，同步磁盘。</strong></em></u></font></p>
<p>所以，如果写的时候崩溃了，那就把这个共享表空间里面的副本拿出来配合redo log进行恢复。</p>
</blockquote>
<p>![image-20231021153343267](..&#x2F;images&#x2F;Mysql复习（mysql技术内幕 innodb存储引擎）&#x2F;image-20231021153343267.png)</p>
<h2 id="3、自适应哈希"><a href="#3、自适应哈希" class="headerlink" title="3、自适应哈希"></a>3、自适应哈希</h2><p>InnoDB会自动为某些访问频率非常高的页建立哈希索引，而哈希索引比起b+树更快，所以也是一种提高性能手段。</p>
<p>但是有一个<font color='blue'><u><em><strong>比较大的痛点就是他只能用于做 等值查询，如果遇到范围查到，就无能为力。</strong></em></u></font></p>
<h1 id="文件"><a href="#文件" class="headerlink" title="文件"></a>文件</h1><p>文件包括mysql文件和innodb文件</p>
<p>1、参数文件</p>
<p>2、日志文件、</p>
<p>3、socket文件</p>
<p>4、pid文件</p>
<p>5、mysql表结构文件</p>
<p>6、存储引擎文件</p>
<p>我们这里只讲几个</p>
<h2 id="2、日志文件"><a href="#2、日志文件" class="headerlink" title="2、日志文件"></a>2、日志文件</h2><p>日志文件有错误日志、慢查询日志、查询日志、二进制日志，我们着重可以讲一下二进制日志</p>
<h3 id="1、二进制日志"><a href="#1、二进制日志" class="headerlink" title="1、二进制日志"></a>1、二进制日志</h3><blockquote>
<p><font color='red'><u><em><strong>它是server层 的日志，记录了对mysql数据库更改的所有操作。</strong></em></u></font><font color='red'><u><em><strong>主要用于备份恢复和主从同步：</strong></em></u></font>不包括selectshow这类操作</p>
<p>过程主要是：</p>
<p>1）事务执行过程中，先把日志写到 binlog cache（Server 层的 cache，MySQL 给每个线程分配了一片内存用于缓冲 binlog）。</p>
<p>2）事务提交的时候，再把 binlog cache 写到 binlog 文件中。</p>
<p>这个刷盘的机制就依赖于sync_binlog这个参数</p>
<ul>
<li>sync_binlog &#x3D; 0 的时候，表示每次提交事务都只 write，不 fsync，后续交由操作系统决定何时将数据持久化到磁盘；</li>
<li>sync_binlog &#x3D; 1 的时候，表示每次提交事务都会 write，然后马上执行 fsync；</li>
<li>sync_binlog &#x3D;N(N&gt;1) 的时候，表示每次提交事务都 write，但累积 N 个事务后才 fsync。</li>
</ul>
<p><font color='red'><u><em><strong>还有个需要关注的点就是它落盘的形式，就是怎么记录的？</strong></em></u></font></p>
<p>这个是依赖于binlog——format这个参数，他就是记录二进制的格式，有三种、statement、row、mixed。</p>
<p>statement就是最简单的sql语句，但是他有个很大的问题就是如果用到了uuid rand udf这些函数或触发器，或者索引选择的问题，那么会导致主从不一致，那我们可以用row的格式，row的话就是记录表的行修改情况。同样的他也有一个很大问题就是要求的容量比较大。那还有一种mixed格式就是混用，正常情况下我按照statement记录sql语句，但是在uuid rand udf这些特殊情况我用row的格式进行纪记录。</p>
<blockquote>
<p>了解：</p>
<p>恢复：某些数据需要二进制日志。比如数据库全备文件恢复之后，通过二进制进行point-in-time的恢复</p>
<p>复制；主从同步，那canal也是通过这种方式去监听binlog</p>
<p>审计：用户通过二进制的信息判断是否有对数据库进行注入的攻击</p>
</blockquote>
</blockquote>
<h3 id="2、表结构定义文件"><a href="#2、表结构定义文件" class="headerlink" title="2、表结构定义文件"></a>2、表结构定义文件</h3><p>这个文件的后缀是.frm，每个文件都会有这个一个frm文件，记录了该表的表结构定义</p>
<h3 id="3、Innodb存储引擎文件"><a href="#3、Innodb存储引擎文件" class="headerlink" title="3、Innodb存储引擎文件"></a>3、Innodb存储引擎文件</h3><h4 id="1、表空间文件"><a href="#1、表空间文件" class="headerlink" title="1、表空间文件"></a>1、表空间文件</h4><p>首当其冲的就是表空间文件，次情况下我们会放到ibdata那个文件里面，但是我们可以通过设置一个参数去产生一个自己表的独立表空间，然后这些<font color='red'><u><em><strong>独立的表空间记录该表的数据，索引信息，其余的还是放在共享表空间里面。</strong></em></u></font></p>
<h4 id="2、redolog"><a href="#2、redolog" class="headerlink" title="2、redolog"></a>2、redolog</h4><blockquote>
<p>有两部分组成：redo log buffer缓冲，redo log File，它为了防止断电导致数据丢失的问题.当有一条记录需要更新的时候，InnoDB 引擎就会先更新内存（同时标记为脏页），然后将本次对这个页的修改记录到redolog buffer里面，然后按照一定的机制刷回redolog文件</p>
<p>后续，InnoDB 引擎会在适当的时候，由后台线程将缓存在 Buffer Pool 的脏页刷新到磁盘里，这就是 <strong>WAL （Write-Ahead Logging）技术</strong>。</p>
<p><font color='red'><u><em><strong>WAL 技术指的是， MySQL 的写操作并不是立刻写到磁盘上，而是先写日志，然后在合适的时间再写到磁盘上。</strong></em></u></font></p>
<p>主要有下面几个时机：</p>
<ul>
<li>MySQL 正常关闭时；</li>
<li>当 redo log buffer 中记录的写入量大于 redo log buffer 内存空间的一半时，会触发落盘；</li>
<li>InnoDB 的后台线程每隔 1 秒，将 redo log buffer 持久化到磁盘。</li>
<li>每次事务提交时都将缓存在 redo log buffer 里的 redo log 直接持久化到磁盘（这个策略可由 innodb_flush_log_at_trx_commit 参数控制，下面会说）。</li>
</ul>
<p>由参数 <code>innodb_flush_log_at_trx_commit</code> 参数控制，可取的值有：0、1、2，默认值为 1，这三个值分别代表的策略如下：</p>
<ul>
<li>当设置该<strong>参数为 0 时</strong>，表示每次事务提交时 ，还是<strong>将 redo log 留在 redo log buffer 中</strong> ，该模式下在事务提交时不会主动触发写入磁盘的操作。</li>
<li>当设置该<strong>参数为 1 时</strong>，表示每次事务提交时，都<strong>将缓存在 redo log buffer 里的 redo log 直接持久化到磁盘</strong>，这样可以保证 MySQL 异常重启之后数据不会丢失。</li>
<li>当设置该<strong>参数为 2 时</strong>，表示每次事务提交时，都只是缓存在 redo log buffer 里的 redo log <strong>写到 redo log 文件，注意写入到「 redo log 文件」并不意味着写入到了磁盘</strong>，因为操作系统的文件系统中有个 Page Cache（如果你想了解 Page Cache，可以看<a target="_blank" rel="noopener" href="https://xiaolincoding.com/os/6_file_system/pagecache.html">这篇 (opens new window)</a>），Page Cache 是专门用来缓存文件数据的，所以写入「 redo log文件」意味着写入到了操作系统的文件缓存。</li>
</ul>
</blockquote>
<h1 id="索引前的准备知识"><a href="#索引前的准备知识" class="headerlink" title="索引前的准备知识"></a>索引前的准备知识</h1><p><a target="_blank" rel="noopener" href="https://baijiahao.baidu.com/s?id=1709211669369376612&amp;wfr=spider&amp;for=pc">https://baijiahao.baidu.com/s?id=1709211669369376612&amp;wfr=spider&amp;for=pc</a></p>
<p><strong>这里我们首先要问三个重要的问题去扒一扒MySQL的InnoDB存储引擎</strong></p>
<ol>
<li><strong>MySQL的记录是怎么存储的？</strong></li>
<li><strong>页内记录到底是怎么维护的？</strong></li>
<li><strong>页内查询过程是怎样的</strong></li>
</ol>
<h3 id="穿上第一件：Page页面"><a href="#穿上第一件：Page页面" class="headerlink" title="穿上第一件：Page页面"></a>穿上第一件：Page页面</h3><p>MySQL管理数据的一个单位叫Page页面，数据都是存在页面里的<strong>。</strong>那咱们想要知道数据是怎么存，就<strong>需要了解页面长什么样子</strong>。</p>
<p>直接爆照：</p>
<p>![img](..&#x2F;images&#x2F;Mysql复习（mysql技术内幕 innodb存储引擎）&#x2F;42a98226cffc1e171d3b202cf4e9e50a728de9ae.jpeg)</p>
<p>页头（Page Header）：存一些统计信息，记录页面的控制信息，共占56字节，包括页面空间使用情况、页的左右兄弟页面指针（<strong>这个就是双向链表，把左右兄弟页面的指针给拿到了</strong>）等。</p>
<p>虚记录：分为最大虚记录与最小虚记录，<strong>它俩把这页里面存储的数据的范围框住了。</strong>那怎么比较谁大谁小？用的是主键去比较：最大虚记录比页内最大主键还大，最小虚记录比页内最小主键还小<strong>。</strong>那主键到底是怎么存的呢？InnoDB用的是聚簇索引——<strong>数据和主键存到一起、数据和索引存到一起，数据按主键顺序存储。</strong></p>
<p>记录堆：<strong>这部分就是存储记录的区域</strong>，分为有效记录和已删除记录。已被删除的记录构成一个链表，叫做自由空间链表<strong>，</strong>如图蓝色已经被删除的数据，<strong>用一个链表把它们连起来</strong>。</p>
<p>未分配空间：页面未使用的存储空间，除了用了一部分的橙色的区域和已删除的蓝色的数据，剩下的就是未分配空间了，<strong>后面有新的数据插入，往里放就行了</strong>。</p>
<p>Slot：<strong>这一块对数据检索非常有用</strong>，卖个关子，后面详细说。</p>
<p>页尾（Page Tailer）：页面的最后部分，占8个字节，主要存储页面的校验信息。<strong>这一页如果写坏了，数据不对了，通过校验位可以检查出来。</strong></p>
<p>好了，到这里一个页面咱们了解了，了解数据大概是怎么分布的，<strong>那接下来需要考虑哪些点呢？</strong>我们接下来研究一下——页面记录是怎么维护的</p>
<h3 id="穿上第二件"><a href="#穿上第二件" class="headerlink" title="穿上第二件"></a>穿上第二件</h3><p>![img](..&#x2F;images&#x2F;Mysql复习（mysql技术内幕 innodb存储引擎）&#x2F;c9fcc3cec3fdfc032a5c874b6446949da5c2269b.jpeg)</p>
<p><strong>那这个数据在里边到底是怎么存的</strong>？换个说法——数据的顺序是怎么保证的？<strong>到底是物理有序，还是逻辑有序？</strong></p>
<p>我们再回顾一下大学的知识——<strong>物理有序写入不友好，查询友好；逻辑有序查询不友好，插入友好</strong>，两者优缺点互补。</p>
<p>再回到正题，了解了这两种不同存储方式的特性，反观页面是怎么做的。</p>
<p>先看下面这幅图，思考一下插入主键为10，9，8的数据，是按物理有序存储还是逻辑有序存储：</p>
<p>![img](..&#x2F;images&#x2F;Mysql复习（mysql技术内幕 innodb存储引擎）&#x2F;e850352ac65c103892bb2f180b68801ab27e89a2.jpeg)</p>
<p>数据插入是写入IO，数据查询是读IO，不管是写还是读，在分析存储的时候，无非是这四种：顺序写、随机写、顺序读、随机读。<strong>如果是顺序写，数据会有各种移动，写入性能肯定非常糟糕</strong>。但是没办法，<strong>优化写入的手段十分有限，不过呢我们却有很多办法优化读</strong>。</p>
<p><strong>所以想都不用想，页内数据存储的顺序就是逻辑有序</strong>。</p>
<p>重新梳理一下，<font color='red'><u><em><strong>Page与Page之间由双向链表连接，页内是用小的链表连起来的：</strong></em></u></font></p>
<p>![img](..&#x2F;images&#x2F;Mysql复习（mysql技术内幕 innodb存储引擎）&#x2F;9825bc315c6034a8191108a4766a5a5d082376a2.jpeg)</p>
<p>我们再来重新画一下这棵树：</p>
<p>![img](..&#x2F;images&#x2F;Mysql复习（mysql技术内幕 innodb存储引擎）&#x2F;80cb39dbb6fd5266c5d8021702618422d5073647.jpeg)</p>
<p>这里要注意，每个Page的索引的每个节点，也就是树的每个节点，它也是一个Page。<strong>既然是个Page，也会有页头，也会有双向链表</strong>，如图蓝色与紫色相间那部分节点数据。</p>
<p><strong>接下来咱分析一下它的插入策略。</strong></p>
<p>蓝色部分已删除的空间（记录堆）怎么办呢？<strong>我们得想办法尽量把它们利用上</strong>，这个换谁做数据库设计都要这么设计<strong>。</strong></p>
<p>其实，插入策略就是先使用自由空间链表，再使用未使用空间，<strong>把数据库“空洞”给补上。</strong>不过呢，自由空间链表的空间也不能完全利用上，比如旧的数据占25个字节，新的数据假设都只有20个字节，<strong>那剩下这5个字节基本也利用不上，这样一来就会产生越来越多的“碎片”</strong>。经过长时间的插入删除插入删除以后，我们就得考虑给数据库做一次收缩，比如通过两次主从表的双向同步，<strong>把所有表数据重新插一遍</strong>。</p>
<p><strong>我们接下来研究一下——页内查询是怎么做的？</strong></p>
<h3 id="穿上第三件：Slot槽"><a href="#穿上第三件：Slot槽" class="headerlink" title="穿上第三件：Slot槽"></a>穿上第三件：Slot槽</h3><p><strong>页内的数据是遍历还是二分查找？</strong></p>
<p>无论数据是物理连续还是逻辑有序，都不能二分查找，都得用遍历的办法。如果我们设计一款数据库，通过索引找到数据在哪个Page里面，要是Page这一层通过遍历的方式，那效率实在是太低了，所以数据库肯定不能这样设计。</p>
<p>遍历不行，那就使用二分查找吧，提高一下效率。那MySQL是怎么做的呢？看看这张图：</p>
<p>![img](..&#x2F;images&#x2F;Mysql复习（mysql技术内幕 innodb存储引擎）&#x2F;3b87e950352ac65c1fead4dc4c8ba11892138a30.jpeg)</p>
<p>如图，最小虚记录和最大虚记录之间形成一个链表，这时候Slot区就派上用场了，每个Slot槽指向链表中的某一个位置，每个槽的大小一样，可以理解为一个指针，<strong>这样我们只需要用一个算法把每个子链表的长度拆成差不多大小就行了</strong>。</p>
<p>在查找的时候，先基于Sn、S0找到指向的最大最小虚记录，在Slot区进行二分：<strong>先找到Sn和S0的中间位置，中间找到某个Slot，然后再一步步进行比较，通过几次二分后找到具体的子链表，最后，在子链表内进行遍历找到最终的记录</strong>。这样我们借助Slot区实现了一个近似二分查找的方法。这特别像Java里面的跳表结构，一次查找跳一次，再一次查找再跳一次，效率就特别高了</p>
<h1 id="索引"><a href="#索引" class="headerlink" title="索引"></a>索引</h1><p><strong>普通索引和唯一索引，应该怎么选择？</strong>查询和对已经在内存的更新差距不大。但是对于不在内存的数据，唯一索引有唯一性要求，要先加到内存（相当于用不了changebuffer），但是普通索引不需要，只需要存到change buffer里面就可以。</p>
<p><strong>MySQL为什么有时候会选错索引？</strong></p>
<blockquote>
<p>优化器是找到一个最优的方案，以最小的代价去执行。</p>
<p>1)我们是根据基数来估计记录数，那基数是怎么得到的？是通过采样统计。InnoDB 默认会选择 N 个数据页，统计这些页面上的不同值，得到一个平均值，然后乘以这个索引的页面数，就得到了基数。</p>
<p>2)优化器还要判断，执行这个语句本身要扫描多少行，</p>
<p>解决方法？</p>
<p>1）forceindex</p>
<p>2）<strong>修改语句，引导 MySQL 使用我们期望的索引</strong></p>
<p>3）新建索引</p>
</blockquote>
<p> <strong>怎么给字符串字段加索引？</strong></p>
<blockquote>
<p>1、前缀索引。这里要关注的区分度，就是前缀索引是几个字符的时候区分度较大，又能节省空间，这个可能需要用到count函数去比较一下。</p>
<p>Ps：用前缀索引就用不上覆盖索引对查询性能的优化了，都要回表</p>
<p>其他方法？</p>
<p>2、倒序存储</p>
<p>3、hash</p>
<p>差别在于，空间，查询效率，区间查找</p>
</blockquote>
<p><strong>对于函数操作，不管有没有改变有序性，都不走索引。</strong></p>
<p>由于上面这条规则， 所以一些在索引字段上面做隐式转换和隐式编码转换，也不走索引。P：在mysql里面字符串和数字的隐式转换是<font color='red'><u><em><strong>字符串转成数字</strong></em></u></font>，字符编码从少的往多的转。</p>
<p>innodb最常见的索引就是：</p>
<p><font color='red'><u><em><strong>b+树索引 （b+树只能找到数据行所在的页，然后把页读到内存里面，进行查找）</strong></em></u></font></p>
<p><font color='red'><u><em><strong>哈希索引（自动生成）</strong></em></u></font></p>
<p><font color='red'><u><em><strong>全文索引</strong></em></u></font></p>
<h2 id="1、B-树索引"><a href="#1、B-树索引" class="headerlink" title="1、B+树索引"></a>1、B+树索引</h2><p>了解 ：二叉查找树（左小于中小于右）-&gt;平衡二叉树，任何结点的两个子树高度差小于等于1（性能比较高，但不是最高）（需要左旋右旋等等）</p>
<blockquote>
<p>b+树是为了磁盘或其他直接存取辅助设备设计的一种平衡查找树</p>
<p>b+树的所有记录结点都是按照键值的大小顺序存放到同一层的叶子结点，他们之间通过叶子结点指针进行连接，中间的都是searchkey</p>
<h3 id=""><a href="#" class="headerlink" title=""></a></h3></blockquote>
<h3 id="1、操作"><a href="#1、操作" class="headerlink" title="1、操作"></a>1、操作</h3><h4 id="1、插入"><a href="#1、插入" class="headerlink" title="1、插入"></a>1、插入</h4><p>![image-20231005201534270](..&#x2F;images&#x2F;Mysql复习（mysql技术内幕 innodb存储引擎）&#x2F;image-20231005201534270.png)</p>
<h4 id="2、旋转"><a href="#2、旋转" class="headerlink" title="2、旋转"></a>2、旋转</h4><p>旋转发生在leaf page已经满了，但是左右兄弟还没有满，这时候会把记录平移到兄弟结点上面，左兄弟优先</p>
<h4 id="3、删除"><a href="#3、删除" class="headerlink" title="3、删除"></a>3、删除</h4><p>![image-20231005202324173](..&#x2F;images&#x2F;Mysql复习（mysql技术内幕 innodb存储引擎）&#x2F;image-20231005202324173.png)</p>
<h3 id="2、分类"><a href="#2、分类" class="headerlink" title="2、分类"></a>2、分类</h3><p>b+树可以分成聚集索引、辅助索引，这两个到区别就是叶子结点放的到底是不是一行信息</p>
<h4 id="1、聚集索引"><a href="#1、聚集索引" class="headerlink" title="1、聚集索引"></a>1、聚集索引</h4><blockquote>
<p><font color='red'><u><em><strong>聚集索引就是按照主键构造的索引b+树，所以叶子结点存放的就是整张表的数据</strong></em></u></font>，叶子结点也叫做数据页。非叶子结点的索引页存放的仅仅是键值和指向数据页的偏移量。</p>
</blockquote>
<h4 id="2、辅助索引"><a href="#2、辅助索引" class="headerlink" title="2、辅助索引"></a>2、辅助索引</h4><blockquote>
<p><font color='red'><u><em><strong>辅助索引的叶子结点不包含行记录的全部数据。叶子结点包含键值和书签，书签用来告诉引擎哪里能找到真正的行数据。</strong></em></u></font>由于innodb是索引组织表，所以辅助索引的书签就是行记录的聚集索引键。所以辅助索引就是包含了索引那列的值和主键的值。</p>
</blockquote>
<h3 id="3、B-树索引的管理"><a href="#3、B-树索引的管理" class="headerlink" title="3、B+树索引的管理"></a>3、B+树索引的管理</h3><blockquote>
<h4 id="1、索引管理"><a href="#1、索引管理" class="headerlink" title="1、索引管理"></a>1、索引管理</h4><p>创建和删除可以通过两种方法。一种是alter table。另一种是create&#x2F;drop index。</p>
<p>查看：show index from XX</p>
<h4 id="2、fast-index-create"><a href="#2、fast-index-create" class="headerlink" title="2、fast index create"></a><font color='red'><u><em><strong>2、fast index create</strong></em></u></font></h4><p>在创建索引的表加上一个S锁不需要重建表，删除索引只需要更新内部视图。<font color='red'><u><em><strong>但是不能做一些更新操作。</strong></em></u></font></p>
<h4 id="3、Online-Schema-Change在线架构改变OSC"><a href="#3、Online-Schema-Change在线架构改变OSC" class="headerlink" title="3、Online Schema Change在线架构改变OSC"></a>3、Online Schema Change在线架构改变OSC</h4><p>osc了解即可：在线的意思其实就是在DDL的过程中，可以有读写事务对表进行操作</p>
<h4 id="4、Online-DDL"><a href="#4、Online-DDL" class="headerlink" title="4、Online DDL"></a><font color='red'><u><em><strong>4、Online DDL</strong></em></u></font></h4><p>允许在辅助索引创建的同时，还允许insert update等DML操作</p>
<p>原理是：执行insert update delete这些操作的时候，<font color='red'><u><em><strong>先把操作日志写入一个缓存里面，然后，索引建立后重做表上面</strong></em></u></font></p>
<p>新的alter table语法中，通过<font color='red'><u><em><strong>algorithm如果是 copy还是通过建立临时表的方式，如果是replace就是不需要临时表，</strong></em></u></font>是在InnoDB引擎内部完成，但是还是需要临时空间的。如果是default，那就是根据old_alter_table判断，如果是off，那就是replace。</p>
<h4 id="5、cardinality值"><a href="#5、cardinality值" class="headerlink" title="5、cardinality值"></a><font color='red'><u><em><strong>5、cardinality值</strong></em></u></font></h4><p>他是一个统计信息，优化器会根据这个值来判断我们用不用索引，表示索引中唯一值的数据的估计值，如果是性别这种，重复的非常多，我们叫低选择性，不适合做索引。反之高选择性就比较适合，尤其是在高选择性属性字段里面取出一小部分数据，那就更有必要了。</p>
<ul>
<li><strong>统计的方式</strong>？</li>
</ul>
<p>所以我们用的是<font color='red'><u><em><strong>采样</strong></em></u></font>的方法（<font color='red'><u><em><strong>（对8或20个叶子结点进行采样预估，取出平均值）</strong></em></u></font>）。cardinality值的<font color='red'><u><em><strong>更新</strong></em></u></font>发生在insert和update操作，但是肯定不是每一次inser tupdate都去更新，具体策略如下：</p>
<p>1、表中1&#x2F;16数据发生了变化</p>
<p>2、计数器超过20亿</p>
</blockquote>
<h3 id="4、B-树索引的使用"><a href="#4、B-树索引的使用" class="headerlink" title="4、B+树索引的使用"></a>4、B+树索引的使用</h3><blockquote>
<h4 id="1、联合索引"><a href="#1、联合索引" class="headerlink" title="1、联合索引"></a>1、联合索引</h4><p>本质也是一颗二叉树，之前是a,b,c,d现在是（a,b）(c,d)</p>
<p>第一个好处：对于联合查询和单列的第一列的查询都可以用联合查询</p>
<p>第二个好处：一句对第二个键值进行了排序处理，可以缩短某些情况的查询时间</p>
<h4 id="2、覆盖索引"><a href="#2、覆盖索引" class="headerlink" title="2、覆盖索引"></a>2、覆盖索引</h4><p>覆盖索引的意思是，从辅助索引中就直接可以得到想要查询的记录，不需要回表。</p>
<p>第一个好处是：辅助索引本身不包括整行记录，所以大小远小于聚集索引，减少io操作</p>
<p>第二个好处是：对于某些统计问题，存储引擎并不会通过积极索引，辅助索引远远小于聚集索引，</p>
<h4 id="3、优化器不选择索引的方式"><a href="#3、优化器不选择索引的方式" class="headerlink" title="3、优化器不选择索引的方式"></a>3、优化器不选择索引的方式</h4><p>多发生在范围查找、join链接操作</p>
<h4 id="4、MRR优化（只支持非聚集索引）（离散读变成顺序读）"><a href="#4、MRR优化（只支持非聚集索引）（离散读变成顺序读）" class="headerlink" title="4、MRR优化（只支持非聚集索引）（离散读变成顺序读）"></a>4、MRR优化（只支持非聚集索引）<font color='red'><u><em><strong>（离散读变成顺序读）</strong></em></u></font></h4><p>工作方式：</p>
<ul>
<li>把辅助索引读出来放到一个缓存里面</li>
<li>把缓存中根据rowid进行排序</li>
<li>然后根据rowid去找数据</li>
</ul>
<p>他适用于某些范围查找，</p>
<p>而且还可以对某些范围查找进行拆分，变成成键值对的等值查找。直接就过滤了一些不符合条件的数据。</p>
<p>好处：</p>
<ul>
<li>数据访问更加顺序，</li>
<li>减少缓冲池页的替换</li>
</ul>
<h4 id="5、索引下推ICP优化（只支持非聚集索引）"><a href="#5、索引下推ICP优化（只支持非聚集索引）" class="headerlink" title="5、索引下推ICP优化（只支持非聚集索引）"></a>5、索引下推ICP优化（只支持非聚集索引）</h4><p>原本我们通过索引进行查询的时候，首先根据索引查找记录，然后根据where条件过滤记录。ICP是在取出索引的同时，判断是否可以进行where条件的过滤，也就是讲where的部分过滤操作放到了存储引擎层</p>
<p>场景：</p>
<p>假设表TB1上有索引IDX_C1_C2_C3(C1,C2,C3)，对于查询SELECT * FROM TB1 WHERE C1&#x3D;’XXX’ AND C3&#x3D;’XXX’</p>
<p>在MySQL 5.6版本以前，由于缺少C2的过滤条件，Innodb存储引擎层只能使用索引IDX_C1_C2_C3按照C1&#x3D;’XXX’条件找出所有满足条件的索引记录，再根据这些索引记录去聚集索引中查找，将找到的表数据返回给MySQL Server层，然后由MySQL Server层使用C3&#x3D;’XXX’条件进行过滤得到最终结果。</p>
<p>再MySQL 5.6版本中引入ICP特性，Innodb存储引擎层只能使用索引IDX_C1_C2_C3按照C1&#x3D;’XXX’条件去扫描所有满足条件的索引记录，再将这些索引记录按照C3&#x3D;’XXX’条件进行过滤，并按照过滤后的索引记录去去聚集索引中查找，将找到的表数据返回给MySQL Server层，得到最终结果。</p>
<p>假设满足C1&#x3D;’XXX’条件的数据行为100000条，而满足C1&#x3D;’XXX’ AND C3&#x3D;’XXX’的数据行为100条，则：</p>
<p>1、在MySQL 5.5版本中，需要对TB1的聚集索引进行100000次Index Seek操作，Innodb存储引擎层向MySQL Server层传递100000行数据。</p>
<p>2、在MySQL 5.6版本中，使用ICP仅需要对TB1的聚集索引进行100次的Index Seek操作，Innodb存储引擎层向MySQL Server层传递100行数据。</p>
</blockquote>
<h3 id="5、自适应哈希索引"><a href="#5、自适应哈希索引" class="headerlink" title="5、自适应哈希索引"></a>5、自适应哈希索引</h3><p>InnoDB中的哈希用的字典进行查找，冲突用链表解决，哈希函数用除法散列</p>
<p>自适应哈希索引就是用的这种方法。</p>
<h3 id="6、全文检索"><a href="#6、全文检索" class="headerlink" title="6、全文检索"></a>6、全文检索</h3><blockquote>
<p>全文检索一般使用倒排索引。</p>
<h5 id="1、倒排索引"><a href="#1、倒排索引" class="headerlink" title="1、倒排索引"></a>1、倒排索引</h5><p>它在辅助表（auxiliary table）中存储了单词与单词自身在一个或多个文档中所在位置之间的映射。这通常利用关键数组实现，其拥有两种表现形式：<br>inverted file index：其表现形式为{单词，单词所在文档的ID}<br>full inverted index：其表现形式为{单词，(单词所在文档的ID，在文档中的具体位置)}</p>
<h5 id="2、InnoDB全文检索的实现"><a href="#2、InnoDB全文检索的实现" class="headerlink" title="2、InnoDB全文检索的实现"></a>2、InnoDB全文检索的实现</h5><p><font color='red'><u><strong>InnoDB全文索引有3个非常重要的东西，一个是辅助表，一个是FTS Index Cache、一个是FTS DOUCUMENT id</strong></u></font></p>
<h6 id="1、Auxiliary-Table（辅助表）"><a href="#1、Auxiliary-Table（辅助表）" class="headerlink" title="1、Auxiliary Table（辅助表）"></a><strong>1、Auxiliary Table（辅助表）</strong></h6><p><font color='red'><u><em><strong>辅助表是把文档，分词然后规范化后的结果，</strong></em></u></font></p>
<p><font color='red'><u><em><strong>辅助表的话采用“full inverted index”的方式有两个列：</strong></em></u></font></p>
<p><font color='red'><u><em><strong>一个是word字段。在word字段上有设有索引，另一个是ilist字段，（DocumentId,Position）</strong></em></u></font></p>
<h6 id="2、FTS-INDEX-Cache（全文检索缓存）"><a href="#2、FTS-INDEX-Cache（全文检索缓存）" class="headerlink" title="2、FTS INDEX Cache（全文检索缓存）"></a><strong>2、FTS INDEX Cache（全文检索缓存）</strong></h6><p>他是一个红黑树的结构：<font color='red'><u><em><strong>我执行插入操作，插入的数据已经更新了对应的表，但是我们的辅助表可能还没更新，这个更新还停留在FTS cache里面</strong></em></u></font>。如果没插一次就更新这是不合理的，那具体同步到辅助表的时机：</p>
<p>1、在我进行全文检索查询的时候，我把FTS INDEX cache里的word字段合并到辅助表，然后查询。有点类似于insert buffer</p>
<p>2、数据库关闭的时候会同步</p>
<p>3、cache满了	</p>
<p>数据库宕机时：一些FTS InDEX Cache中的数据库可能未被同步到磁盘上。那么下次重启时，当用户对表进行全文检索（查询或者插入操作）时，InnoDB会自动读取未完成的文档，然后进行分词操作，再将分词的结果放入到FTS Index Cache中</p>
<p>对于InnoDB来说，其总是在事务提交时将分词写入到FTS Index Cache。</p>
<h6 id="3、FTS-DOUCUMENT-ID"><a href="#3、FTS-DOUCUMENT-ID" class="headerlink" title="3、FTS DOUCUMENT ID"></a>3、FTS DOUCUMENT ID</h6><p><font color='red'><u><em><strong>为了支持全文检索，我们每一行数据必须有一个列与word进行映射：</strong></em></u></font></p>
<ul>
<li>在InnoDB中这个列<strong>被命名为FTS_DOC_ID</strong>，他是自动创建的</li>
<li>其<strong>类型必须是</strong>bigint unsigned not null</li>
<li>并且InnoDB自动会在该列上加入一个<strong>名为FTS_DOC_ID_INDEX的unique index索引</strong></li>
<li><strong>用户也可以在建表时自动添加FTS_DOC_ID，以及相应的Unique Index</strong></li>
</ul>
<p>Deleted auxiliary table<br>文档中分词的插入操作是在事务提交时完成的，然而对于删除操作，其在事务提交时不删除磁盘Auxiliary Table中的记录，而只是删除FTS Index Cache中的记录。对于Auxiliary Table中被删除的记录，InnoDB会记录其FTS Document ID，并将其保存在Deleted auxiliary table中</p>
<p>由于文档的DML操作实际并不删除索引中的数据，相反还会在对应的DELETED表中插入记录，因此随着应用程序的允许，索引会变得非常大，即使索引列中的有些数据已经被删除，查询也不会使用到。为了，InnoDB存储引擎提供了一种方式，允许用户手动地将已删除的记录从索引中彻底删除，该命令就是OPTIMIZE TABLE</p>
</blockquote>
<p>事务级别</p>
<p><strong>类型一：RU（READ-UNCOMMITTED 表示读未提交）</strong></p>
<p>可以读取到事务未提交的数据，隔离性差，会出现脏读（当前内存读），不可重复读，幻读问题;</p>
<p><strong>类型二：RC（READ-COMMITTED 表示读已提交）</strong>可用</p>
<p>可以读取到事务已提交的数据，隔离性一般，不会出现脏读问题，但是会出现不可重复读，幻读问题；</p>
<p><strong>类型三：RR（REPEATABLE-READ 表示可重复读）</strong><code>默认</code></p>
<p>可以防止脏读（当前内存读），防止不可重复读问题，防止会出现的幻读问题，但是并发能力较差；</p>
<p>会使用next lock锁进制，来防止幻读问题，但是引入锁进制后，锁的代价会比较高，比较耗费CPU资源，占用系统性能；</p>
<p><strong>类型四：SR（SERIALIZABLE 可串行化）</strong></p>
<p>隔离性比较高，可以实现串行化读取数据，但是事务的并发度就没有了；</p>
<p>这是事务的最高级别，在每条读的数据上，加上锁，使之不可能相互冲突</p>
<h1 id="锁"><a href="#锁" class="headerlink" title="锁"></a>锁</h1><p>锁机制是用于管理对共享资源的并发访问，保证数据的完整性和一致性。</p>
<h2 id="1、锁的类型"><a href="#1、锁的类型" class="headerlink" title="1、锁的类型"></a>1、锁的类型</h2><h3 id="1、全局锁"><a href="#1、全局锁" class="headerlink" title="1、全局锁"></a>1、全局锁</h3><blockquote>
<p><font color='red'><u><em><strong>典型的使用场景就是做全库的逻辑备份</strong></em></u></font></p>
<ul>
<li><p>一旦加了全局锁之后，其他的DDL、 DML全部都处于阻塞状态，但是可以执行DQL语句，也就是处于只读状态</p>
</li>
<li><p>语法</p>
</li>
</ul>
 <figure class="highlight sql"><table><tr><td class="code"><pre><span class="line">flush tables <span class="keyword">with</span> read lock;<span class="number">1</span>、加全局锁</span><br><span class="line">mysqldump <span class="operator">-</span>uroot <span class="operator">-</span>pxxx db_name <span class="operator">-</span><span class="operator">&gt;</span> xxx.sql;<span class="number">2</span>、数据备份</span><br><span class="line">unlock tables;<span class="number">3</span>、释放锁</span><br></pre></td></tr></table></figure>


</blockquote>
<h3 id="2、表级锁"><a href="#2、表级锁" class="headerlink" title="2、表级锁"></a>2、表级锁</h3><blockquote>
<p>表级锁，主要分为4类：</p>
<ul>
<li>表锁</li>
<li>元数据锁（meta data lock，MDL）</li>
<li>意向锁</li>
<li>自增锁</li>
</ul>
</blockquote>
<h4 id="1、表锁"><a href="#1、表锁" class="headerlink" title="1、表锁"></a>1、表锁</h4><p>对于表锁，又可以分为2类：</p>
<ul>
<li>表共享读锁（read lock）</li>
<li>表独占写锁（write lock）</li>
</ul>
<p>结论: 读锁不会阻塞其他客户端的读，但是会阻塞写。写锁既会阻塞其他客户端的读，又会阻塞 其他客户端的写。</p>
<h4 id="2、元数据锁"><a href="#2、元数据锁" class="headerlink" title="2、元数据锁"></a>2、元数据锁</h4><blockquote>
<p>再来说说<strong>元数据锁</strong>（MDL）,<font color='red'><u><em><strong>它 是为了保证当用户对表执行 CRUD 操作时，防止其他线程对这个表结构做了变更。我们不需要显示的使用 MDL，会自动给这个表加上 MDL：</strong></em></u></font></p>
<ul>
<li>对一张表进行 CRUD 操作时，加的是 <strong>MDL 读锁</strong>；</li>
<li>对一张表做结构变更操作的时候，加的是 <strong>MDL 写锁</strong>；</li>
</ul>
</blockquote>
<blockquote>
<p>MDL 不需要显示调用，那它是在什么时候释放的?</p>
</blockquote>
<p>MDL 是在事务提交后才会释放，这意味着<strong>事务执行期间，MDL 是一直持有的</strong>。</p>
<h4 id="3、意向锁"><a href="#3、意向锁" class="headerlink" title="3、意向锁"></a>3、意向锁</h4><blockquote>
<p><font color='red'><u><strong>我觉得意向锁主要还是解决行锁和表锁之间的冲突问题</strong></u></font></p>
<ul>
<li>在使用 InnoDB 引擎的表里对某些记录加上「共享锁」之前，需要先在表级别加上一个「意向共享锁」；</li>
<li>在使用 InnoDB 引擎的表里对某些纪录加上「独占锁」之前，需要先在表级别加上一个「意向独占锁」；</li>
</ul>
</blockquote>
<p>也就是，当执行插入、更新、删除操作，需要先对表加上「意向独占锁」，然后对该记录加行级独占锁。</p>
<p>![img](..&#x2F;images&#x2F;Mysql复习（mysql技术内幕 innodb存储引擎）&#x2F;20e0f35589584352bd15e817668a0886.png)</p>
<p>![img](..&#x2F;images&#x2F;Mysql复习（mysql技术内幕 innodb存储引擎）&#x2F;6e6b275c2d6d4dfcbbb338be4f61bee9.png)</p>
<p>所以，<strong>意向锁的目的是为了快速判断表里是否有记录被加锁</strong>。</p>
<h4 id="4、自增锁"><a href="#4、自增锁" class="headerlink" title="4、自增锁"></a>4、自增锁</h4><blockquote>
<p><font color='red'><u><em><strong>主键设置成自增之后，会自动给主键赋递增的值.</strong></em></u></font></p>
<p>然后这里有两种方式一种是，AUTO-INC 锁<strong>，</strong>不是一个事务提交后才释放，而是在<font color='red'><u><em><strong>执行完插入语句后就会立即释放。</strong></em></u></font></p>
<p>但是，对大量数据进行插入的时候，会影响插入性能，因为另一个事务中的插入会被阻塞。</p>
<p>所以后面InnoDB 存储引擎提供了一种<strong>轻量级的锁</strong>，并且提供了一个参数，叫innodb autoinc lock mode</p>
<ul>
<li>当 innodb_autoinc_lock_mode &#x3D; 0，就采用 AUTO-INC 锁，语句执行结束后才释放锁；</li>
<li>当 innodb_autoinc_lock_mode &#x3D; 2，就采用轻量级锁，申请自增主键后就释放锁，并不需要等语句执行后才释放。</li>
<li>当 innodb_autoinc_lock_mode &#x3D; 1：</li>
<li>普通 insert 语句，自增锁在申请之后就马上释放；</li>
<li>类似 insert … select 这样的批量插入数据的语句，自增锁还是要等语句结束后才被释放<font color='red'><u><em><strong>（因为“不知道要预先申请多少个 id）</strong></em></u></font></li>
<li>原因如下：</li>
</ul>
</blockquote>
<p>![img](..&#x2F;images&#x2F;Mysql复习（mysql技术内幕 innodb存储引擎）&#x2F;innodb_autoinc_lock_mode&#x3D;2.png)</p>
<p>session A 往表 t 中插入了 4 行数据，然后创建了一个相同结构的表 t2，然后<strong>两个 session 同时执行向表 t2 中插入数据</strong>。</p>
<p>如果 innodb_autoinc_lock_mode &#x3D; 2，意味着「申请自增主键后就释放锁，不必等插入语句执行完」。那么就可能出现这样的情况：</p>
<ul>
<li>session B 先插入了两个记录，(1,1,1)、(2,2,2)；</li>
<li>然后，session A 来申请自增 id 得到 id&#x3D;3，插入了（3,5,5)；</li>
<li>之后，session B 继续执行，插入两条记录 (4,3,3)、 (5,4,4)。</li>
</ul>
<p>可以看到，<strong>session B 的 insert 语句，生成的 id 不连续</strong>。</p>
<p>当「主库」发生了这种情况，binlog 面对 t2 表的更新只会记录这两个 session 的 insert 语句，如果 binlog_format&#x3D;statement，记录的语句就是原始语句。记录的顺序要么先记 session A 的 insert 语句，要么先记 session B 的 insert 语句。</p>
<p>但不论是哪一种，这个 binlog 拿去「从库」执行，这时从库是按「顺序」执行语句的，只有当执行完一条 SQL 语句后，才会执行下一条 SQL。因此，在<strong>从库上「不会」发生像主库那样两个 session 「同时」执行向表 t2 中插入数据的场景。所以，在备库上执行了 session B 的 insert 语句，生成的结果里面，id 都是连续的。这时，主从库就发生了数据不一致</strong>。</p>
<p>要解决这问题，binlog 日志格式要设置为 row，这样在 binlog 里面记录的是主库分配的自增值，到备库执行的时候，主库的自增值是什么，从库的自增值就是什么。</p>
<p>所以，<strong>当 innodb_autoinc_lock_mode &#x3D; 2 时，并且 binlog_format &#x3D; row，既能提升并发性，又不会出现数据一致性问题</strong>。</p>
<h3 id="3、行锁"><a href="#3、行锁" class="headerlink" title="3、行锁"></a>3、行锁</h3><blockquote>
<p>InnoDB实现了以下两种类型的行锁：</p>
<ul>
<li>共享锁（S）：允许一个事务去读一行，阻止其他事务获得相同数据集的排它锁。</li>
<li>排他锁（X）：允许获取排他锁的事务更新数据，阻止其他事务获得相同数据集的共享锁和排他 锁</li>
</ul>
<p><strong>MySQL 的行锁是在引擎层由各个引擎自己实现的。</strong></p>
<p><strong>两阶段锁协议</strong>：</p>
<blockquote>
<p><strong>在 InnoDB 事务中，行锁是在需要的时候才加上的，但并不是不需要了就立刻释放，而是要等到事务结束时才释放。</strong></p>
</blockquote>
<blockquote>
<p>![image-20230805221422216](..&#x2F;images&#x2F;Mysql复习（mysql技术内幕 innodb存储引擎）&#x2F;image-20230805221422216.png)</p>
</blockquote>
<blockquote>
<p>InnoDB有三种行锁的算法：</p>
</blockquote>
<blockquote>
<p>Record Lock：单个行记录的锁</p>
</blockquote>
<blockquote>
<p>Gap Lock：间隙锁，锁定一个范围，但不包括记录本身</p>
</blockquote>
<blockquote>
<p>Next-Key Lock：Record Lock + Gap Lock</p>
</blockquote>
<blockquote>
<p>InnoDB就是用Next-Key去解决幻读问题（同一事务下，连续执行两次相同的sql语句可能导致不同的结果，第二次sql可能会返回之前不存在的行）</p>
</blockquote>
<blockquote>
<p>查询的索引如果是唯一性质，那么降级为Record Lock</p>
</blockquote>
<h2 id="2、一致性非锁定读（快照读）"><a href="#2、一致性非锁定读（快照读）" class="headerlink" title="2、一致性非锁定读（快照读）"></a>2、一致性非锁定读（快照读）</h2><p>一致性非锁定读是指InnoDb通过多版本控制（MVCC）的方式读一个我能看到的数据。就算读取的那一行正在做一些dml操作，但是我不会去等，我会直接去读一个快照数据。</p>
<p>所以我们要讲一下这个MVCC，他这个就依赖于undolog版本链和readView。</p>
<p>首先，每一行数据其实都有两个隐藏列，一个是trxid一个是rollpointer，trxid 表示最新修改事务的id，rollpointer表示指向旧版本undo log</p>
<p>undolog版本链形成的原因是，我们修改的数据的时候，我们把该行数据拷贝到 <code>undo log</code>作为旧版本。进行真正的修改操作，同时修改trxid 和roll_pointer。</p>
<p>ReadView，里面有四个比较关键的东西：</p>
<p>一个是m_ids，这个就是说事务开启那一刻有哪些事务在Mysql里面执行还没有提交的；</p>
<p>一个是min_trx_id，就是m_ids里最小的事务id的值；</p>
<p>一个是max_trx_id，就是此刻mysql下一个要生成的事务id，就是最大事务id；</p>
<p>一个是creator_trx_id，就是你这个事务的id。</p>
<p><font color='red'><u><em><strong>如果比mintexid小或者等于creatoridexid，我们可以看得见。</strong></em></u></font></p>
<p>比如一条记录旧版本里面有三条记录：10，20，30。然后我们的事务id是15，m_ids里面有20，30。这里的min_trx_id就是20，我们的15比她小，说明还没有提交。因为隔离性所以肯定是看不到的，然后再去找更前面版本，我们就找到了10，发现10可以，所以我们这次读到的数据就是事务id为10的那一个版本。</p>
<h2 id="3、一致性锁定读（当前读）"><a href="#3、一致性锁定读（当前读）" class="headerlink" title="3、一致性锁定读（当前读）"></a>3、一致性锁定读（当前读）</h2><p>有时候用户需要些显式的对读操作进行加锁保证一致性。<font color='red'><u><em><strong>还有update也是当前读</strong></em></u></font></p>
<h2 id="5、锁问题"><a href="#5、锁问题" class="headerlink" title="5、锁问题"></a>5、锁问题</h2><h3 id="1、脏读"><a href="#1、脏读" class="headerlink" title="1、脏读"></a>1、脏读</h3><p><font color='blue'><u><em><strong>读到了其他事务没有提交的数据</strong></em></u></font>，违反了隔离性。但是脏读发生的隔离级别最少也得是read uncommitted，而我们的数据库默认是可重复读，所以一般在生产环境中，发生的并不多。</p>
<h3 id="2、不可重复读-or-幻读"><a href="#2、不可重复读-or-幻读" class="headerlink" title="2、不可重复读 or 幻读"></a>2、不可重复读 or 幻读</h3><p>不可重复读：两次读，读的不一样。</p>
<p>幻读：一个事务在前后两次查询同一个范围的时候，后一次查询看到了前一次查询没有看到的行。说白了就是另一个事物插入了新的数据，但是没办法拒绝。</p>
<p>不可重复读：就是一个事务读两次，另一个事务在两次读之间作出修改，因为读是mvcc，不加锁，所以会出现不可重复读。innoDB的解决方法：</p>
<ul>
<li>针对<strong>快照读</strong>（普通 select 语句），是<strong>通过 MVCC 方式解决了幻读</strong>，因为可重复读隔离级别下，事务执行过程中看到的数据，一直跟这个事务启动时看到的数据是一致的，即使中途有其他事务插入了一条数据，是查询不出来这条数据的，所以就很好了避免幻读问题。</li>
<li>针对<strong>当前读</strong>（select … for update 等语句），是<font color='red'><u><em><strong>通过 next-key lock（记录锁+间隙锁）（前开后闭区间）</strong></em></u></font><strong>方式解决了幻读</strong>，因为当执行 select … for update 语句的时候，会加上 next-key lock，如果有其他事务在 next-key lock 锁范围内插入了一条记录，那么这个插入语句就会被阻塞，无法成功插入，所以就很好了避免幻读问题。</li>
</ul>
<h3 id="3、丢失更新"><a href="#3、丢失更新" class="headerlink" title="3、丢失更新"></a>3、丢失更新</h3><p>是指一个事务的操作被另一个事务的操作覆盖了，但是当前数据库的任何隔离级别都对行或者粗粒度的对象加锁，所以还是比较难发生。</p>
</blockquote>
<h2 id="6、死锁"><a href="#6、死锁" class="headerlink" title="6、死锁"></a>6、死锁</h2><p>死锁是指两个或以上的事务争夺资源造成的一种互相等待的现象</p>
<p>解决方法：</p>
<p>1、设置超时的阈值，回滚一个死锁的事务</p>
<p>2、wait-for-graph 等待图。检测是否有回路。通常用深度优先。1.2版本开始就变成非递归</p>
<p>如果有死锁，那就回归undo量最少的</p>
<h2 id="7、锁升级"><a href="#7、锁升级" class="headerlink" title="7、锁升级"></a>7、锁升级</h2><p>InnoDB中不存在锁升级的问题，因为InnoDB不是更具每个记录来产生锁的，相反，其根据每个事务访问的每个页对锁进行管理，采用的是位图的方式。所以不管你锁住的是页中的一个记录或者多个记录，开销一样</p>
<p>![image-20231006204601132](..&#x2F;images&#x2F;Mysql复习（mysql技术内幕 innodb存储引擎）&#x2F;image-20231006204601132.png)</p>
<h1 id="事务"><a href="#事务" class="headerlink" title="事务"></a>事务</h1><h2 id="1、认识事务"><a href="#1、认识事务" class="headerlink" title="1、认识事务"></a>1、认识事务</h2><h3 id="1、四个特性：acid。"><a href="#1、四个特性：acid。" class="headerlink" title="1、四个特性：acid。"></a>1、四个特性：acid。</h3><p>原子性：要么成功要么失败</p>
<p>一致性：讲数据库从一种状态转变为下一种一致的状态，完整性约束没有被破坏。</p>
<p>隔离性Isolation：一个事务提交之前对其他事物不可见</p>
<p>Durability：一旦提交，那么结果是永久性的</p>
<h3 id="2、分类-1"><a href="#2、分类-1" class="headerlink" title="2、分类"></a>2、分类</h3><p>扁平事务</p>
<p>带有保存点的扁平事务</p>
<p>链事务</p>
<p>嵌套事务</p>
<p>分布式事务</p>
<h2 id="2、事务的实现"><a href="#2、事务的实现" class="headerlink" title="2、事务的实现"></a>2、事务的实现</h2><p>事务的隔离性由锁机制来实现。</p>
<p>原子性、一致性、持久性通过redo log和undo log完成</p>
<p>redo log保证持久性</p>
<p>undo log保证事务的原子性，一致性</p>
<h3 id="1、redo-log"><a href="#1、redo-log" class="headerlink" title="1、redo log"></a>1、redo log</h3><p><font color='red'><u><em><strong>它为了防止断电导致数据丢失的问题</strong></em></u></font>，<font color='red'><u><em><strong>当有一条更新操作的时候，InnoDB 引擎就会先更新内存（同时标记为脏页），然后将本次对这个页的修改以 redo log 的形式记录下来，InnoDB 引擎会在适当的时候，由后台线程将缓存在 Buffer Pool 的脏页刷新到磁盘里</strong></em></u></font>。这就是 <strong>WAL （Write-Ahead Logging）技术</strong>。</p>
<p><font color='red'><u><em><strong>WAL 技术指的是， MySQL 的写操作并不是立刻写到磁盘上，而是先写日志，然后在合适的时间再写到磁盘上。</strong></em></u></font></p>
<p>主要有下面几个时机：</p>
<ul>
<li>MySQL 正常关闭时；</li>
<li>当 redo log buffer 中记录的写入量大于 redo log buffer 内存空间的一半时，会触发落盘；</li>
<li>InnoDB 的后台线程每隔 1 秒，将 redo log buffer 持久化到磁盘。</li>
<li>每次事务提交时都将缓存在 redo log buffer 里的 redo log 直接持久化到磁盘（这个策略可由 innodb_flush_log_at_trx_commit 参数控制，下面会说）。</li>
</ul>
<p>由参数 <code>innodb_flush_log_at_trx_commit</code> 参数控制，可取的值有：0、1、2，默认值为 1，这三个值分别代表的策略如下：</p>
<ul>
<li>当设置该<strong>参数为 0 时</strong>，表示每次事务提交时 ，还是<strong>将 redo log 留在 redo log buffer 中</strong> ，该模式下在事务提交时不会主动触发写入磁盘的操作。</li>
<li>当设置该<strong>参数为 1 时</strong>，表示每次事务提交时，都<strong>将缓存在 redo log buffer 里的 redo log 直接持久化到磁盘</strong>，这样可以保证 MySQL 异常重启之后数据不会丢失。</li>
<li>当设置该<strong>参数为 2 时</strong>，表示每次事务提交时，都只是缓存在 redo log buffer 里的 redo log <strong>写到 redo log 文件，注意写入到「 redo log 文件」并不意味着写入到了磁盘</strong>，因为操作系统的文件系统中有个 Page Cache（如果你想了解 Page Cache，可以看<a target="_blank" rel="noopener" href="https://xiaolincoding.com/os/6_file_system/pagecache.html">这篇 (opens new window)</a>），Page Cache 是专门用来缓存文件数据的，所以写入「 redo log文件」意味着写入到了操作系统的文件缓存。</li>
</ul>
<p>事务提交的时候必须把事务的所有日志写入重做日志文件进行持久化。这个的所有日志包括redo log 和undo log</p>
<p>![image-20231007131604938](..&#x2F;images&#x2F;Mysql复习（mysql技术内幕 innodb存储引擎）&#x2F;image-20231007131604938.png)</p>
<p>![image-20231007131752781](..&#x2F;images&#x2F;Mysql复习（mysql技术内幕 innodb存储引擎）&#x2F;image-20231007131752781.png)</p>
<p>![image-20231007131726290](..&#x2F;images&#x2F;Mysql复习（mysql技术内幕 innodb存储引擎）&#x2F;image-20231007131726290.png)</p>
<blockquote>
<p>产生的 redo log 是直接写入磁盘的吗？</p>
</blockquote>
<p>不是的。</p>
<p>实际上， 执行一个事务的过程中，产生的 redo log 也不是直接写入磁盘的，因为这样会产生大量的 I&#x2F;O 操作，而且磁盘的运行速度远慢于内存。</p>
<p>所以，redo log 也有自己的缓存—— <strong>redo log buffer</strong>，每当产生一条 redo log 时，会先写入到 redo log buffer，后续在持久化到磁盘如下图：</p>
<p>![image-20231007131921540](..&#x2F;images&#x2F;Mysql复习（mysql技术内幕 innodb存储引擎）&#x2F;image-20231007131921540.png)</p>
<h3 id="2、undo-log"><a href="#2、undo-log" class="headerlink" title="2、undo log"></a>2、undo log</h3><blockquote>
<p>undo log最主要的作用有两点：<font color='red'><u><em><strong>一个是事务回滚，保证原子性；还有一个是支持mvcc</strong></em></u></font></p>
<p>那我们先讲第一个，就是事务提交之前，如果发生意外，这时候你用redolog是没有办法恢复的，所以我们可以使用undolog，因为undolog他记录的是修改前的记录。</p>
<p>另外一个大的作用是mvcc，mvcc他是基于undo log版本链和ReadView实现</p>
<p>首先，每一行数据其实都有两个隐藏列，一个是trxid一个是rollpointer，trxid 表示最新修改事务的id，rollpointer表示指向旧版本log</p>
<p>undolog版本链形成的原因是，我们修改的数据的时候，我们把该行数据拷贝到 <code>undo log</code>作为旧版本。进行真正的修改操作，同时修改trxid 和roll_pointer。</p>
<p>ReadView，里面有四个比较关键的东西：</p>
<p>一个是m_ids，这个就是说事务开启那一刻有哪些事务在Mysql里面执行还没有提交的；</p>
<p>一个是min_trx_id，就是m_ids里最小的事务id的值；</p>
<p>一个是max_trx_id，就是此刻mysql下一个要生成的事务id，就是最大事务id；</p>
<p>一个是creator_trx_id，就是你这个事务的id。</p>
<p><font color='red'><u><em><strong>如果比mintexid小或者等于creatoridexid，我们可以看得见。</strong></em></u></font></p>
<p>比如一条记录旧版本里面有三条记录：10，20，30。然后我们的事务id是15，m_ids里面有20，30。这里的min_trx_id就是20，我们的15比她小，说明还没有提交。因为隔离性所以肯定是看不到的，然后再去找更前面版本，我们就找到了10，发现10可以，所以我们这次读到的数据就是事务id为10的那一个版本。</p>
</blockquote>
<p>rr：事务启动的时候创建readview</p>
<p>rc：每次查询都会创建一个readview</p>
<p>mvcc是快照读，update是当前读，但是要注意两阶段锁协议</p>

                    
                        


                    
                    
                        <p>
                            <a
                                href="/2023/07/08/MySQL%E5%A4%8D%E4%B9%A0%EF%BC%88mysql%E6%8A%80%E6%9C%AF%E5%86%85%E5%B9%95%20innodb%E5%AD%98%E5%82%A8%E5%BC%95%E6%93%8E%EF%BC%89/#post-footer"
                                class="postShorten-excerpt_link link"
                                aria-label=""
                            >
                                Kommentieren und teilen
                            </a>
                        </p>
                    
                </div>
            
        </div>
        
    </article>
    
    <div class="pagination-bar">
    <ul class="pagination">
        
        
        <li class="pagination-number">Seite 1 von 1</li>
    </ul>
</div>

</section>



                <footer id="footer" class="main-content-wrap">
    <span class="copyrights">
        Copyrights &copy; 2023 CSEN. All Rights Reserved.
    </span>
</footer>

            </div>
            
        </div>
        


    
        
    

<div id="about">
    <div id="about-card">
        <div id="about-btn-close">
            <i class="fa fa-times"></i>
        </div>
        
            <img id="about-card-picture" src="/assets/images/head.jpg" alt="Bild des Autors"/>
        
            <h4 id="about-card-name">CSEN</h4>
        
            <div id="about-card-bio"><p>author.bio</p>
</div>
        
        
            <div id="about-card-job">
                <i class="fa fa-briefcase"></i>
                <br/>
                <p>author.job</p>

            </div>
        
        
            <div id="about-card-location">
                <i class="fa fa-map-marker-alt"></i>
                <br/>
                浙江温州
            </div>
        
    </div>
</div>

        
        
<div id="cover" style="background-image:url('/assets/images/cover.jpg');"></div>
        <!--SCRIPTS-->

<script src="/assets/js/script-39paoi2hupf5wmw7ojejrxpco6edftjriz5ezbtp4grymrdceksftgan2adp.min.js"></script>

<!--SCRIPTS END-->





    </body>
</html>
